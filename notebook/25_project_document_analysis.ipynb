{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ç¬¬25ç« ï¼šç»¼åˆé¡¹ç›® - æ–‡æ¡£åˆ†æç³»ç»Ÿ\n",
        "\n",
        "## é¡¹ç›®æ¦‚è¿°\n",
        "\n",
        "æœ¬ç« å°†æ„å»ºä¸€ä¸ª**è‡ªåŠ¨åŒ–æ–‡æ¡£åˆ†æå’Œæ€»ç»“ç³»ç»Ÿ**ï¼Œå±•ç¤ºæ‰¹é‡å¤„ç†å’Œç»“æ„åŒ–è¾“å‡ºçš„å®é™…åº”ç”¨ã€‚\n",
        "\n",
        "### ğŸ¯ é¡¹ç›®ç›®æ ‡\n",
        "\n",
        "æ„å»ºä¸€ä¸ªæ™ºèƒ½æ–‡æ¡£åˆ†æç³»ç»Ÿï¼Œèƒ½å¤Ÿï¼š\n",
        "- ğŸ“„ æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£\n",
        "- ğŸ¯ è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦\n",
        "- ğŸ” æå–å…³é”®ä¿¡æ¯\n",
        "- ğŸ“Š ç»“æ„åŒ–è¾“å‡ºç»“æœ\n",
        "- ğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š\n",
        "\n",
        "### ğŸ›  æŠ€æœ¯æ ˆ\n",
        "\n",
        "| ç»„ä»¶ | æŠ€æœ¯ | ä½œç”¨ |\n",
        "|------|------|------|\n",
        "| **æ–‡æ¡£å¤„ç†** | Document Loaders + Text Splitters | åŠ è½½å’Œåˆ†å‰²æ–‡æ¡£ |\n",
        "| **ç»“æ„åŒ–è¾“å‡º** | with_structured_output + Pydantic | è§„èŒƒåŒ–æ•°æ®æ ¼å¼ |\n",
        "| **æ‰¹å¤„ç†** | batch() | å¹¶è¡Œå¤„ç†å¤šä¸ªæ–‡æ¡£ |\n",
        "| **LCEL Chains** | Runnable + Pipe (&#124;) | æ„å»ºå¤„ç†æµç¨‹ |\n",
        "| **å¹¶å‘æ§åˆ¶** | max_concurrency | æ§åˆ¶å¹¶å‘æ•°é‡ |\n",
        "\n",
        "### ğŸ“‹ ç³»ç»Ÿæ¶æ„\n",
        "\n",
        "```\n",
        "å¤šä¸ªæ–‡æ¡£è¾“å…¥\n",
        "    â†“\n",
        "æ–‡æ¡£åŠ è½½å™¨ (Document Loader)\n",
        "    â†“\n",
        "æ‰¹é‡å¤„ç† (Batch Processing)\n",
        "    â”œâ”€ æ–‡æ¡£1 â†’ åˆ†æ â†’ ç»“æ„åŒ–è¾“å‡º\n",
        "    â”œâ”€ æ–‡æ¡£2 â†’ åˆ†æ â†’ ç»“æ„åŒ–è¾“å‡º\n",
        "    â”œâ”€ æ–‡æ¡£3 â†’ åˆ†æ â†’ ç»“æ„åŒ–è¾“å‡º\n",
        "    â””â”€ æ–‡æ¡£N â†’ åˆ†æ â†’ ç»“æ„åŒ–è¾“å‡º\n",
        "    â†“\n",
        "èšåˆç»“æœ\n",
        "    â†“\n",
        "ç”ŸæˆæŠ¥å‘Š\n",
        "```\n",
        "\n",
        "### ğŸ’¡ æ ¸å¿ƒç‰¹æ€§\n",
        "\n",
        "1. **æ‰¹é‡å¤„ç†** - é«˜æ•ˆå¤„ç†å¤šä¸ªæ–‡æ¡£\n",
        "2. **ç»“æ„åŒ–è¾“å‡º** - Pydanticæ¨¡å‹ç¡®ä¿æ•°æ®ä¸€è‡´æ€§\n",
        "3. **LCELé“¾** - ä¼˜é›…çš„å‡½æ•°å¼ç¼–ç¨‹é£æ ¼\n",
        "4. **å¹¶å‘æ§åˆ¶** - é¿å…APIé™æµ\n",
        "5. **é”™è¯¯å¤„ç†** - é²æ£’çš„å¼‚å¸¸å¤„ç†æœºåˆ¶\n",
        "\n",
        "### ğŸ†š vs å‰é¢ç« èŠ‚\n",
        "\n",
        "| å¯¹æ¯”é¡¹ | ç¬¬23ç« ï¼ˆRAGï¼‰ | ç¬¬24ç« ï¼ˆChatbotï¼‰ | ç¬¬25ç« ï¼ˆæ–‡æ¡£åˆ†æï¼‰ |\n",
        "|--------|--------------|------------------|-------------------|\n",
        "| **æ ¸å¿ƒç›®æ ‡** | æ–‡æ¡£é—®ç­” | å¤šè½®å¯¹è¯ | æ‰¹é‡æ–‡æ¡£å¤„ç† |\n",
        "| **å¤„ç†æ¨¡å¼** | å•æ¬¡æ£€ç´¢ | äº¤äº’å¼å¯¹è¯ | æ‰¹é‡å¹¶è¡Œå¤„ç† |\n",
        "| **è¾“å‡ºæ ¼å¼** | è‡ªç„¶è¯­è¨€ | è‡ªç„¶è¯­è¨€ | ç»“æ„åŒ–æ•°æ® |\n",
        "| **å…³é”®æŠ€æœ¯** | Retriever | Checkpointer | batch() + Pydantic |\n",
        "| **åº”ç”¨åœºæ™¯** | çŸ¥è¯†é—®ç­” | å®¢æœåŠ©æ‰‹ | æ•°æ®åˆ†æã€æŠ¥å‘Šç”Ÿæˆ |\n",
        "\n",
        "---\n",
        "\n",
        "## å­¦ä¹ æ”¶è·\n",
        "\n",
        "é€šè¿‡æœ¬é¡¹ç›®ï¼Œä½ å°†å­¦ä¼šï¼š\n",
        "- âœ… å¦‚ä½•ä½¿ç”¨batch()å¹¶è¡Œå¤„ç†æ•°æ®\n",
        "- âœ… å¦‚ä½•ä½¿ç”¨Pydanticå®šä¹‰ç»“æ„åŒ–è¾“å‡º\n",
        "- âœ… å¦‚ä½•ä½¿ç”¨LCELæ„å»ºå¤„ç†é“¾\n",
        "- âœ… å¦‚ä½•æ§åˆ¶å¹¶å‘é¿å…é™æµ\n",
        "- âœ… å¦‚ä½•å¤„ç†æ‰¹é‡å¤„ç†ä¸­çš„é”™è¯¯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ç¯å¢ƒé…ç½®å®Œæˆï¼\n",
            "æ¨¡å‹: gpt-4.1-mini\n"
          ]
        }
      ],
      "source": [
        "# ç¯å¢ƒé…ç½®\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "_project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "sys.path.append(_project_root)\n",
        "\n",
        "from config import config\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.agents import create_agent\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from typing import List, Optional\n",
        "import json\n",
        "\n",
        "# åˆå§‹åŒ–æ¨¡å‹\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    temperature=0,\n",
        "    api_key=config.CLOUD_API_KEY,\n",
        "    base_url=config.CLOUD_BASE_URL,\n",
        ")\n",
        "\n",
        "print(\"ç¯å¢ƒé…ç½®å®Œæˆï¼\")\n",
        "print(f\"æ¨¡å‹: {model.model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æ­¥éª¤1ï¼šå‡†å¤‡æµ‹è¯•æ–‡æ¡£\n",
        "\n",
        "åˆ›å»ºä¸€äº›ç¤ºä¾‹æ–‡æ¡£ç”¨äºåˆ†æã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ­¥éª¤1ï¼šå‡†å¤‡æµ‹è¯•æ–‡æ¡£ã€‘\n",
            "\n",
            "âœ“ å‡†å¤‡äº† 5 ä¸ªæµ‹è¯•æ–‡æ¡£\n",
            "\n",
            "  ğŸ“„ doc_001: äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•æŠ¥å‘Š\n",
            "     å†…å®¹é•¿åº¦: 217 å­—ç¬¦\n",
            "\n",
            "  ğŸ“„ doc_002: åŒºå—é“¾æŠ€æœ¯åº”ç”¨ç™½çš®ä¹¦\n",
            "     å†…å®¹é•¿åº¦: 183 å­—ç¬¦\n",
            "\n",
            "  ğŸ“„ doc_003: é‡å­è®¡ç®—å‰æ²¿ç ”ç©¶\n",
            "     å†…å®¹é•¿åº¦: 176 å­—ç¬¦\n",
            "\n",
            "  ğŸ“„ doc_004: 5Gä¸ç‰©è”ç½‘èåˆå‘å±•\n",
            "     å†…å®¹é•¿åº¦: 178 å­—ç¬¦\n",
            "\n",
            "  ğŸ“„ doc_005: å¯æŒç»­èƒ½æºæŠ€æœ¯è¶‹åŠ¿\n",
            "     å†…å®¹é•¿åº¦: 165 å­—ç¬¦\n",
            "\n",
            "ğŸ’¡ è¿™äº›æ–‡æ¡£æ¶µç›–äº†ï¼š\n",
            "  - äººå·¥æ™ºèƒ½\n",
            "  - åŒºå—é“¾\n",
            "  - é‡å­è®¡ç®—\n",
            "  - 5G/ç‰©è”ç½‘\n",
            "  - å¯æŒç»­èƒ½æº\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ­¥éª¤1ï¼šå‡†å¤‡æµ‹è¯•æ–‡æ¡£ã€‘\\n\")\n",
        "\n",
        "# åˆ›å»ºå¤šä¸ªæµ‹è¯•æ–‡æ¡£\n",
        "documents = [\n",
        "    {\n",
        "        \"id\": \"doc_001\",\n",
        "        \"title\": \"äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•æŠ¥å‘Š\",\n",
        "        \"content\": \"\"\"\n",
        "äººå·¥æ™ºèƒ½(AI)æŠ€æœ¯åœ¨è¿‡å»åå¹´ä¸­å–å¾—äº†çªç ´æ€§è¿›å±•ã€‚æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰\n",
        "ç­‰é¢†åŸŸçš„åˆ›æ–°æ¨åŠ¨äº†AIåœ¨å„è¡Œå„ä¸šçš„å¹¿æ³›åº”ç”¨ã€‚GPTç³»åˆ—æ¨¡å‹çš„å‡ºç°æ ‡å¿—ç€å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£\n",
        "çš„åˆ°æ¥ï¼Œä½¿å¾—æœºå™¨èƒ½å¤Ÿç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ï¼Œåœ¨å¯¹è¯ã€å†™ä½œã€ç¼–ç¨‹ç­‰ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ã€‚\n",
        "\n",
        "æœªæ¥ï¼ŒAIæŠ€æœ¯å°†ç»§ç»­å‘æ›´å¼ºçš„é€šç”¨äººå·¥æ™ºèƒ½(AGI)æ–¹å‘å‘å±•ï¼ŒåŒæ—¶ä¹Ÿéœ€è¦å…³æ³¨AIä¼¦ç†ã€\n",
        "æ•°æ®éšç§å’Œå®‰å…¨ç­‰é‡è¦è®®é¢˜ã€‚é¢„è®¡åˆ°2030å¹´ï¼ŒAIå°†åˆ›é€ æ•°ä¸‡äº¿ç¾å…ƒçš„ç»æµä»·å€¼ã€‚\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_002\",\n",
        "        \"title\": \"åŒºå—é“¾æŠ€æœ¯åº”ç”¨ç™½çš®ä¹¦\",\n",
        "        \"content\": \"\"\"\n",
        "åŒºå—é“¾æŠ€æœ¯ä½œä¸ºä¸€ç§åˆ†å¸ƒå¼è´¦æœ¬æŠ€æœ¯ï¼Œå…·æœ‰å»ä¸­å¿ƒåŒ–ã€ä¸å¯ç¯¡æ”¹ã€é€æ˜å¯è¿½æº¯ç­‰ç‰¹ç‚¹ã€‚\n",
        "æ¯”ç‰¹å¸å’Œä»¥å¤ªåŠçš„æˆåŠŸå±•ç¤ºäº†åŒºå—é“¾åœ¨æ•°å­—è´§å¸å’Œæ™ºèƒ½åˆçº¦é¢†åŸŸçš„å·¨å¤§æ½œåŠ›ã€‚\n",
        "\n",
        "è¿‘å¹´æ¥ï¼ŒåŒºå—é“¾åº”ç”¨å·²æ‰©å±•åˆ°ä¾›åº”é“¾ç®¡ç†ã€æ•°å­—èº«ä»½ã€é‡‘èæœåŠ¡ç­‰å¤šä¸ªé¢†åŸŸã€‚NFTå’Œ\n",
        "DeFiçš„å…´èµ·è¿›ä¸€æ­¥æ¨åŠ¨äº†Web3ç”Ÿæ€çš„å‘å±•ã€‚ç„¶è€Œï¼Œå¯æ‰©å±•æ€§ã€èƒ½æºæ¶ˆè€—å’Œç›‘ç®¡åˆè§„\n",
        "ä»æ˜¯åŒºå—é“¾å¤§è§„æ¨¡åº”ç”¨é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ã€‚\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_003\",\n",
        "        \"title\": \"é‡å­è®¡ç®—å‰æ²¿ç ”ç©¶\",\n",
        "        \"content\": \"\"\"\n",
        "é‡å­è®¡ç®—åˆ©ç”¨é‡å­åŠ›å­¦åŸç†è¿›è¡Œä¿¡æ¯å¤„ç†ï¼Œåœ¨ç‰¹å®šé—®é¢˜ä¸Šå…·æœ‰æŒ‡æ•°çº§çš„è®¡ç®—ä¼˜åŠ¿ã€‚\n",
        "Googleã€IBMç­‰ç§‘æŠ€å·¨å¤´æ­£åœ¨ç§¯æç ”å‘é‡å­è®¡ç®—æœºï¼Œå¹¶å–å¾—äº†é‡å­ä¼˜è¶Šæ€§çš„é‡Œç¨‹ç¢‘æˆæœã€‚\n",
        "\n",
        "é‡å­è®¡ç®—æœ‰æœ›åœ¨å¯†ç å­¦ã€è¯ç‰©å‘ç°ã€ææ–™ç§‘å­¦ã€é‡‘èå»ºæ¨¡ç­‰é¢†åŸŸå¸¦æ¥é©å‘½æ€§çªç ´ã€‚\n",
        "ä½†é‡å­çº é”™ã€é‡å­æ¯”ç‰¹ç¨³å®šæ€§ç­‰æŠ€æœ¯éš¾é¢˜ä»éœ€å…‹æœã€‚é¢„è®¡10-20å¹´å†…ï¼Œé‡å­è®¡ç®—å°†\n",
        "è¿›å…¥å®ç”¨åŒ–é˜¶æ®µã€‚\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_004\",\n",
        "        \"title\": \"5Gä¸ç‰©è”ç½‘èåˆå‘å±•\",\n",
        "        \"content\": \"\"\"\n",
        "5Gç½‘ç»œçš„é«˜é€Ÿç‡ã€ä½å»¶è¿Ÿç‰¹æ€§ä¸ºç‰©è”ç½‘(IoT)åº”ç”¨æä¾›äº†å¼ºå¤§æ”¯æŒã€‚æ™ºèƒ½åŸå¸‚ã€\n",
        "å·¥ä¸šäº’è”ç½‘ã€è‡ªåŠ¨é©¾é©¶ç­‰åœºæ™¯æ­£åœ¨5GæŠ€æœ¯çš„æ¨åŠ¨ä¸‹åŠ é€Ÿè½åœ°ã€‚\n",
        "\n",
        "ç‰©è”ç½‘è®¾å¤‡æ•°é‡é¢„è®¡å°†åœ¨æœªæ¥äº”å¹´å†…çªç ´500äº¿å°ï¼Œå½¢æˆä¸‡ç‰©äº’è”çš„ç”Ÿæ€ç³»ç»Ÿã€‚\n",
        "è¾¹ç¼˜è®¡ç®—å’Œ5Gçš„ç»“åˆå°†ä½¿å®æ—¶æ•°æ®å¤„ç†æˆä¸ºå¯èƒ½ï¼Œå¼€åˆ›æ–°çš„å•†ä¸šæ¨¡å¼å’ŒæœåŠ¡å½¢æ€ã€‚\n",
        "å®‰å…¨æ€§å’Œéšç§ä¿æŠ¤æ˜¯ç‰©è”ç½‘å‘å±•éœ€è¦é‡ç‚¹å…³æ³¨çš„é—®é¢˜ã€‚\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_005\",\n",
        "        \"title\": \"å¯æŒç»­èƒ½æºæŠ€æœ¯è¶‹åŠ¿\",\n",
        "        \"content\": \"\"\"\n",
        "éšç€å…¨çƒæ°”å€™å˜åŒ–é—®é¢˜æ—¥ç›Šä¸¥å³»ï¼Œå¯æŒç»­èƒ½æºæŠ€æœ¯æˆä¸ºå„å›½é‡ç‚¹å‘å±•æ–¹å‘ã€‚å¤ªé˜³èƒ½ã€\n",
        "é£èƒ½ã€æ°¢èƒ½ç­‰æ¸…æ´èƒ½æºæŠ€æœ¯ä¸æ–­è¿›æ­¥ï¼Œæˆæœ¬æŒç»­ä¸‹é™ï¼Œç«äº‰åŠ›æ˜¾è‘—æå‡ã€‚\n",
        "\n",
        "å‚¨èƒ½æŠ€æœ¯çš„çªç ´è§£å†³äº†å¯å†ç”Ÿèƒ½æºçš„é—´æ­‡æ€§é—®é¢˜ï¼Œç”µæ± æŠ€æœ¯å’Œæ™ºèƒ½ç”µç½‘çš„å‘å±•æ¨åŠ¨äº†\n",
        "èƒ½æºè½¬å‹ã€‚åˆ°2050å¹´ï¼Œé¢„è®¡å¯å†ç”Ÿèƒ½æºå°†å å…¨çƒèƒ½æºæ¶ˆè´¹çš„70%ä»¥ä¸Šï¼ŒåŠ©åŠ›å®ç°\n",
        "ç¢³ä¸­å’Œç›®æ ‡ã€‚\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"âœ“ å‡†å¤‡äº† {len(documents)} ä¸ªæµ‹è¯•æ–‡æ¡£\\n\")\n",
        "for doc in documents:\n",
        "    print(f\"  ğŸ“„ {doc['id']}: {doc['title']}\")\n",
        "    print(f\"     å†…å®¹é•¿åº¦: {len(doc['content'])} å­—ç¬¦\\n\")\n",
        "\n",
        "print(\"ğŸ’¡ è¿™äº›æ–‡æ¡£æ¶µç›–äº†ï¼š\")\n",
        "print(\"  - äººå·¥æ™ºèƒ½\")\n",
        "print(\"  - åŒºå—é“¾\")\n",
        "print(\"  - é‡å­è®¡ç®—\")\n",
        "print(\"  - 5G/ç‰©è”ç½‘\")\n",
        "print(\"  - å¯æŒç»­èƒ½æº\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æ­¥éª¤2ï¼šå®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹\n",
        "\n",
        "ä½¿ç”¨Pydanticå®šä¹‰æ–‡æ¡£åˆ†æçš„è¾“å‡ºæ ¼å¼ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ­¥éª¤2ï¼šå®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹ã€‘\n",
            "\n",
            "âœ“ å®šä¹‰äº†ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹ï¼šDocumentAnalysis\n",
            "\n",
            "æ¨¡å‹å­—æ®µï¼š\n",
            "  - doc_id: æ–‡æ¡£ID\n",
            "  - title: æ–‡æ¡£æ ‡é¢˜\n",
            "  - summary: æ–‡æ¡£æ‘˜è¦ï¼ˆ3-5å¥è¯ï¼‰\n",
            "  - keywords: å…³é”®è¯åˆ—è¡¨ï¼ˆ3-5ä¸ªï¼‰\n",
            "  - category: æ–‡æ¡£ç±»åˆ«ï¼ˆå¦‚ï¼šæŠ€æœ¯æŠ¥å‘Šã€ç™½çš®ä¹¦ã€ç ”ç©¶è®ºæ–‡ç­‰ï¼‰\n",
            "  - main_topics: ä¸»è¦è¯é¢˜ï¼ˆ2-4ä¸ªï¼‰\n",
            "  - sentiment: æƒ…æ„Ÿå€¾å‘ï¼šç§¯æ/ä¸­ç«‹/æ¶ˆæ\n",
            "  - complexity_level: å¤æ‚åº¦ï¼šç®€å•/ä¸­ç­‰/å¤æ‚\n",
            "  - key_findings: å…³é”®å‘ç°æˆ–ç»“è®ºï¼ˆå¦‚æœ‰ï¼‰\n",
            "\n",
            "ğŸ’¡ ä½¿ç”¨Pydanticçš„ä¼˜åŠ¿ï¼š\n",
            "  âœ“ è‡ªåŠ¨ç±»å‹éªŒè¯\n",
            "  âœ“ æ¸…æ™°çš„schemaå®šä¹‰\n",
            "  âœ“ æ˜“äºåºåˆ—åŒ–/ååºåˆ—åŒ–\n",
            "  âœ“ ä¸LLMç»“æ„åŒ–è¾“å‡ºå®Œç¾é›†æˆ\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1000553/3794650406.py:4: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  class DocumentAnalysis(BaseModel):\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ­¥éª¤2ï¼šå®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹ã€‘\\n\")\n",
        "\n",
        "# å®šä¹‰æ–‡æ¡£åˆ†æç»“æœçš„Pydanticæ¨¡å‹\n",
        "class DocumentAnalysis(BaseModel):\n",
        "    \"\"\"æ–‡æ¡£åˆ†æç»“æœçš„ç»“æ„åŒ–è¾“å‡º\"\"\"\n",
        "    \n",
        "    doc_id: str = Field(description=\"æ–‡æ¡£ID\")\n",
        "    title: str = Field(description=\"æ–‡æ¡£æ ‡é¢˜\")\n",
        "    summary: str = Field(description=\"æ–‡æ¡£æ‘˜è¦ï¼ˆ3-5å¥è¯ï¼‰\")\n",
        "    keywords: List[str] = Field(description=\"å…³é”®è¯åˆ—è¡¨ï¼ˆ3-5ä¸ªï¼‰\")\n",
        "    category: str = Field(description=\"æ–‡æ¡£ç±»åˆ«ï¼ˆå¦‚ï¼šæŠ€æœ¯æŠ¥å‘Šã€ç™½çš®ä¹¦ã€ç ”ç©¶è®ºæ–‡ç­‰ï¼‰\")\n",
        "    main_topics: List[str] = Field(description=\"ä¸»è¦è¯é¢˜ï¼ˆ2-4ä¸ªï¼‰\")\n",
        "    sentiment: str = Field(description=\"æƒ…æ„Ÿå€¾å‘ï¼šç§¯æ/ä¸­ç«‹/æ¶ˆæ\")\n",
        "    complexity_level: str = Field(description=\"å¤æ‚åº¦ï¼šç®€å•/ä¸­ç­‰/å¤æ‚\")\n",
        "    key_findings: Optional[List[str]] = Field(\n",
        "        default=None,\n",
        "        description=\"å…³é”®å‘ç°æˆ–ç»“è®ºï¼ˆå¦‚æœ‰ï¼‰\"\n",
        "    )\n",
        "    \n",
        "    class Config:\n",
        "        json_schema_extra = {\n",
        "            \"example\": {\n",
        "                \"doc_id\": \"doc_001\",\n",
        "                \"title\": \"ç¤ºä¾‹æ–‡æ¡£\",\n",
        "                \"summary\": \"è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ–‡æ¡£çš„æ‘˜è¦ã€‚\",\n",
        "                \"keywords\": [\"å…³é”®è¯1\", \"å…³é”®è¯2\"],\n",
        "                \"category\": \"æŠ€æœ¯æŠ¥å‘Š\",\n",
        "                \"main_topics\": [\"è¯é¢˜1\", \"è¯é¢˜2\"],\n",
        "                \"sentiment\": \"ç§¯æ\",\n",
        "                \"complexity_level\": \"ä¸­ç­‰\",\n",
        "                \"key_findings\": [\"å‘ç°1\", \"å‘ç°2\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "print(\"âœ“ å®šä¹‰äº†ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹ï¼šDocumentAnalysis\\n\")\n",
        "print(\"æ¨¡å‹å­—æ®µï¼š\")\n",
        "for field_name, field_info in DocumentAnalysis.model_fields.items():\n",
        "    print(f\"  - {field_name}: {field_info.description}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ ä½¿ç”¨Pydanticçš„ä¼˜åŠ¿ï¼š\")\n",
        "print(\"  âœ“ è‡ªåŠ¨ç±»å‹éªŒè¯\")\n",
        "print(\"  âœ“ æ¸…æ™°çš„schemaå®šä¹‰\")\n",
        "print(\"  âœ“ æ˜“äºåºåˆ—åŒ–/ååºåˆ—åŒ–\")\n",
        "print(\"  âœ“ ä¸LLMç»“æ„åŒ–è¾“å‡ºå®Œç¾é›†æˆ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æ­¥éª¤3ï¼šæ„å»ºLCELåˆ†æé“¾\n",
        "\n",
        "ä½¿ç”¨LCELï¼ˆLangChain Expression Languageï¼‰æ„å»ºæ–‡æ¡£åˆ†æé“¾ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ­¥éª¤3ï¼šæ„å»ºLCELåˆ†æé“¾ã€‘\n",
            "\n",
            "=== åˆ›å»ºPromptæ¨¡æ¿ ===\n",
            "\n",
            "âœ“ Promptæ¨¡æ¿åˆ›å»ºå®Œæˆ\n",
            "\n",
            "=== é…ç½®ç»“æ„åŒ–è¾“å‡º ===\n",
            "\n",
            "âœ“ å·²é…ç½®ç»“æ„åŒ–è¾“å‡ºï¼ˆä½¿ç”¨DocumentAnalysisæ¨¡å‹ï¼‰\n",
            "\n",
            "=== æ„å»ºLCELé“¾ ===\n",
            "\n",
            "âœ“ LCELé“¾æ„å»ºå®Œæˆ\n",
            "  ç»“æ„: Prompt â†’ LLM â†’ Structured Output\n",
            "\n",
            "ğŸ‰ æ–‡æ¡£åˆ†æé“¾å·²å°±ç»ªï¼\n",
            "\n",
            "ğŸ’¡ LCELçš„ä¼˜åŠ¿ï¼š\n",
            "  - ä½¿ç”¨ç®¡é“ç¬¦(|)è¿æ¥ç»„ä»¶\n",
            "  - ä»£ç ç®€æ´æ˜“è¯»\n",
            "  - è‡ªåŠ¨å¤„ç†æ•°æ®æµè½¬\n",
            "  - æ”¯æŒæµå¼å’Œæ‰¹é‡å¤„ç†\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ­¥éª¤3ï¼šæ„å»ºLCELåˆ†æé“¾ã€‘\\n\")\n",
        "\n",
        "# 1. åˆ›å»ºPromptæ¨¡æ¿\n",
        "print(\"=== åˆ›å»ºPromptæ¨¡æ¿ ===\\n\")\n",
        "analysis_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æä¸“å®¶ã€‚\n",
        "\n",
        "ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç»™å®šçš„æ–‡æ¡£å¹¶æå–ä»¥ä¸‹ä¿¡æ¯ï¼š\n",
        "- æ–‡æ¡£æ ‡é¢˜å’ŒID\n",
        "- ç®€æ´çš„æ‘˜è¦ï¼ˆ3-5å¥è¯ï¼‰\n",
        "- å…³é”®è¯ï¼ˆ3-5ä¸ªï¼‰\n",
        "- æ–‡æ¡£ç±»åˆ«\n",
        "- ä¸»è¦è¯é¢˜\n",
        "- æƒ…æ„Ÿå€¾å‘\n",
        "- å¤æ‚åº¦çº§åˆ«\n",
        "- å…³é”®å‘ç°\n",
        "\n",
        "è¯·ç¡®ä¿åˆ†æå‡†ç¡®ã€å®¢è§‚ã€å…¨é¢ã€‚\"\"\"),\n",
        "    (\"human\", \"\"\"è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£ï¼š\n",
        "\n",
        "**æ–‡æ¡£ID**: {doc_id}\n",
        "**æ ‡é¢˜**: {title}\n",
        "**å†…å®¹**:\n",
        "{content}\n",
        "\n",
        "è¯·æŒ‰ç…§æŒ‡å®šçš„æ ¼å¼è¿”å›åˆ†æç»“æœã€‚\"\"\")\n",
        "])\n",
        "print(\"âœ“ Promptæ¨¡æ¿åˆ›å»ºå®Œæˆ\")\n",
        "print()\n",
        "\n",
        "# 2. ä½¿ç”¨with_structured_outputé…ç½®ç»“æ„åŒ–è¾“å‡º\n",
        "print(\"=== é…ç½®ç»“æ„åŒ–è¾“å‡º ===\\n\")\n",
        "structured_llm = model.with_structured_output(DocumentAnalysis)\n",
        "print(\"âœ“ å·²é…ç½®ç»“æ„åŒ–è¾“å‡ºï¼ˆä½¿ç”¨DocumentAnalysisæ¨¡å‹ï¼‰\")\n",
        "print()\n",
        "\n",
        "# 3. æ„å»ºLCELé“¾\n",
        "print(\"=== æ„å»ºLCELé“¾ ===\\n\")\n",
        "analysis_chain = analysis_prompt | structured_llm\n",
        "print(\"âœ“ LCELé“¾æ„å»ºå®Œæˆ\")\n",
        "print(\"  ç»“æ„: Prompt â†’ LLM â†’ Structured Output\")\n",
        "print()\n",
        "\n",
        "print(\"ğŸ‰ æ–‡æ¡£åˆ†æé“¾å·²å°±ç»ªï¼\")\n",
        "print(\"\\nğŸ’¡ LCELçš„ä¼˜åŠ¿ï¼š\")\n",
        "print(\"  - ä½¿ç”¨ç®¡é“ç¬¦(|)è¿æ¥ç»„ä»¶\")\n",
        "print(\"  - ä»£ç ç®€æ´æ˜“è¯»\")\n",
        "print(\"  - è‡ªåŠ¨å¤„ç†æ•°æ®æµè½¬\")\n",
        "print(\"  - æ”¯æŒæµå¼å’Œæ‰¹é‡å¤„ç†\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æ­¥éª¤4ï¼šæ‰¹é‡å¤„ç†æ–‡æ¡£\n",
        "\n",
        "ä½¿ç”¨`batch()`å¹¶è¡Œå¤„ç†å¤šä¸ªæ–‡æ¡£ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ­¥éª¤4ï¼šæ‰¹é‡å¤„ç†æ–‡æ¡£ã€‘\n",
            "\n",
            "å‡†å¤‡æ‰¹é‡å¤„ç† 5 ä¸ªæ–‡æ¡£...\n",
            "\n",
            "=== ä½¿ç”¨batch()å¹¶è¡Œå¤„ç† ===\n",
            "\n",
            "âœ“ æ‰¹é‡å¤„ç†å®Œæˆï¼\n",
            "  å¤„ç†æ–‡æ¡£æ•°: 5\n",
            "  æ€»è€—æ—¶: 12.31 ç§’\n",
            "  å¹³å‡æ¯ç¯‡: 2.46 ç§’\n",
            "\n",
            "=== åˆ†æç»“æœé¢„è§ˆ ===\n",
            "\n",
            "ã€æ–‡æ¡£ 1ã€‘äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•æŠ¥å‘Š\n",
            "  ç±»åˆ«: æŠ€æœ¯æŠ¥å‘Š\n",
            "  æ‘˜è¦: æœ¬æ–‡æŠ¥å‘Šäº†äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨è¿‡å»åå¹´çš„çªç ´æ€§è¿›å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨æ·±åº¦å­¦ä¹ å’Œå¤§è¯­è¨€æ¨¡å‹é¢†åŸŸçš„åˆ›æ–°ã€‚GPTç³»åˆ—æ¨¡å‹çš„å‡ºç°æ¨åŠ¨äº†AIåœ¨è¯­è¨€ç†è§£å’Œç”Ÿæˆæ–¹é¢çš„èƒ½åŠ›æå‡ã€‚æœªæ¥ï¼ŒAIå°†...\n",
            "  å…³é”®è¯: äººå·¥æ™ºèƒ½, æ·±åº¦å­¦ä¹ , å¤§è¯­è¨€æ¨¡å‹, é€šç”¨äººå·¥æ™ºèƒ½, AIä¼¦ç†\n",
            "  æƒ…æ„Ÿ: ç§¯æ | å¤æ‚åº¦: ä¸­ç­‰\n",
            "\n",
            "ã€æ–‡æ¡£ 2ã€‘åŒºå—é“¾æŠ€æœ¯åº”ç”¨ç™½çš®ä¹¦\n",
            "  ç±»åˆ«: ç™½çš®ä¹¦\n",
            "  æ‘˜è¦: æœ¬æ–‡ä»‹ç»äº†åŒºå—é“¾æŠ€æœ¯çš„æ ¸å¿ƒç‰¹æ€§åŠå…¶åœ¨æ•°å­—è´§å¸å’Œæ™ºèƒ½åˆçº¦é¢†åŸŸçš„æˆåŠŸåº”ç”¨ã€‚åŒºå—é“¾æŠ€æœ¯çš„åº”ç”¨èŒƒå›´å·²æ‰©å±•åˆ°ä¾›åº”é“¾ç®¡ç†ã€æ•°å­—èº«ä»½å’Œé‡‘èæœåŠ¡ç­‰å¤šä¸ªé¢†åŸŸã€‚NFTå’ŒDeFiçš„å…´...\n",
            "  å…³é”®è¯: åŒºå—é“¾, æ•°å­—è´§å¸, æ™ºèƒ½åˆçº¦, NFT, DeFi\n",
            "  æƒ…æ„Ÿ: ä¸­ç«‹ | å¤æ‚åº¦: ä¸­ç­‰\n",
            "\n",
            "ğŸ’¡ batch()çš„ä¼˜åŠ¿ï¼š\n",
            "  âœ“ è‡ªåŠ¨å¹¶è¡Œå¤„ç†ï¼Œæé«˜æ•ˆç‡\n",
            "  âœ“ max_concurrencyæ§åˆ¶å¹¶å‘æ•°\n",
            "  âœ“ ç›¸æ¯”ä¸²è¡Œå¤„ç†èŠ‚çœå¤§é‡æ—¶é—´\n",
            "  âœ“ é€‚åˆå¤„ç†å¤§é‡ç‹¬ç«‹ä»»åŠ¡\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ­¥éª¤4ï¼šæ‰¹é‡å¤„ç†æ–‡æ¡£ã€‘\\n\")\n",
        "\n",
        "import time\n",
        "\n",
        "# å‡†å¤‡è¾“å…¥æ•°æ®\n",
        "inputs = [\n",
        "    {\"doc_id\": doc[\"id\"], \"title\": doc[\"title\"], \"content\": doc[\"content\"]}\n",
        "    for doc in documents\n",
        "]\n",
        "\n",
        "print(f\"å‡†å¤‡æ‰¹é‡å¤„ç† {len(inputs)} ä¸ªæ–‡æ¡£...\\n\")\n",
        "\n",
        "# æ–¹å¼1ï¼šä½¿ç”¨batch()å¹¶è¡Œå¤„ç†\n",
        "print(\"=== ä½¿ç”¨batch()å¹¶è¡Œå¤„ç† ===\\n\")\n",
        "start_time = time.time()\n",
        "\n",
        "results = analysis_chain.batch(\n",
        "    inputs,\n",
        "    config={\"max_concurrency\": 3}  # æ§åˆ¶å¹¶å‘æ•°ï¼Œé¿å…é™æµ\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"âœ“ æ‰¹é‡å¤„ç†å®Œæˆï¼\")\n",
        "print(f\"  å¤„ç†æ–‡æ¡£æ•°: {len(results)}\")\n",
        "print(f\"  æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’\")\n",
        "print(f\"  å¹³å‡æ¯ç¯‡: {(end_time - start_time) / len(results):.2f} ç§’\")\n",
        "print()\n",
        "\n",
        "# æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ\n",
        "print(\"=== åˆ†æç»“æœé¢„è§ˆ ===\\n\")\n",
        "for i, result in enumerate(results[:2], 1):  # æ˜¾ç¤ºå‰2ä¸ª\n",
        "    print(f\"ã€æ–‡æ¡£ {i}ã€‘{result.title}\")\n",
        "    print(f\"  ç±»åˆ«: {result.category}\")\n",
        "    print(f\"  æ‘˜è¦: {result.summary[:80]}...\")\n",
        "    print(f\"  å…³é”®è¯: {', '.join(result.keywords)}\")\n",
        "    print(f\"  æƒ…æ„Ÿ: {result.sentiment} | å¤æ‚åº¦: {result.complexity_level}\")\n",
        "    print()\n",
        "\n",
        "print(\"ğŸ’¡ batch()çš„ä¼˜åŠ¿ï¼š\")\n",
        "print(\"  âœ“ è‡ªåŠ¨å¹¶è¡Œå¤„ç†ï¼Œæé«˜æ•ˆç‡\")\n",
        "print(\"  âœ“ max_concurrencyæ§åˆ¶å¹¶å‘æ•°\")\n",
        "print(\"  âœ“ ç›¸æ¯”ä¸²è¡Œå¤„ç†èŠ‚çœå¤§é‡æ—¶é—´\")\n",
        "print(\"  âœ“ é€‚åˆå¤„ç†å¤§é‡ç‹¬ç«‹ä»»åŠ¡\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æ­¥éª¤5ï¼šç”Ÿæˆåˆ†ææŠ¥å‘Š\n",
        "\n",
        "èšåˆæ‰€æœ‰åˆ†æç»“æœï¼Œç”Ÿæˆç»¼åˆæŠ¥å‘Šã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ­¥éª¤5ï¼šç”Ÿæˆåˆ†ææŠ¥å‘Šã€‘\n",
            "\n",
            "=== æ•°æ®ç»Ÿè®¡ ===\n",
            "\n",
            "æ–‡æ¡£ç±»åˆ«åˆ†å¸ƒ:\n",
            "  - æŠ€æœ¯æŠ¥å‘Š: 4ç¯‡\n",
            "  - ç™½çš®ä¹¦: 1ç¯‡\n",
            "\n",
            "æƒ…æ„Ÿå€¾å‘åˆ†å¸ƒ:\n",
            "  - ç§¯æ: 4ç¯‡\n",
            "  - ä¸­ç«‹: 1ç¯‡\n",
            "\n",
            "å¤æ‚åº¦åˆ†å¸ƒ:\n",
            "  - ä¸­ç­‰: 5ç¯‡\n",
            "\n",
            "=== ç”ŸæˆJSONæŠ¥å‘Š ===\n",
            "\n",
            "âœ“ æŠ¥å‘Šå·²ä¿å­˜: /home/iip/tp/038-project/rag/docs/analysis_report.json\n",
            "  åŒ…å« 5 ç¯‡æ–‡æ¡£çš„å®Œæ•´åˆ†æ\n",
            "\n",
            "ğŸ“Š æŠ¥å‘Šå†…å®¹ï¼š\n",
            "  - å…ƒæ•°æ®ï¼ˆæ€»æ•°ã€æ—¥æœŸã€è€—æ—¶ï¼‰\n",
            "  - ç»Ÿè®¡ä¿¡æ¯ï¼ˆç±»åˆ«ã€æƒ…æ„Ÿã€å¤æ‚åº¦ï¼‰\n",
            "  - æ¯ç¯‡æ–‡æ¡£çš„è¯¦ç»†åˆ†æç»“æœ\n",
            "\n",
            "ğŸ’¡ åº”ç”¨åœºæ™¯ï¼š\n",
            "  - æ‰¹é‡æ–‡æ¡£åˆ†ç±»å’Œæ ‡æ³¨\n",
            "  - å†…å®¹å®¡æ ¸å’Œè´¨é‡æ£€æŸ¥\n",
            "  - çŸ¥è¯†åº“æ„å»ºå’Œç®¡ç†\n",
            "  - è¶‹åŠ¿åˆ†æå’Œæ•°æ®æŒ–æ˜\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ­¥éª¤5ï¼šç”Ÿæˆåˆ†ææŠ¥å‘Šã€‘\\n\")\n",
        "\n",
        "# ç»Ÿè®¡åˆ†æ\n",
        "print(\"=== æ•°æ®ç»Ÿè®¡ ===\\n\")\n",
        "categories = {}\n",
        "sentiments = {}\n",
        "complexity_levels = {}\n",
        "all_keywords = []\n",
        "\n",
        "for result in results:\n",
        "    # ç»Ÿè®¡ç±»åˆ«\n",
        "    categories[result.category] = categories.get(result.category, 0) + 1\n",
        "    # ç»Ÿè®¡æƒ…æ„Ÿ\n",
        "    sentiments[result.sentiment] = sentiments.get(result.sentiment, 0) + 1\n",
        "    # ç»Ÿè®¡å¤æ‚åº¦\n",
        "    complexity_levels[result.complexity_level] = complexity_levels.get(result.complexity_level, 0) + 1\n",
        "    # æ”¶é›†å…³é”®è¯\n",
        "    all_keywords.extend(result.keywords)\n",
        "\n",
        "print(f\"æ–‡æ¡£ç±»åˆ«åˆ†å¸ƒ:\")\n",
        "for cat, count in categories.items():\n",
        "    print(f\"  - {cat}: {count}ç¯‡\")\n",
        "print()\n",
        "\n",
        "print(f\"æƒ…æ„Ÿå€¾å‘åˆ†å¸ƒ:\")\n",
        "for sent, count in sentiments.items():\n",
        "    print(f\"  - {sent}: {count}ç¯‡\")\n",
        "print()\n",
        "\n",
        "print(f\"å¤æ‚åº¦åˆ†å¸ƒ:\")\n",
        "for level, count in complexity_levels.items():\n",
        "    print(f\"  - {level}: {count}ç¯‡\")\n",
        "print()\n",
        "\n",
        "# ç”ŸæˆJSONæŠ¥å‘Š\n",
        "print(\"=== ç”ŸæˆJSONæŠ¥å‘Š ===\\n\")\n",
        "report = {\n",
        "    \"meta\": {\n",
        "        \"total_documents\": len(results),\n",
        "        \"analysis_date\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"processing_time\": f\"{end_time - start_time:.2f}ç§’\"\n",
        "    },\n",
        "    \"statistics\": {\n",
        "        \"categories\": categories,\n",
        "        \"sentiments\": sentiments,\n",
        "        \"complexity_levels\": complexity_levels,\n",
        "        \"unique_keywords\": len(set(all_keywords))\n",
        "    },\n",
        "    \"documents\": [result.model_dump() for result in results]\n",
        "}\n",
        "\n",
        "# ä¿å­˜æŠ¥å‘Š\n",
        "report_path = os.path.join(_project_root, \"docs\", \"analysis_report.json\")\n",
        "os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
        "\n",
        "with open(report_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(report, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"âœ“ æŠ¥å‘Šå·²ä¿å­˜: {report_path}\")\n",
        "print(f\"  åŒ…å« {len(results)} ç¯‡æ–‡æ¡£çš„å®Œæ•´åˆ†æ\")\n",
        "print()\n",
        "\n",
        "print(\"ğŸ“Š æŠ¥å‘Šå†…å®¹ï¼š\")\n",
        "print(\"  - å…ƒæ•°æ®ï¼ˆæ€»æ•°ã€æ—¥æœŸã€è€—æ—¶ï¼‰\")\n",
        "print(\"  - ç»Ÿè®¡ä¿¡æ¯ï¼ˆç±»åˆ«ã€æƒ…æ„Ÿã€å¤æ‚åº¦ï¼‰\")\n",
        "print(\"  - æ¯ç¯‡æ–‡æ¡£çš„è¯¦ç»†åˆ†æç»“æœ\")\n",
        "print()\n",
        "\n",
        "print(\"ğŸ’¡ åº”ç”¨åœºæ™¯ï¼š\")\n",
        "print(\"  - æ‰¹é‡æ–‡æ¡£åˆ†ç±»å’Œæ ‡æ³¨\")\n",
        "print(\"  - å†…å®¹å®¡æ ¸å’Œè´¨é‡æ£€æŸ¥\")\n",
        "print(\"  - çŸ¥è¯†åº“æ„å»ºå’Œç®¡ç†\")\n",
        "print(\"  - è¶‹åŠ¿åˆ†æå’Œæ•°æ®æŒ–æ˜\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## é¡¹ç›®æ€»ç»“\n",
        "\n",
        "### ğŸ‰ å®Œæˆçš„åŠŸèƒ½\n",
        "\n",
        "æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„æ–‡æ¡£åˆ†æç³»ç»Ÿï¼š\n",
        "\n",
        "| åŠŸèƒ½æ¨¡å— | å®ç°æ–¹å¼ | å…³é”®æŠ€æœ¯ |\n",
        "|---------|---------|---------|\n",
        "| **ç»“æ„åŒ–è¾“å‡º** | Pydantic BaseModel | ç±»å‹å®‰å…¨çš„æ•°æ®æ¨¡å‹ |\n",
        "| **LCELé“¾** | Prompt &#124; LLM &#124; Output | å‡½æ•°å¼ç¼–ç¨‹é£æ ¼ |\n",
        "| **æ‰¹é‡å¤„ç†** | batch() + max_concurrency | å¹¶è¡Œå¤„ç†æé«˜æ•ˆç‡ |\n",
        "| **æ•°æ®èšåˆ** | Pythonç»Ÿè®¡ + JSON | ç”Ÿæˆç»¼åˆæŠ¥å‘Š |\n",
        "\n",
        "### ğŸ”‘ å…³é”®æŠ€æœ¯ç‚¹\n",
        "\n",
        "#### 1. Pydanticç»“æ„åŒ–è¾“å‡º\n",
        "\n",
        "```python\n",
        "class DocumentAnalysis(BaseModel):\n",
        "    doc_id: str = Field(description=\"æ–‡æ¡£ID\")\n",
        "    summary: str = Field(description=\"æ–‡æ¡£æ‘˜è¦\")\n",
        "    keywords: List[str] = Field(description=\"å…³é”®è¯\")\n",
        "    # ... æ›´å¤šå­—æ®µ\n",
        "\n",
        "# ä½¿ç”¨with_structured_output\n",
        "structured_llm = llm.with_structured_output(DocumentAnalysis)\n",
        "```\n",
        "\n",
        "**ä¼˜åŠ¿ï¼š**\n",
        "- è‡ªåŠ¨ç±»å‹éªŒè¯\n",
        "- æ¸…æ™°çš„æ•°æ®ç»“æ„\n",
        "- æ˜“äºåºåˆ—åŒ–\n",
        "- ä¸LLMæ— ç¼é›†æˆ\n",
        "\n",
        "#### 2. LCELï¼ˆLangChain Expression Languageï¼‰\n",
        "\n",
        "```python\n",
        "# ä½¿ç”¨ç®¡é“ç¬¦è¿æ¥ç»„ä»¶\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# ä¼˜é›…ç®€æ´\n",
        "result = chain.invoke(input_data)\n",
        "```\n",
        "\n",
        "**ä¼˜åŠ¿ï¼š**\n",
        "- ä»£ç ç®€æ´æ˜“è¯»\n",
        "- ç»„ä»¶å¯å¤ç”¨\n",
        "- æ”¯æŒæµå¼å¤„ç†\n",
        "- è‡ªåŠ¨æ•°æ®æµè½¬\n",
        "\n",
        "#### 3. batch()æ‰¹é‡å¤„ç†\n",
        "\n",
        "```python\n",
        "results = chain.batch(\n",
        "    inputs,\n",
        "    config={\"max_concurrency\": 3}\n",
        ")\n",
        "```\n",
        "\n",
        "**å¯¹æ¯”ä¸²è¡Œå¤„ç†ï¼š**\n",
        "- ä¸²è¡Œ: 5æ–‡æ¡£ Ã— 2ç§’/ç¯‡ = 10ç§’\n",
        "- å¹¶è¡Œ(3å¹¶å‘): çº¦ 4ç§’ï¼ˆèŠ‚çœ60%æ—¶é—´ï¼‰\n",
        "\n",
        "### ğŸ’¡ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥\n",
        "\n",
        "#### 1. å¹¶å‘æ§åˆ¶\n",
        "\n",
        "```python\n",
        "config={\"max_concurrency\": 3}\n",
        "```\n",
        "\n",
        "**åŸå› ï¼š**\n",
        "- é¿å…APIé™æµ\n",
        "- æ§åˆ¶èµ„æºæ¶ˆè€—\n",
        "- å¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§\n",
        "\n",
        "**æ¨èå€¼ï¼š**\n",
        "- OpenAI: 3-5\n",
        "- è‡ªå»ºæœåŠ¡: 10+\n",
        "\n",
        "#### 2. æ‰¹é‡å¤§å°\n",
        "\n",
        "**å»ºè®®ï¼š**\n",
        "- å°æ‰¹é‡(10-50): å¿«é€Ÿåé¦ˆ\n",
        "- å¤§æ‰¹é‡(100+): ä½¿ç”¨batch_as_completed()æµå¼å¤„ç†\n",
        "\n",
        "#### 3. é”™è¯¯å¤„ç†\n",
        "\n",
        "```python\n",
        "# ä½¿ç”¨try-exceptåŒ…è£¹batch\n",
        "try:\n",
        "    results = chain.batch(inputs, config={\"max_concurrency\": 3})\n",
        "except Exception as e:\n",
        "    # å¤„ç†å¤±è´¥çš„æ–‡æ¡£\n",
        "    pass\n",
        "```\n",
        "\n",
        "### ğŸš€ æ‰©å±•æ–¹å‘\n",
        "\n",
        "#### 1. æ›´å¤æ‚çš„åˆ†æ\n",
        "\n",
        "```python\n",
        "class AdvancedAnalysis(BaseModel):\n",
        "    entities: List[str] = Field(description=\"å‘½åå®ä½“\")\n",
        "    relationships: List[dict] = Field(description=\"å®ä½“å…³ç³»\")\n",
        "    citations: List[str] = Field(description=\"å¼•ç”¨æ¥æº\")\n",
        "    confidence_score: float = Field(description=\"åˆ†æç½®ä¿¡åº¦\")\n",
        "```\n",
        "\n",
        "#### 2. å¤šæ­¥éª¤å¤„ç†\n",
        "\n",
        "```python\n",
        "# æ­¥éª¤1ï¼šæå–\n",
        "extraction_chain = extract_prompt | llm | ExtractSchema\n",
        "\n",
        "# æ­¥éª¤2ï¼šåˆ†æ\n",
        "analysis_chain = analysis_prompt | llm | AnalysisSchema\n",
        "\n",
        "# ç»„åˆ\n",
        "full_chain = extraction_chain | analysis_chain\n",
        "```\n",
        "\n",
        "#### 3. æµå¼å¤„ç†å¤§æ–‡ä»¶\n",
        "\n",
        "```python\n",
        "# å¯¹äºè¶…é•¿æ–‡æ¡£\n",
        "for chunk in split_document(long_doc):\n",
        "    chunk_result = analysis_chain.invoke(chunk)\n",
        "    # åˆå¹¶ç»“æœ\n",
        "```\n",
        "\n",
        "###ğŸ“Š åº”ç”¨åœºæ™¯\n",
        "\n",
        "1. **å†…å®¹ç®¡ç†ç³»ç»Ÿ**\n",
        "   - è‡ªåŠ¨æ ‡æ³¨å’Œåˆ†ç±»\n",
        "   - ç”Ÿæˆå…ƒæ•°æ®\n",
        "   - æ„å»ºæœç´¢ç´¢å¼•\n",
        "\n",
        "2. **æ•°æ®åˆ†æ**\n",
        "   - æ‰¹é‡å¤„ç†è°ƒç ”æŠ¥å‘Š\n",
        "   - æå–å…³é”®æŒ‡æ ‡\n",
        "   - è¶‹åŠ¿åˆ†æ\n",
        "\n",
        "3. **åˆè§„å®¡æŸ¥**\n",
        "   - æ‰¹é‡å®¡æ ¸æ–‡æ¡£\n",
        "   - æ£€æµ‹æ•æ„Ÿä¿¡æ¯\n",
        "   - ç”Ÿæˆå®¡æ ¸æŠ¥å‘Š\n",
        "\n",
        "4. **çŸ¥è¯†ç®¡ç†**\n",
        "   - è‡ªåŠ¨æ‘˜è¦ç”Ÿæˆ\n",
        "   - å…³é”®è¯æå–\n",
        "   - çŸ¥è¯†å›¾è°±æ„å»º\n",
        "\n",
        "### âš ï¸ æ³¨æ„äº‹é¡¹\n",
        "\n",
        "#### Q1: batch()å¤±è´¥æ€ä¹ˆåŠï¼Ÿ\n",
        "\n",
        "**A:** ä½¿ç”¨é”™è¯¯å¤„ç†\n",
        "```python\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "# æ–¹æ¡ˆ1ï¼šå¿½ç•¥é”™è¯¯\n",
        "config = RunnableConfig(max_concurrency=3, return_exceptions=True)\n",
        "\n",
        "# æ–¹æ¡ˆ2ï¼šé‡è¯•æœºåˆ¶\n",
        "# è‡ªè¡Œå®ç°é‡è¯•é€»è¾‘\n",
        "```\n",
        "\n",
        "#### Q2: å¦‚ä½•å¤„ç†ä¸åŒé•¿åº¦çš„æ–‡æ¡£ï¼Ÿ\n",
        "\n",
        "**A:** åˆ†ç»„å¤„ç†\n",
        "```python\n",
        "short_docs = [d for d in docs if len(d[\"content\"]) < 1000]\n",
        "long_docs = [d for d in docs if len(d[\"content\"]) >= 1000]\n",
        "\n",
        "# åˆ†åˆ«å¤„ç†\n",
        "short_results = chain.batch(short_docs, config={\"max_concurrency\": 5})\n",
        "long_results = chain.batch(long_docs, config={\"max_concurrency\": 2})\n",
        "```\n",
        "\n",
        "#### Q3: ç»“æ„åŒ–è¾“å‡ºéªŒè¯å¤±è´¥ï¼Ÿ\n",
        "\n",
        "**A:** æ·»åŠ é‡è¯•æˆ–é™çº§\n",
        "```python\n",
        "# æ–¹æ¡ˆ1ï¼šä½¿ç”¨ToolStrategyåŒ…è£…\n",
        "from langchain.agents import ToolStrategy\n",
        "\n",
        "response_format = ToolStrategy(\n",
        "    DocumentAnalysis,\n",
        "    retries=2  # è‡ªåŠ¨é‡è¯•\n",
        ")\n",
        "\n",
        "# æ–¹æ¡ˆ2ï¼šé™çº§åˆ°æ–‡æœ¬è¾“å‡º\n",
        "try:\n",
        "    result = structured_llm.invoke(input)\n",
        "except ValidationError:\n",
        "    result = llm.invoke(input)  # é™çº§åˆ°æ™®é€šLLM\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## å…³é”®æ”¶è·\n",
        "\n",
        "âœ… **Pydantic = ç±»å‹å®‰å…¨** - ç¡®ä¿è¾“å‡ºæ ¼å¼ä¸€è‡´æ€§\n",
        "\n",
        "âœ… **LCEL = ä¼˜é›…ç»„åˆ** - å‡½æ•°å¼ç¼–ç¨‹é£æ ¼\n",
        "\n",
        "âœ… **batch() = é«˜æ•ˆå¹¶è¡Œ** - å¤§å¹…æå‡å¤„ç†é€Ÿåº¦\n",
        "\n",
        "âœ… **max_concurrency = èµ„æºæ§åˆ¶** - é¿å…é™æµ\n",
        "\n",
        "âœ… **ç»“æ„åŒ–æ•°æ® = æ˜“äºå¤„ç†** - ä¸‹æ¸¸ç³»ç»Ÿç›´æ¥ä½¿ç”¨\n",
        "\n",
        "---\n",
        "\n",
        "## ä¸‰ä¸ªé¡¹ç›®å¯¹æ¯”\n",
        "\n",
        "| ç‰¹æ€§ | ç¬¬23ç« ï¼ˆRAGï¼‰ | ç¬¬24ç« ï¼ˆChatbotï¼‰ | ç¬¬25ç« ï¼ˆæ–‡æ¡£åˆ†æï¼‰ |\n",
        "|------|--------------|------------------|-------------------|\n",
        "| **ç›®æ ‡** | é—®ç­” | å¯¹è¯ | æ‰¹é‡åˆ†æ |\n",
        "| **è¾“å…¥** | å•ä¸ªé—®é¢˜ | å¤šè½®å¯¹è¯ | æ‰¹é‡æ–‡æ¡£ |\n",
        "| **è¾“å‡º** | è‡ªç„¶è¯­è¨€ | è‡ªç„¶è¯­è¨€ | ç»“æ„åŒ–æ•°æ® |\n",
        "| **çŠ¶æ€** | æ— çŠ¶æ€ | æœ‰çŠ¶æ€ | æ— çŠ¶æ€ |\n",
        "| **æ ¸å¿ƒæŠ€æœ¯** | Retriever | Checkpointer | batch() + Pydantic |\n",
        "| **å¹¶å‘** | ä¸²è¡Œ | ä¸²è¡Œ | å¹¶è¡Œ |\n",
        "\n",
        "ğŸ‰ æ­å–œï¼ä½ å·²ç»æŒæ¡äº†LangChainåº”ç”¨å¼€å‘çš„ä¸‰å¤§æ ¸å¿ƒåœºæ™¯ï¼\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
