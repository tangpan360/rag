{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 第10章：RAG进阶（Agentic RAG）\n",
        "\n",
        "## 学习目标\n",
        "\n",
        "本章将学习：\n",
        "1. Agentic RAG vs 2-Step RAG的区别\n",
        "2. Agent动态决策何时检索\n",
        "3. 使用@tool创建retriever工具\n",
        "4. RAG Agent的构建（create_agent）\n",
        "5. 多数据源RAG（多个知识库）\n",
        "6. 查询改写和优化技术\n",
        "7. Hybrid RAG模式简介\n",
        "\n",
        "## RAG的三种架构\n",
        "\n",
        "### 1. 2-Step RAG（两步RAG）\n",
        "- 固定流程：总是先检索，再生成\n",
        "- 控制性强，延迟可预测\n",
        "- 适合：FAQ、文档问答\n",
        "\n",
        "### 2. Agentic RAG（智能体RAG）\n",
        "- Agent决定何时检索\n",
        "- 灵活性高，可多次检索\n",
        "- 适合：复杂推理、多工具场景\n",
        "\n",
        "### 3. Hybrid RAG（混合RAG）\n",
        "- 结合两者优势\n",
        "- 包含查询优化、结果验证等中间步骤\n",
        "- 适合：需要质量控制的场景\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "环境配置完成！\n",
            "Chat模型: gpt-4.1-mini\n",
            "Embedding模型: text-embedding-3-small\n"
          ]
        }
      ],
      "source": [
        "# 环境配置\n",
        "import os\n",
        "import sys\n",
        "\n",
        "_project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "sys.path.append(_project_root)\n",
        "\n",
        "from config import config\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.documents import Document\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import create_agent\n",
        "\n",
        "# 初始化模型\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    temperature=0,\n",
        "    api_key=config.CLOUD_API_KEY,\n",
        "    base_url=config.CLOUD_BASE_URL,\n",
        ")\n",
        "\n",
        "# 配置Embedding模型\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    api_key=config.CLOUD_API_KEY,\n",
        "    base_url=config.CLOUD_BASE_URL\n",
        ")\n",
        "\n",
        "print(\"环境配置完成！\")\n",
        "print(f\"Chat模型: {model.model_name}\")\n",
        "print(f\"Embedding模型: {embeddings.model}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【准备知识库】\n",
            "\n",
            "知识库已创建，包含 5 个文档\n"
          ]
        }
      ],
      "source": [
        "### 1.1 准备知识库\n",
        "\n",
        "print(\"【准备知识库】\")\n",
        "print()\n",
        "\n",
        "# 创建知识库文档\n",
        "documents = [\n",
        "    Document(page_content=\"LangChain是一个用于构建LLM应用的框架，提供了丰富的工具和组件。\", metadata={\"source\": \"langchain_intro\"}),\n",
        "    Document(page_content=\"Agent可以自主决策使用哪些工具，适合复杂的多步骤任务。\", metadata={\"source\": \"agent_guide\"}),\n",
        "    Document(page_content=\"RAG技术通过检索外部知识来增强LLM的回答能力。\", metadata={\"source\": \"rag_guide\"}),\n",
        "    Document(page_content=\"LCEL使用管道操作符|连接组件，构建复杂的处理链。\", metadata={\"source\": \"lcel_guide\"}),\n",
        "    Document(page_content=\"Tool Calling让LLM能够调用外部工具和API。\", metadata={\"source\": \"tools_guide\"}),\n",
        "]\n",
        "\n",
        "# 创建向量存储\n",
        "vector_store = InMemoryVectorStore(embeddings)\n",
        "vector_store.add_documents(documents)\n",
        "\n",
        "print(f\"知识库已创建，包含 {len(documents)} 个文档\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Agentic RAG vs 2-Step RAG\n",
        "\n",
        "### 核心区别\n",
        "\n",
        "| 特性 | 2-Step RAG | Agentic RAG |\n",
        "|------|-----------|-------------|\n",
        "| 检索时机 | 总是检索 | Agent决定 |\n",
        "| LLM调用次数 | 1次 | 多次（可变） |\n",
        "| 控制性 | 高 | 低 |\n",
        "| 灵活性 | 低 | 高 |\n",
        "| 延迟 | 可预测 | 可变 |\n",
        "| 适用场景 | 简单问答 | 复杂推理 |\n",
        "\n",
        "### Agentic RAG的优势\n",
        "\n",
        "- 只在需要时检索（节省成本）\n",
        "- 可以多次检索（深度探索）\n",
        "- 能处理问候、闲聊等不需要检索的场景\n",
        "- Agent可以优化查询词\n",
        "\n",
        "### Agentic RAG的劣势\n",
        "\n",
        "- 需要多次LLM调用（成本高）\n",
        "- 可能跳过必要的检索\n",
        "- 延迟不可预测"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 创建Retriever工具\n",
        "\n",
        "将Retriever包装成Tool，让Agent可以调用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【创建Retriever工具】\n",
            "\n",
            "工具名称: retrieve_knowledge\n",
            "工具描述: 从知识库中检索相关信息。用于回答关于LangChain、RAG、Agent等技术问题。\n",
            "\n",
            "检索结果:\n",
            "来源: rag_guide\n",
            "内容: RAG技术通过检索外部知识来增强LLM的回答能力。\n",
            "\n",
            "来源: langchain_intro\n",
            "内容: LangChain是一个用于构建LLM应用的框架，提供了丰富的工具和组件。\n"
          ]
        }
      ],
      "source": [
        "print(\"【创建Retriever工具】\")\n",
        "print()\n",
        "\n",
        "# 方式1：使用@tool装饰器包装retriever\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve_knowledge(query: str):\n",
        "    \"\"\"从知识库中检索相关信息。用于回答关于LangChain、RAG、Agent等技术问题。\"\"\"\n",
        "    docs = vector_store.similarity_search(query, k=2)\n",
        "    # 格式化为字符串\n",
        "    content = \"\\n\\n\".join(\n",
        "        f\"来源: {doc.metadata['source']}\\n内容: {doc.page_content}\"\n",
        "        for doc in docs\n",
        "    )\n",
        "    return content, docs  # content给LLM，docs作为artifact\n",
        "\n",
        "# 测试工具\n",
        "print(\"工具名称:\", retrieve_knowledge.name)\n",
        "print(\"工具描述:\", retrieve_knowledge.description)\n",
        "print()\n",
        "\n",
        "# 直接调用测试\n",
        "result = retrieve_knowledge.invoke({\"query\": \"什么是RAG？\"})\n",
        "print(\"检索结果:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 4. 构建Agentic RAG\n",
        "\n",
        "使用`create_agent`创建能够自主决策何时检索的Agent。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【构建Agentic RAG】\n",
            "\n",
            "Agentic RAG已创建！\n",
            "可用工具: ['retrieve_knowledge']\n"
          ]
        }
      ],
      "source": [
        "print(\"【构建Agentic RAG】\")\n",
        "print()\n",
        "\n",
        "# 创建Agent\n",
        "tools = [retrieve_knowledge]\n",
        "system_prompt = \"\"\"你是一个AI助手，可以使用工具来检索知识库。\n",
        "\n",
        "使用指南：\n",
        "- 如果用户问候或闲聊，直接回答，不需要检索\n",
        "- 如果问题需要知识库信息，使用retrieve_knowledge工具\n",
        "- 如果第一次检索不够，可以再次检索\n",
        "- 基于检索结果回答问题，并引用来源\n",
        "\"\"\"\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=tools,\n",
        "    system_prompt=system_prompt\n",
        ")\n",
        "\n",
        "print(\"Agentic RAG已创建！\")\n",
        "print(f\"可用工具: {[t.name for t in tools]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 测试场景1：不需要检索的问题"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【测试：问候】\n",
            "\n",
            "用户: 你好！\n",
            "Agent: 你好！有什么我可以帮您的吗？\n",
            "\n",
            "是否调用工具: 否\n"
          ]
        }
      ],
      "source": [
        "print(\"【测试：问候】\")\n",
        "print()\n",
        "\n",
        "# Agent应该直接回答，不调用工具\n",
        "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"你好！\"}]})\n",
        "\n",
        "print(\"用户: 你好！\")\n",
        "print(f\"Agent: {response['messages'][-1].content}\")\n",
        "print()\n",
        "\n",
        "# 检查是否调用了工具\n",
        "tool_calls = [msg for msg in response['messages'] if hasattr(msg, 'tool_calls') and msg.tool_calls]\n",
        "print(f\"是否调用工具: {'是' if tool_calls else '否'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 测试场景2：需要检索的问题"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【测试：需要检索的问题】\n",
            "\n",
            "用户: 什么是RAG技术？\n",
            "\n",
            "[HumanMessage]: 什么是RAG技术？...\n",
            "[Tool Call]: retrieve_knowledge(query='什么是RAG技术')\n",
            "[ToolMessage]: 来源: rag_guide\n",
            "内容: RAG技术通过检索外部知识来增强LLM的回答能力。\n",
            "\n",
            "来源: agent_guide\n",
            "内容: Agent可以自主决策使用哪些工具，适合复杂的多步骤任务。...\n",
            "[AIMessage]: RAG技术（Retrieval-Augmented Generation）是一种通过检索外部知识来增强大型语言模型（LLM）回答能力的技术。它结合了检索和生成的能力，使模型能够利用外部知识库中的信息，提供更准确和丰富的回答。...\n",
            "\n",
            "最终回答: RAG技术（Retrieval-Augmented Generation）是一种通过检索外部知识来增强大型语言模型（LLM）回答能力的技术。它结合了检索和生成的能力，使模型能够利用外部知识库中的信息，提供更准确和丰富的回答。\n"
          ]
        }
      ],
      "source": [
        "print(\"【测试：需要检索的问题】\")\n",
        "print()\n",
        "\n",
        "# Agent应该调用retrieve_knowledge工具\n",
        "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"什么是RAG技术？\"}]})\n",
        "\n",
        "print(\"用户: 什么是RAG技术？\")\n",
        "print()\n",
        "\n",
        "# 显示完整的交互过程\n",
        "for i, msg in enumerate(response['messages']):\n",
        "    if hasattr(msg, 'content') and msg.content:\n",
        "        role = msg.__class__.__name__\n",
        "        print(f\"[{role}]: {msg.content[:200]}...\")\n",
        "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
        "        print(f\"[Tool Call]: {msg.tool_calls[0]['name']}(query='{msg.tool_calls[0]['args']['query']}')\")\n",
        "\n",
        "print()\n",
        "print(f\"最终回答: {response['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 测试场景3：需要多次检索的复杂问题"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【测试：复杂问题（可能多次检索）】\n",
            "\n",
            "用户: Agent和LCEL分别是什么？它们有什么关系？\n",
            "\n",
            "工具调用次数: 1\n",
            "\n",
            "最终回答: Agent是LangChain框架中的一个概念，指的是能够根据用户输入自动选择和调用不同工具或组件来完成任务的智能体。它可以理解用户意图，动态地决定调用哪些工具，从而实现复杂的任务处理。\n",
            "\n",
            "LCEL（LangChain Execution Language）是LangChain中用于构建复杂处理链的语言或机制。它通过使用管道操作符和连接组件，帮助开发者构建复杂的处理流程链条，实现多步骤的数据处理和任务执行。\n",
            "\n",
            "它们的关系是：Agent作为智能体，可能会利用LCEL构建的复杂处理链来完成任务。LCEL提供了构建复杂处理流程的能力，而Agent则是利用这些流程和工具来智能地响应用户请求的执行者。\n",
            "\n",
            "总结：\n",
            "- Agent是智能体，负责理解和执行任务，调用工具。\n",
            "- LCEL是构建复杂处理链的语言或机制。\n",
            "- Agent可能会使用LCEL构建的处理链来完成任务。\n",
            "\n",
            "以上信息来源于LangChain相关知识库。\n"
          ]
        }
      ],
      "source": [
        "print(\"【测试：复杂问题（可能多次检索）】\")\n",
        "print()\n",
        "\n",
        "# Agent可能会多次调用工具\n",
        "query = \"Agent和LCEL分别是什么？它们有什么关系？\"\n",
        "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
        "\n",
        "print(f\"用户: {query}\")\n",
        "print()\n",
        "\n",
        "# 统计工具调用次数\n",
        "tool_call_count = sum(1 for msg in response['messages'] if hasattr(msg, 'tool_calls') and msg.tool_calls)\n",
        "print(f\"工具调用次数: {tool_call_count}\")\n",
        "print()\n",
        "print(f\"最终回答: {response['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 多数据源RAG\n",
        "\n",
        "为不同的知识库创建不同的检索工具。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【多数据源RAG】\n",
            "\n",
            "多数据源Agent已创建！\n",
            "可用工具: ['retrieve_knowledge', 'retrieve_python_docs']\n"
          ]
        }
      ],
      "source": [
        "print(\"【多数据源RAG】\")\n",
        "print()\n",
        "\n",
        "# 创建第二个知识库（Python编程）\n",
        "python_docs = [\n",
        "    Document(page_content=\"Python是一种高级编程语言，以简洁和可读性著称。\", metadata={\"source\": \"python_intro\"}),\n",
        "    Document(page_content=\"列表推导式是Python的特色语法，用于快速创建列表。\", metadata={\"source\": \"python_features\"}),\n",
        "    Document(page_content=\"装饰器是Python的高级特性，用于修改函数行为。\", metadata={\"source\": \"python_advanced\"}),\n",
        "]\n",
        "\n",
        "python_vector_store = InMemoryVectorStore(embeddings)\n",
        "python_vector_store.add_documents(python_docs)\n",
        "\n",
        "# 为Python知识库创建工具\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve_python_docs(query: str):\n",
        "    \"\"\"从Python编程知识库中检索信息。用于回答Python语言相关问题。\"\"\"\n",
        "    docs = python_vector_store.similarity_search(query, k=2)\n",
        "    content = \"\\n\\n\".join(\n",
        "        f\"来源: {doc.metadata['source']}\\n内容: {doc.page_content}\"\n",
        "        for doc in docs\n",
        "    )\n",
        "    return content, docs\n",
        "\n",
        "# 创建多工具Agent\n",
        "multi_tools = [retrieve_knowledge, retrieve_python_docs]\n",
        "multi_system_prompt = \"\"\"你是一个AI助手，可以访问两个知识库：\n",
        "1. LangChain知识库（retrieve_knowledge）：关于LangChain、RAG、Agent等\n",
        "2. Python知识库（retrieve_python_docs）：关于Python编程\n",
        "\n",
        "根据问题选择合适的工具，或同时使用多个工具。\n",
        "\"\"\"\n",
        "\n",
        "multi_agent = create_agent(\n",
        "    model=model,\n",
        "    tools=multi_tools,\n",
        "    system_prompt=multi_system_prompt\n",
        ")\n",
        "\n",
        "print(f\"多数据源Agent已创建！\")\n",
        "print(f\"可用工具: {[t.name for t in multi_tools]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 测试多数据源检索"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【测试：跨知识库问题】\n",
            "\n",
            "用户: Python的装饰器是什么？\n",
            "\n",
            "调用工具: retrieve_python_docs\n",
            "\n",
            "回答: Python的装饰器是一种高级特性，用于修改函数的行为。装饰器本质上是一个函数，它接受另一个函数作为参数，并返回一个新的函数，从而在不改变原函数代码的情况下，动态地增加或修改函数的功能。装饰器常用于日志记录、权限校验、性能测试等场景。你需要我详细讲解装饰器的用法和示例吗？\n"
          ]
        }
      ],
      "source": [
        "print(\"【测试：跨知识库问题】\")\n",
        "print()\n",
        "\n",
        "# Agent需要选择正确的工具\n",
        "query = \"Python的装饰器是什么？\"\n",
        "response = multi_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
        "\n",
        "print(f\"用户: {query}\")\n",
        "print()\n",
        "\n",
        "# 显示使用了哪个工具\n",
        "for msg in response['messages']:\n",
        "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
        "        for tc in msg.tool_calls:\n",
        "            print(f\"调用工具: {tc['name']}\")\n",
        "\n",
        "print()\n",
        "print(f\"回答: {response['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 查询改写与优化（Hybrid RAG）\n",
        "\n",
        "Hybrid RAG在检索前对查询进行优化，提高检索质量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【查询改写】\n",
            "\n",
            "原始查询: 能不能告诉我RAG到底是啥东西？\n",
            "改写查询: RAG技术定义及应用\n",
            "\n",
            "使用原始查询检索:\n",
            "  - rag_guide: RAG技术通过检索外部知识来增强LLM的回答能力。...\n",
            "  - langchain_intro: LangChain是一个用于构建LLM应用的框架，提供了丰富的工具和组件。...\n",
            "\n",
            "使用改写查询检索:\n",
            "  - rag_guide: RAG技术通过检索外部知识来增强LLM的回答能力。...\n",
            "  - tools_guide: Tool Calling让LLM能够调用外部工具和API。...\n"
          ]
        }
      ],
      "source": [
        "print(\"【查询改写】\")\n",
        "print()\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# 定义查询改写的输出结构\n",
        "class RewrittenQuery(BaseModel):\n",
        "    query: str\n",
        "\n",
        "# 创建查询改写函数\n",
        "def rewrite_query(original_query: str) -> str:\n",
        "    \"\"\"将用户查询改写为更适合检索的形式\"\"\"\n",
        "    system_prompt = \"\"\"你是查询优化专家。将用户的问题改写为更适合向量检索的形式。\n",
        "    \n",
        "改写原则：\n",
        "- 提取关键概念和术语\n",
        "- 去除口语化表达\n",
        "- 保留核心语义\n",
        "- 简洁明确\n",
        "\n",
        "只返回改写后的查询，不要解释。\"\"\"\n",
        "    \n",
        "    response = model.with_structured_output(RewrittenQuery).invoke([\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": original_query}\n",
        "    ])\n",
        "    return response.query\n",
        "\n",
        "# 测试查询改写\n",
        "original = \"能不能告诉我RAG到底是啥东西？\"\n",
        "rewritten = rewrite_query(original)\n",
        "\n",
        "print(f\"原始查询: {original}\")\n",
        "print(f\"改写查询: {rewritten}\")\n",
        "print()\n",
        "\n",
        "# 对比检索效果\n",
        "print(\"使用原始查询检索:\")\n",
        "docs1 = vector_store.similarity_search(original, k=2)\n",
        "for doc in docs1:\n",
        "    print(f\"  - {doc.metadata['source']}: {doc.page_content[:50]}...\")\n",
        "\n",
        "print()\n",
        "print(\"使用改写查询检索:\")\n",
        "docs2 = vector_store.similarity_search(rewritten, k=2)\n",
        "for doc in docs2:\n",
        "    print(f\"  - {doc.metadata['source']}: {doc.page_content[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 实战项目：智能RAG系统\n",
        "\n",
        "构建一个完整的Hybrid RAG系统，结合查询改写和Agentic检索。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【智能RAG系统】\n",
            "\n",
            "智能RAG系统已创建！\n"
          ]
        }
      ],
      "source": [
        "print(\"【智能RAG系统】\")\n",
        "print()\n",
        "\n",
        "class SmartRAGSystem:\n",
        "    \"\"\"结合查询优化和Agentic检索的智能RAG系统\"\"\"\n",
        "    \n",
        "    def __init__(self, model, vector_store, embeddings):\n",
        "        self.model = model\n",
        "        self.vector_store = vector_store\n",
        "        self.embeddings = embeddings\n",
        "        self.setup_tools()\n",
        "        self.setup_agent()\n",
        "    \n",
        "    def rewrite_query(self, query: str) -> str:\n",
        "        \"\"\"查询改写\"\"\"\n",
        "        system_prompt = \"\"\"改写查询使其更适合检索。提取关键词，去除口语化。\"\"\"\n",
        "        response = self.model.with_structured_output(RewrittenQuery).invoke([\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": query}\n",
        "        ])\n",
        "        return response.query\n",
        "    \n",
        "    def setup_tools(self):\n",
        "        \"\"\"创建检索工具（带查询优化）\"\"\"\n",
        "        @tool(response_format=\"content_and_artifact\")\n",
        "        def smart_retrieve(query: str):\n",
        "            \"\"\"智能检索工具：自动优化查询并检索相关信息\"\"\"\n",
        "            # 查询改写\n",
        "            optimized_query = self.rewrite_query(query)\n",
        "            \n",
        "            # 检索\n",
        "            docs = self.vector_store.similarity_search(optimized_query, k=3)\n",
        "            \n",
        "            # 格式化\n",
        "            content = f\"[查询优化: {query} -> {optimized_query}]\\n\\n\"\n",
        "            content += \"\\n\\n\".join(\n",
        "                f\"来源: {doc.metadata['source']}\\n{doc.page_content}\"\n",
        "                for doc in docs\n",
        "            )\n",
        "            return content, docs\n",
        "        \n",
        "        self.tools = [smart_retrieve]\n",
        "    \n",
        "    def setup_agent(self):\n",
        "        \"\"\"创建Agent\"\"\"\n",
        "        system_prompt = \"\"\"你是智能问答助手。\n",
        "\n",
        "使用smart_retrieve工具检索知识库（工具会自动优化查询）。\n",
        "基于检索结果回答问题，并说明信息来源。\n",
        "如果是问候或闲聊，直接回答。\"\"\"\n",
        "        \n",
        "        self.agent = create_agent(\n",
        "            model=self.model,\n",
        "            tools=self.tools,\n",
        "            system_prompt=system_prompt\n",
        "        )\n",
        "    \n",
        "    def query(self, question: str):\n",
        "        \"\"\"处理用户查询\"\"\"\n",
        "        response = self.agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": question}]})\n",
        "        return response['messages'][-1].content\n",
        "\n",
        "# 创建系统\n",
        "rag_system = SmartRAGSystem(model, vector_store, embeddings)\n",
        "print(\"智能RAG系统已创建！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 测试智能RAG系统"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【测试智能RAG系统】\n",
            "\n",
            "问题: 能不能跟我说说RAG是啥？\n",
            "回答: RAG（Retrieval-Augmented Generation）是一种技术，通过检索外部知识库中的信息来增强大型语言模型（LLM）的回答能力。简单来说，RAG结合了检索（Retrieval）和生成（Generation）两部分：先从外部知识库中检索相关信息，再基于这些信息生成更准确和丰富的回答。这种方法可以让模型在面对需要具体知识的问题时，提供更可靠和详细的答案。\n",
            "\n",
            "信息来源于rag_guide中的相关介绍。\n",
            "------------------------------------------------------------\n",
            "\n",
            "问题: Agent和普通的LLM有啥区别？\n",
            "回答: Agent和普通的LLM（大型语言模型）主要区别在于Agent具备调用外部工具和执行多步骤任务的能力，而普通的LLM主要是基于输入文本生成响应。\n",
            "\n",
            "具体来说：\n",
            "- 普通的LLM主要通过理解和生成文本来回答问题或完成任务，能力局限于模型本身的训练数据和推理能力。\n",
            "- Agent则是在LLM基础上，结合了工具调用（Tool Calling）和多步骤推理的能力，可以主动调用外部API、数据库、检索系统等工具，完成更复杂的任务。例如，Agent可以先检索信息，再基于检索结果生成回答，或者调用计算工具进行计算。\n",
            "\n",
            "这种设计使得Agent能够处理更复杂和动态的任务，扩展了LLM的应用场景。\n",
            "\n",
            "信息来源包括LangChain框架介绍、RAG技术和工具调用相关资料。\n",
            "------------------------------------------------------------\n",
            "\n",
            "问题: 你好！\n",
            "回答: 你好！有什么我可以帮您的吗？\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"【测试智能RAG系统】\")\n",
        "print()\n",
        "\n",
        "# 测试1：口语化问题\n",
        "test_queries = [\n",
        "    \"能不能跟我说说RAG是啥？\",\n",
        "    \"Agent和普通的LLM有啥区别？\",\n",
        "    \"你好！\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"问题: {query}\")\n",
        "    answer = rag_system.query(query)\n",
        "    print(f\"回答: {answer}\")\n",
        "    print(\"-\" * 60)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. RAG架构对比总结\n",
        "\n",
        "### 三种架构的选择指南\n",
        "\n",
        "| 场景 | 推荐架构 | 原因 |\n",
        "|------|---------|------|\n",
        "| FAQ系统 | 2-Step RAG | 每个问题都需要检索，延迟可预测 |\n",
        "| 文档问答 | 2-Step RAG | 简单高效，成本低 |\n",
        "| 智能客服 | Agentic RAG | 需要处理闲聊和问答 |\n",
        "| 复杂研究助手 | Agentic RAG | 需要多次检索和推理 |\n",
        "| 多数据源查询 | Agentic RAG | Agent选择合适的数据源 |\n",
        "| 需要高质量 | Hybrid RAG | 查询优化提高检索质量 |\n",
        "| 对话式应用 | Agentic RAG | 灵活处理上下文 |\n",
        "\n",
        "### 性能对比\n",
        "\n",
        "**2-Step RAG:**\n",
        "- LLM调用：1次\n",
        "- 延迟：低（约1-2秒）\n",
        "- 成本：低\n",
        "- 控制性：高\n",
        "\n",
        "**Agentic RAG:**\n",
        "- LLM调用：2-5次（可变）\n",
        "- 延迟：中高（约3-10秒）\n",
        "- 成本：中高\n",
        "- 灵活性：高\n",
        "\n",
        "**Hybrid RAG:**\n",
        "- LLM调用：2-3次\n",
        "- 延迟：中（约2-5秒）\n",
        "- 成本：中\n",
        "- 质量：最高\n",
        "\n",
        "### 实施建议\n",
        "\n",
        "1. 从2-Step RAG开始（简单场景）\n",
        "2. 如果需要灵活性，升级到Agentic RAG\n",
        "3. 如果检索质量不够，添加查询优化（Hybrid）\n",
        "4. 监控成本和延迟，按需调整"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 总结与最佳实践\n",
        "\n",
        "### 核心概念回顾\n",
        "\n",
        "1. **2-Step RAG**: 固定的检索-生成流程，简单高效\n",
        "2. **Agentic RAG**: Agent动态决策何时检索，灵活但成本高\n",
        "3. **Hybrid RAG**: 结合查询优化和验证步骤，质量最高\n",
        "4. **多数据源RAG**: 为不同知识库创建不同的工具\n",
        "5. **查询改写**: 优化用户查询，提高检索质量\n",
        "\n",
        "### Agentic RAG的关键要素\n",
        "\n",
        "1. **Retriever工具**: 使用`@tool`装饰器包装检索器\n",
        "2. **response_format**: 设置为`\"content_and_artifact\"`保留原始文档\n",
        "3. **create_agent**: 创建能够使用工具的Agent\n",
        "4. **System Prompt**: 指导Agent何时使用工具\n",
        "5. **工具描述**: 清晰的描述帮助Agent选择正确工具\n",
        "\n",
        "### 最佳实践\n",
        "\n",
        "**工具设计：**\n",
        "- 工具名称要清晰（如`retrieve_knowledge`）\n",
        "- 描述要详细说明工具用途和适用场景\n",
        "- 使用`response_format=\"content_and_artifact\"`保留元数据\n",
        "- 格式化输出，包含来源信息\n",
        "\n",
        "**System Prompt：**\n",
        "- 明确告诉Agent何时使用工具\n",
        "- 说明不同工具的适用场景\n",
        "- 指导Agent如何处理检索结果\n",
        "- 提供示例和指导原则\n",
        "\n",
        "**查询优化：**\n",
        "- 提取关键词和术语\n",
        "- 去除口语化和冗余表达\n",
        "- 保持核心语义\n",
        "- 使用结构化输出确保格式\n",
        "\n",
        "**多数据源：**\n",
        "- 为每个数据源创建独立工具\n",
        "- 工具描述要明确数据源内容\n",
        "- 让Agent自主选择合适的工具\n",
        "- 可以并行调用多个工具\n",
        "\n",
        "### 性能优化\n",
        "\n",
        "1. **控制检索次数**: 在System Prompt中限制最大检索次数\n",
        "2. **缓存常见查询**: 缓存热门问题的检索结果\n",
        "3. **批量处理**: 对多个问题使用batch方法\n",
        "4. **监控成本**: 跟踪LLM调用次数和token使用\n",
        "5. **降级策略**: 高负载时切换到2-Step RAG\n",
        "\n",
        "### 常见问题与解决\n",
        "\n",
        "**问题1: Agent不调用工具**\n",
        "- 检查System Prompt是否清晰\n",
        "- 确认工具描述是否准确\n",
        "- 测试不同的问题表述\n",
        "\n",
        "**问题2: Agent过度调用工具**\n",
        "- 在System Prompt中添加限制\n",
        "- 优化工具描述，避免过于宽泛\n",
        "- 调整temperature参数\n",
        "\n",
        "**问题3: 检索质量不高**\n",
        "- 添加查询改写步骤\n",
        "- 调整检索参数（k值、相似度阈值）\n",
        "- 改进文档切分策略\n",
        "- 使用更好的Embedding模型\n",
        "\n",
        "**问题4: 延迟太高**\n",
        "- 考虑切换到2-Step RAG\n",
        "- 减少检索文档数量\n",
        "- 使用更快的模型\n",
        "- 添加缓存层\n",
        "\n",
        "**问题5: 成本太高**\n",
        "- 监控并限制工具调用次数\n",
        "- 使用更便宜的模型\n",
        "- 添加缓存减少重复调用\n",
        "- 对简单问题使用2-Step RAG\n",
        "\n",
        "### 架构选择决策树\n",
        "\n",
        "```\n",
        "问题需要检索吗？\n",
        "├─ 总是需要 → 2-Step RAG\n",
        "└─ 不一定需要\n",
        "   ├─ 只有一个数据源 → Agentic RAG\n",
        "   └─ 多个数据源 → Agentic RAG + 多工具\n",
        "   \n",
        "检索质量是否足够？\n",
        "├─ 是 → 保持当前架构\n",
        "└─ 否 → 添加查询优化（Hybrid RAG）\n",
        "\n",
        "延迟是否可接受？\n",
        "├─ 是 → 保持当前架构\n",
        "└─ 否 → 降级到2-Step RAG或优化\n",
        "```\n",
        "\n",
        "### 进阶方向\n",
        "\n",
        "1. **Self-Query**: 从自然语言中提取结构化查询条件\n",
        "2. **答案验证**: 检查生成答案的准确性和完整性\n",
        "3. **多轮对话**: 支持上下文相关的连续提问\n",
        "4. **混合检索**: 结合关键词和向量检索\n",
        "5. **评估指标**: 使用RAGAS等工具评估RAG质量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
