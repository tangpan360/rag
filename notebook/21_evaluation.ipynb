{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ç¬¬21ç« ï¼šEvaluation & Testingï¼ˆè¯„ä¼°ä¸æµ‹è¯•ï¼‰\n",
        "\n",
        "## å­¦ä¹ ç›®æ ‡\n",
        "\n",
        "æœ¬ç« å°†å­¦ä¹ ï¼š\n",
        "1. ä¸ºä»€ä¹ˆéœ€è¦è¯„ä¼°LLMåº”ç”¨\n",
        "2. è¯„ä¼° vs æµ‹è¯•çš„åŒºåˆ«\n",
        "3. åˆ›å»ºæµ‹è¯•æ•°æ®é›†\n",
        "4. RAGè¯„ä¼°æŒ‡æ ‡ï¼ˆç›¸å…³æ€§ã€å‡†ç¡®æ€§ã€å¿ å®åº¦ï¼‰\n",
        "5. Agentè¯„ä¼°æ–¹æ³•ï¼ˆè½¨è¿¹è¯„ä¼°ï¼‰\n",
        "6. LLM-as-Judgeè¯„ä¼°å™¨\n",
        "7. è‡ªå®šä¹‰è¯„ä¼°å™¨\n",
        "8. ä½¿ç”¨pytestè¿›è¡Œæµ‹è¯•\n",
        "9. è¯„ä¼°æœ€ä½³å®è·µ\n",
        "\n",
        "---\n",
        "\n",
        "## ä¸ºä»€ä¹ˆéœ€è¦è¯„ä¼°ï¼Ÿ\n",
        "\n",
        "### LLMåº”ç”¨çš„æŒ‘æˆ˜\n",
        "\n",
        "LLMè¾“å‡ºæ˜¯**éç¡®å®šæ€§**çš„ï¼Œè¿™ä½¿å¾—è¯„ä¼°è´¨é‡å˜å¾—å›°éš¾ï¼š\n",
        "\n",
        "| ä¼ ç»Ÿè½¯ä»¶ | LLMåº”ç”¨ |\n",
        "|---------|---------|\n",
        "| è¾“å…¥ç›¸åŒï¼Œè¾“å‡ºç¡®å®š | è¾“å…¥ç›¸åŒï¼Œè¾“å‡ºå¯èƒ½ä¸åŒ |\n",
        "| å¯ä»¥ç”¨å•å…ƒæµ‹è¯•éªŒè¯ | éœ€è¦è¯„ä¼°æŒ‡æ ‡è¡¡é‡ |\n",
        "| æ­£ç¡®æ€§æ˜¯äºŒå…ƒçš„ï¼ˆå¯¹/é”™ï¼‰ | è´¨é‡æ˜¯è¿ç»­çš„ï¼ˆå¥½/ä¸­/å·®ï¼‰ |\n",
        "| å®¹æ˜“è‡ªåŠ¨åŒ–æµ‹è¯• | éœ€è¦æ›´å¤æ‚çš„è¯„ä¼°æ–¹æ³• |\n",
        "\n",
        "### è¯„ä¼°çš„ä»·å€¼\n",
        "\n",
        "âœ… **ç¡®ä¿è´¨é‡** - æŒç»­ç›‘æ§ç³»ç»Ÿæ€§èƒ½  \n",
        "âœ… **å¯¹æ¯”æ–¹æ¡ˆ** - æ¯”è¾ƒä¸åŒçš„æ¨¡å‹ã€æç¤ºè¯ã€æ¶æ„  \n",
        "âœ… **å‘ç°é—®é¢˜** - åŠæ—©å‘ç°é€€åŒ–å’Œé”™è¯¯  \n",
        "âœ… **æŒ‡å¯¼ä¼˜åŒ–** - æ•°æ®é©±åŠ¨çš„æ”¹è¿›å†³ç­–  \n",
        "âœ… **å»ºç«‹ä¿¡å¿ƒ** - ä¸ºç”Ÿäº§éƒ¨ç½²æä¾›ä¾æ®\n",
        "\n",
        "---\n",
        "\n",
        "## æ ¸å¿ƒæ¦‚å¿µ\n",
        "\n",
        "### 1. è¯„ä¼° vs æµ‹è¯•\n",
        "\n",
        "| ç»´åº¦ | è¯„ä¼°ï¼ˆEvaluationï¼‰ | æµ‹è¯•ï¼ˆTestingï¼‰ |\n",
        "|------|-------------------|----------------|\n",
        "| **ç›®çš„** | è¡¡é‡æ€§èƒ½ | æ–­è¨€æ­£ç¡®æ€§ |\n",
        "| **ç»“æœ** | æŒ‡æ ‡åˆ†æ•°ï¼ˆè¿ç»­å€¼ï¼‰ | é€šè¿‡/å¤±è´¥ï¼ˆäºŒå…ƒï¼‰ |\n",
        "| **æ ‡å‡†** | ç›¸å¯¹çš„ã€å¯ä»¥æ¨¡ç³Š | ç»å¯¹çš„ã€å¿…é¡»æ˜ç¡® |\n",
        "| **ç”¨é€”** | å¯¹æ¯”ä¸åŒç‰ˆæœ¬ | ç¡®ä¿åŸºæœ¬åŠŸèƒ½ |\n",
        "| **éƒ¨ç½²** | åˆ†æ•°ä½å¯ä»¥éƒ¨ç½² | æµ‹è¯•å¤±è´¥ä¸èƒ½éƒ¨ç½² |\n",
        "\n",
        "**å…³é”®**ï¼šè¯„ä¼°æŒ‡æ ‡å¯ä»¥è½¬æ¢ä¸ºæµ‹è¯•ï¼ˆå¦‚å›å½’æµ‹è¯•ï¼šæ–°ç‰ˆæœ¬å¿…é¡»ä¼˜äºåŸºçº¿ï¼‰\n",
        "\n",
        "### 2. è¯„ä¼°å·¥ä½œæµ\n",
        "\n",
        "```\n",
        "1. åˆ›å»ºæ•°æ®é›†\n",
        "   â†“\n",
        "2. è¿è¡Œåº”ç”¨\n",
        "   â†“\n",
        "3. ä½¿ç”¨è¯„ä¼°å™¨æ‰“åˆ†\n",
        "   â†“\n",
        "4. åˆ†æç»“æœ\n",
        "   â†“\n",
        "5. è¿­ä»£æ”¹è¿›\n",
        "```\n",
        "\n",
        "### 3. è¯„ä¼°å™¨ç±»å‹\n",
        "\n",
        "| ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |\n",
        "|------|------|------|\n",
        "| **åŸºäºè§„åˆ™** | ç®€å•å‡½æ•°æ£€æŸ¥ | é•¿åº¦æ£€æŸ¥ã€æ ¼å¼éªŒè¯ |\n",
        "| **åŸºäºå‚è€ƒ** | ä¸æ ‡å‡†ç­”æ¡ˆå¯¹æ¯” | å‡†ç¡®æ€§ã€ä¸€è‡´æ€§ |\n",
        "| **LLM-as-Judge** | ç”¨LLMè¯„ä¼°è¾“å‡º | ç›¸å…³æ€§ã€æœ‰ç”¨æ€§ |\n",
        "| **äººå·¥è¯„ä¼°** | äººç±»ä¸“å®¶æ‰“åˆ† | ä¸»è§‚è´¨é‡ã€åˆ›æ„æ€§ |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ç¯å¢ƒé…ç½®å®Œæˆï¼\n",
            "æ¨¡å‹: gpt-4.1-mini\n",
            "âœ“ å‡†å¤‡å­¦ä¹ è¯„ä¼°ä¸æµ‹è¯•\n"
          ]
        }
      ],
      "source": [
        "# ç¯å¢ƒé…ç½®\n",
        "import os\n",
        "import sys\n",
        "\n",
        "_project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "sys.path.append(_project_root)\n",
        "\n",
        "from config import config\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# åˆå§‹åŒ–æ¨¡å‹\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    temperature=0,\n",
        "    api_key=config.CLOUD_API_KEY,\n",
        "    base_url=config.CLOUD_BASE_URL,\n",
        ")\n",
        "\n",
        "print(\"ç¯å¢ƒé…ç½®å®Œæˆï¼\")\n",
        "print(f\"æ¨¡å‹: {model.model_name}\")\n",
        "print(\"âœ“ å‡†å¤‡å­¦ä¹ è¯„ä¼°ä¸æµ‹è¯•\")\n",
        "\n",
        "# æ³¨æ„ï¼šæœ¬ç« é‡ç‚¹è®²è§£è¯„ä¼°æ¦‚å¿µå’Œæ–¹æ³•\n",
        "# LangSmithçš„åœ¨çº¿è¯„ä¼°åŠŸèƒ½å°†åœ¨ç¬¬22ç« è¯¦ç»†ä»‹ç»"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. åˆ›å»ºæµ‹è¯•æ•°æ®é›†\n",
        "\n",
        "### æ ¸å¿ƒä»·å€¼\n",
        "\n",
        "æµ‹è¯•æ•°æ®é›†æ˜¯è¯„ä¼°çš„åŸºç¡€ï¼ŒåŒ…å«ï¼š\n",
        "- **è¾“å…¥ï¼ˆInputsï¼‰**ï¼šé—®é¢˜æˆ–æŸ¥è¯¢\n",
        "- **é¢„æœŸè¾“å‡ºï¼ˆExpected Outputsï¼‰**ï¼šå‚è€ƒç­”æ¡ˆï¼ˆå¯é€‰ï¼‰\n",
        "- **å…ƒæ•°æ®ï¼ˆMetadataï¼‰**ï¼šé¢å¤–ä¿¡æ¯\n",
        "\n",
        "### æ•°æ®é›†ç±»å‹\n",
        "\n",
        "| ç±»å‹ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |\n",
        "|------|------|---------|\n",
        "| **Golden Dataset** | äººå·¥æ ‡æ³¨çš„é«˜è´¨é‡æ•°æ® | æ ¸å¿ƒåŠŸèƒ½æµ‹è¯• |\n",
        "| **Synthetic Dataset** | è‡ªåŠ¨ç”Ÿæˆçš„æ•°æ® | å¤§è§„æ¨¡æµ‹è¯• |\n",
        "| **Production Data** | ä»ç”Ÿäº§ç¯å¢ƒé‡‡æ · | çœŸå®åœºæ™¯æµ‹è¯• |\n",
        "\n",
        "### æ•°æ®é›†ç¤ºä¾‹\n",
        "\n",
        "```python\n",
        "# ç®€å•çš„æµ‹è¯•æ•°æ®é›†\n",
        "test_dataset = [\n",
        "    {\n",
        "        \"input\": \"ä»€ä¹ˆæ˜¯Pythonï¼Ÿ\",\n",
        "        \"expected_output\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...\",\n",
        "        \"metadata\": {\"category\": \"basic\", \"difficulty\": \"easy\"}\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"å¦‚ä½•å®‰è£…LangChainï¼Ÿ\",\n",
        "        \"expected_output\": \"ä½¿ç”¨pip install langchain...\",\n",
        "        \"metadata\": {\"category\": \"setup\", \"difficulty\": \"easy\"}\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ¼”ç¤º1ï¼šåˆ›å»ºæµ‹è¯•æ•°æ®é›†ã€‘\n",
            "\n",
            "âœ“ åˆ›å»ºäº†åŒ…å« 3 ä¸ªæ ·æœ¬çš„æµ‹è¯•æ•°æ®é›†\n",
            "\n",
            "æ ·æœ¬ 1:\n",
            "  é—®é¢˜: Pythonæ˜¯ä»€ä¹ˆç±»å‹çš„è¯­è¨€ï¼Ÿ\n",
            "  é¢„æœŸç­”æ¡ˆ: Pythonæ˜¯ä¸€ç§é«˜çº§ã€è§£é‡Šå‹ã€é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€...\n",
            "  ç±»åˆ«: basic\n",
            "\n",
            "æ ·æœ¬ 2:\n",
            "  é—®é¢˜: LangChainçš„ä¸»è¦ç”¨é€”æ˜¯ä»€ä¹ˆï¼Ÿ\n",
            "  é¢„æœŸç­”æ¡ˆ: LangChainç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åº...\n",
            "  ç±»åˆ«: framework\n",
            "\n",
            "æ ·æœ¬ 3:\n",
            "  é—®é¢˜: ä»€ä¹ˆæ˜¯RAGï¼Ÿ\n",
            "  é¢„æœŸç­”æ¡ˆ: RAGï¼ˆRetrieval Augmented Genera...\n",
            "  ç±»åˆ«: concept\n",
            "\n",
            "ğŸ’¡ æ•°æ®é›†è®¾è®¡è¦ç‚¹ï¼š\n",
            "  1. è¦†ç›–æ ¸å¿ƒåŠŸèƒ½å’Œè¾¹ç•Œæƒ…å†µ\n",
            "  2. åŒ…å«ä¸åŒéš¾åº¦å’Œç±»å‹çš„æ ·æœ¬\n",
            "  3. é¢„æœŸç­”æ¡ˆä¸éœ€è¦å®Œå…¨åŒ¹é…ï¼Œä½†è¦åŒ…å«å…³é”®ä¿¡æ¯\n",
            "  4. æ·»åŠ å…ƒæ•°æ®ä¾¿äºåˆ†ç±»åˆ†æ\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ¼”ç¤º1ï¼šåˆ›å»ºæµ‹è¯•æ•°æ®é›†ã€‘\\n\")\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªç®€å•çš„QAæµ‹è¯•æ•°æ®é›†\n",
        "qa_dataset = [\n",
        "    {\n",
        "        \"question\": \"Pythonæ˜¯ä»€ä¹ˆç±»å‹çš„è¯­è¨€ï¼Ÿ\",\n",
        "        \"expected_answer\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ã€è§£é‡Šå‹ã€é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€\",\n",
        "        \"category\": \"basic\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"LangChainçš„ä¸»è¦ç”¨é€”æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
        "        \"expected_answer\": \"LangChainç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åº\",\n",
        "        \"category\": \"framework\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"ä»€ä¹ˆæ˜¯RAGï¼Ÿ\",\n",
        "        \"expected_answer\": \"RAGï¼ˆRetrieval Augmented Generationï¼‰æ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯\",\n",
        "        \"category\": \"concept\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"âœ“ åˆ›å»ºäº†åŒ…å« {len(qa_dataset)} ä¸ªæ ·æœ¬çš„æµ‹è¯•æ•°æ®é›†\\n\")\n",
        "\n",
        "# æŸ¥çœ‹æ•°æ®é›†ç»“æ„\n",
        "for i, example in enumerate(qa_dataset, 1):\n",
        "    print(f\"æ ·æœ¬ {i}:\")\n",
        "    print(f\"  é—®é¢˜: {example['question']}\")\n",
        "    print(f\"  é¢„æœŸç­”æ¡ˆ: {example['expected_answer'][:30]}...\")\n",
        "    print(f\"  ç±»åˆ«: {example['category']}\\n\")\n",
        "\n",
        "print(\"ğŸ’¡ æ•°æ®é›†è®¾è®¡è¦ç‚¹ï¼š\")\n",
        "print(\"  1. è¦†ç›–æ ¸å¿ƒåŠŸèƒ½å’Œè¾¹ç•Œæƒ…å†µ\")\n",
        "print(\"  2. åŒ…å«ä¸åŒéš¾åº¦å’Œç±»å‹çš„æ ·æœ¬\")\n",
        "print(\"  3. é¢„æœŸç­”æ¡ˆä¸éœ€è¦å®Œå…¨åŒ¹é…ï¼Œä½†è¦åŒ…å«å…³é”®ä¿¡æ¯\")\n",
        "print(\"  4. æ·»åŠ å…ƒæ•°æ®ä¾¿äºåˆ†ç±»åˆ†æ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. åŸºäºè§„åˆ™çš„è¯„ä¼°å™¨\n",
        "\n",
        "### æ ¸å¿ƒä»·å€¼\n",
        "\n",
        "ä½¿ç”¨ç®€å•çš„Pythonå‡½æ•°æ£€æŸ¥è¾“å‡ºçš„åŸºæœ¬å±æ€§ï¼Œå¿«é€Ÿã€ç¡®å®šæ€§ã€æ— éœ€é¢å¤–æˆæœ¬ã€‚\n",
        "\n",
        "### å¸¸è§è§„åˆ™è¯„ä¼°\n",
        "\n",
        "| è¯„ä¼°é¡¹ | è¯´æ˜ | ç¤ºä¾‹ |\n",
        "|--------|------|------|\n",
        "| **é•¿åº¦æ£€æŸ¥** | è¾“å‡ºé•¿åº¦æ˜¯å¦åˆç† | ä¸èƒ½å¤ªçŸ­æˆ–å¤ªé•¿ |\n",
        "| **æ ¼å¼éªŒè¯** | æ˜¯å¦ç¬¦åˆé¢„æœŸæ ¼å¼ | JSONæ ¼å¼ã€åŒ…å«ç‰¹å®šå­—æ®µ |\n",
        "| **å…³é”®è¯æ£€æŸ¥** | æ˜¯å¦åŒ…å«å¿…éœ€å…³é”®è¯ | ç­”æ¡ˆä¸­å¿…é¡»æåˆ°\"Python\" |\n",
        "| **ç¦ç”¨è¯æ£€æŸ¥** | æ˜¯å¦åŒ…å«ä¸åº”å‡ºç°çš„è¯ | ä¸èƒ½åŒ…å«è„è¯ã€æ•æ„Ÿè¯ |\n",
        "\n",
        "### è¯„ä¼°å™¨å‡½æ•°ç­¾å\n",
        "\n",
        "```python\n",
        "def evaluator(inputs: dict, outputs: dict, reference: dict = None) -> dict:\n",
        "    \"\"\"\n",
        "    è¯„ä¼°å™¨å‡½æ•°\n",
        "    \n",
        "    Args:\n",
        "        inputs: è¾“å…¥æ•°æ®\n",
        "        outputs: æ¨¡å‹è¾“å‡º\n",
        "        reference: å‚è€ƒç­”æ¡ˆï¼ˆå¯é€‰ï¼‰\n",
        "    \n",
        "    Returns:\n",
        "        {\"score\": float, \"key\": str, \"comment\": str}\n",
        "    \"\"\"\n",
        "    pass\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ¼”ç¤º2ï¼šåŸºäºè§„åˆ™çš„è¯„ä¼°å™¨ã€‘\n",
            "\n",
            "=== æµ‹è¯•è¯„ä¼°å™¨ ===\n",
            "\n",
            "é•¿åº¦è¯„ä¼°ï¼š\n",
            "  åˆ†æ•°: 1.0\n",
            "  è¯„è®º: è¾“å‡ºé•¿åº¦åˆç†ï¼ˆ31å­—ç¬¦ï¼‰\n",
            "\n",
            "å…³é”®è¯è¯„ä¼°ï¼š\n",
            "  åˆ†æ•°: 1.0\n",
            "  è¯„è®º: æ‰¾åˆ° 2/2 ä¸ªå…³é”®è¯\n",
            "\n",
            "âœ“ åŸºäºè§„åˆ™çš„è¯„ä¼°å™¨ä¼˜ç‚¹ï¼š\n",
            "  - å¿«é€Ÿã€ç¡®å®šæ€§\n",
            "  - æ— éœ€é¢å¤–APIè°ƒç”¨\n",
            "  - é€‚åˆæ£€æŸ¥åŸºæœ¬å±æ€§\n",
            "âœ“ å±€é™æ€§ï¼š\n",
            "  - æ— æ³•è¯„ä¼°è¯­ä¹‰è´¨é‡\n",
            "  - è§„åˆ™éœ€è¦äººå·¥å®šä¹‰\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ¼”ç¤º2ï¼šåŸºäºè§„åˆ™çš„è¯„ä¼°å™¨ã€‘\\n\")\n",
        "\n",
        "# å®šä¹‰è¯„ä¼°å™¨1ï¼šé•¿åº¦æ£€æŸ¥\n",
        "def length_evaluator(inputs: dict, outputs: dict, reference: dict = None) -> dict:\n",
        "    \"\"\"æ£€æŸ¥è¾“å‡ºé•¿åº¦æ˜¯å¦åˆç†\"\"\"\n",
        "    output_text = outputs.get(\"output\", \"\")\n",
        "    length = len(output_text)\n",
        "    \n",
        "    # è¯„åˆ†è§„åˆ™ï¼š20-200å­—ç¬¦ä¸ºåˆç†èŒƒå›´\n",
        "    if length < 20:\n",
        "        score = 0.0\n",
        "        comment = f\"è¾“å‡ºå¤ªçŸ­ï¼ˆ{length}å­—ç¬¦ï¼‰ï¼Œå¯èƒ½ä¿¡æ¯ä¸è¶³\"\n",
        "    elif length > 200:\n",
        "        score = 0.5\n",
        "        comment = f\"è¾“å‡ºè¾ƒé•¿ï¼ˆ{length}å­—ç¬¦ï¼‰ï¼Œå¯èƒ½å†—ä½™\"\n",
        "    else:\n",
        "        score = 1.0\n",
        "        comment = f\"è¾“å‡ºé•¿åº¦åˆç†ï¼ˆ{length}å­—ç¬¦ï¼‰\"\n",
        "    \n",
        "    return {\"key\": \"length\", \"score\": score, \"comment\": comment}\n",
        "\n",
        "# å®šä¹‰è¯„ä¼°å™¨2ï¼šå…³é”®è¯æ£€æŸ¥\n",
        "def keyword_evaluator(inputs: dict, outputs: dict, reference: dict = None) -> dict:\n",
        "    \"\"\"æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å«å…³é”®è¯\"\"\"\n",
        "    output_text = outputs.get(\"output\", \"\").lower()\n",
        "    question = inputs.get(\"question\", \"\").lower()\n",
        "    \n",
        "    # æ ¹æ®é—®é¢˜ç¡®å®šå¿…éœ€å…³é”®è¯\n",
        "    required_keywords = []\n",
        "    if \"python\" in question:\n",
        "        required_keywords = [\"python\", \"è¯­è¨€\"]\n",
        "    elif \"langchain\" in question:\n",
        "        required_keywords = [\"langchain\"]\n",
        "    elif \"rag\" in question:\n",
        "        required_keywords = [\"rag\", \"æ£€ç´¢\"]\n",
        "    \n",
        "    # æ£€æŸ¥å…³é”®è¯\n",
        "    found_keywords = [kw for kw in required_keywords if kw in output_text]\n",
        "    score = len(found_keywords) / len(required_keywords) if required_keywords else 1.0\n",
        "    \n",
        "    comment = f\"æ‰¾åˆ° {len(found_keywords)}/{len(required_keywords)} ä¸ªå…³é”®è¯\"\n",
        "    \n",
        "    return {\"key\": \"keyword\", \"score\": score, \"comment\": comment}\n",
        "\n",
        "# æµ‹è¯•è¯„ä¼°å™¨\n",
        "print(\"=== æµ‹è¯•è¯„ä¼°å™¨ ===\\n\")\n",
        "\n",
        "# æ¨¡æ‹Ÿä¸€ä¸ªè¾“å‡º\n",
        "test_output = {\n",
        "    \"output\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦å’ŒWebå¼€å‘ã€‚\"\n",
        "}\n",
        "test_input = {\n",
        "    \"question\": \"Pythonæ˜¯ä»€ä¹ˆç±»å‹çš„è¯­è¨€ï¼Ÿ\"\n",
        "}\n",
        "\n",
        "# è¿è¡Œè¯„ä¼°å™¨\n",
        "length_result = length_evaluator(test_input, test_output)\n",
        "keyword_result = keyword_evaluator(test_input, test_output)\n",
        "\n",
        "print(\"é•¿åº¦è¯„ä¼°ï¼š\")\n",
        "print(f\"  åˆ†æ•°: {length_result['score']}\")\n",
        "print(f\"  è¯„è®º: {length_result['comment']}\\n\")\n",
        "\n",
        "print(\"å…³é”®è¯è¯„ä¼°ï¼š\")\n",
        "print(f\"  åˆ†æ•°: {keyword_result['score']}\")\n",
        "print(f\"  è¯„è®º: {keyword_result['comment']}\\n\")\n",
        "\n",
        "print(\"âœ“ åŸºäºè§„åˆ™çš„è¯„ä¼°å™¨ä¼˜ç‚¹ï¼š\")\n",
        "print(\"  - å¿«é€Ÿã€ç¡®å®šæ€§\")\n",
        "print(\"  - æ— éœ€é¢å¤–APIè°ƒç”¨\")\n",
        "print(\"  - é€‚åˆæ£€æŸ¥åŸºæœ¬å±æ€§\")\n",
        "print(\"âœ“ å±€é™æ€§ï¼š\")\n",
        "print(\"  - æ— æ³•è¯„ä¼°è¯­ä¹‰è´¨é‡\")\n",
        "print(\"  - è§„åˆ™éœ€è¦äººå·¥å®šä¹‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. LLM-as-Judgeè¯„ä¼°å™¨\n",
        "\n",
        "ä½¿ç”¨LLMä½œä¸ºè¯„åˆ¤è€…ï¼Œè¯„ä¼°è¾“å‡ºçš„è¯­ä¹‰è´¨é‡ã€‚\n",
        "\n",
        "### é€‚ç”¨åœºæ™¯\n",
        "\n",
        "- ç›¸å…³æ€§ï¼šç­”æ¡ˆæ˜¯å¦å›ç­”äº†é—®é¢˜\n",
        "- å‡†ç¡®æ€§ï¼šç­”æ¡ˆæ˜¯å¦ä¸å‚è€ƒä¸€è‡´\n",
        "- æœ‰ç”¨æ€§ï¼šç­”æ¡ˆæ˜¯å¦æœ‰å¸®åŠ©\n",
        "- å¿ å®åº¦ï¼šç­”æ¡ˆæ˜¯å¦åŸºäºæ£€ç´¢å†…å®¹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ¼”ç¤º3ï¼šLLM-as-Judgeè¯„ä¼°å™¨ã€‘\n",
            "\n",
            "=== æµ‹è¯•LLM-as-Judgeè¯„ä¼°å™¨ ===\n",
            "\n",
            "æµ‹è¯•æ¡ˆä¾‹ 1:\n",
            "  é—®é¢˜: Pythonæ˜¯ä»€ä¹ˆç±»å‹çš„è¯­è¨€ï¼Ÿ\n",
            "  ç­”æ¡ˆ: Pythonæ˜¯ä¸€ç§é«˜çº§ã€è§£é‡Šå‹ã€é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€ã€‚\n",
            "  è¯„ä¼°ç»“æœ: LLMè¯„åˆ†: 5/5\n",
            "  å½’ä¸€åŒ–åˆ†æ•°: 1.00\n",
            "\n",
            "æµ‹è¯•æ¡ˆä¾‹ 2:\n",
            "  é—®é¢˜: Pythonæ˜¯ä»€ä¹ˆç±»å‹çš„è¯­è¨€ï¼Ÿ\n",
            "  ç­”æ¡ˆ: ä»Šå¤©å¤©æ°”å¾ˆå¥½ã€‚\n",
            "  è¯„ä¼°ç»“æœ: LLMè¯„åˆ†: 1/5\n",
            "  å½’ä¸€åŒ–åˆ†æ•°: 0.20\n",
            "\n",
            "âœ“ LLM-as-Judgeä¼˜ç‚¹ï¼š\n",
            "  - å¯ä»¥è¯„ä¼°è¯­ä¹‰è´¨é‡\n",
            "  - çµæ´»ï¼Œå¯ä»¥è¯„ä¼°å„ç§æŒ‡æ ‡\n",
            "  - æ¥è¿‘äººç±»åˆ¤æ–­\n",
            "âœ“ å±€é™æ€§ï¼š\n",
            "  - éœ€è¦é¢å¤–çš„LLMè°ƒç”¨ï¼ˆæˆæœ¬ï¼‰\n",
            "  - ç»“æœå¯èƒ½ä¸ç¨³å®š\n",
            "  - éœ€è¦ç²¾å¿ƒè®¾è®¡è¯„ä¼°æç¤ºè¯\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ¼”ç¤º3ï¼šLLM-as-Judgeè¯„ä¼°å™¨ã€‘\\n\")\n",
        "\n",
        "# å®šä¹‰è¯„ä¼°æç¤ºè¯\n",
        "RELEVANCE_PROMPT = \"\"\"è¯·è¯„ä¼°ä»¥ä¸‹ç­”æ¡ˆæ˜¯å¦å›ç­”äº†ç”¨æˆ·çš„é—®é¢˜ã€‚\n",
        "\n",
        "é—®é¢˜: {question}\n",
        "ç­”æ¡ˆ: {answer}\n",
        "\n",
        "è¯„åˆ†æ ‡å‡†ï¼š\n",
        "- 5åˆ†ï¼šå®Œå…¨å›ç­”äº†é—®é¢˜ï¼Œä¿¡æ¯å‡†ç¡®å®Œæ•´\n",
        "- 4åˆ†ï¼šåŸºæœ¬å›ç­”äº†é—®é¢˜ï¼Œä¿¡æ¯å¤§è‡´æ­£ç¡®\n",
        "- 3åˆ†ï¼šéƒ¨åˆ†å›ç­”äº†é—®é¢˜ï¼Œæœ‰äº›ä¿¡æ¯ç¼ºå¤±\n",
        "- 2åˆ†ï¼šåªæœ‰å°‘é‡ç›¸å…³ä¿¡æ¯\n",
        "- 1åˆ†ï¼šå®Œå…¨ä¸ç›¸å…³\n",
        "\n",
        "è¯·åªè¿”å›ä¸€ä¸ª0-5çš„æ•°å­—ä½œä¸ºåˆ†æ•°ã€‚\"\"\"\n",
        "\n",
        "# åˆ›å»ºLLM-as-Judgeè¯„ä¼°å™¨\n",
        "def llm_relevance_evaluator(inputs: dict, outputs: dict, reference: dict = None) -> dict:\n",
        "    \"\"\"ä½¿ç”¨LLMè¯„ä¼°ç­”æ¡ˆçš„ç›¸å…³æ€§\"\"\"\n",
        "    question = inputs.get(\"question\", \"\")\n",
        "    answer = outputs.get(\"output\", \"\")\n",
        "    \n",
        "    # æ„é€ è¯„ä¼°æç¤º\n",
        "    eval_prompt = RELEVANCE_PROMPT.format(question=question, answer=answer)\n",
        "    \n",
        "    # è°ƒç”¨LLMè¿›è¡Œè¯„ä¼°\n",
        "    response = model.invoke(eval_prompt)\n",
        "    \n",
        "    # è§£æåˆ†æ•°ï¼ˆç®€å•å®ç°ï¼‰\n",
        "    try:\n",
        "        score_text = response.content.strip()\n",
        "        score = float(score_text[0]) / 5.0  # å½’ä¸€åŒ–åˆ°0-1\n",
        "        comment = f\"LLMè¯„åˆ†: {score_text[0]}/5\"\n",
        "    except:\n",
        "        score = 0.5\n",
        "        comment = \"è§£æå¤±è´¥ï¼Œé»˜è®¤0.5åˆ†\"\n",
        "    \n",
        "    return {\"key\": \"relevance\", \"score\": score, \"comment\": comment}\n",
        "\n",
        "# æµ‹è¯•LLM-as-Judge\n",
        "print(\"=== æµ‹è¯•LLM-as-Judgeè¯„ä¼°å™¨ ===\\n\")\n",
        "\n",
        "test_cases = [\n",
        "    {\n",
        "        \"input\": {\"question\": \"Pythonæ˜¯ä»€ä¹ˆç±»å‹çš„è¯­è¨€ï¼Ÿ\"},\n",
        "        \"output\": {\"output\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ã€è§£é‡Šå‹ã€é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€ã€‚\"}\n",
        "    },\n",
        "    {\n",
        "        \"input\": {\"question\": \"Pythonæ˜¯ä»€ä¹ˆç±»å‹çš„è¯­è¨€ï¼Ÿ\"},\n",
        "        \"output\": {\"output\": \"ä»Šå¤©å¤©æ°”å¾ˆå¥½ã€‚\"}  # ä¸ç›¸å…³çš„ç­”æ¡ˆ\n",
        "    }\n",
        "]\n",
        "\n",
        "for i, test_case in enumerate(test_cases, 1):\n",
        "    print(f\"æµ‹è¯•æ¡ˆä¾‹ {i}:\")\n",
        "    print(f\"  é—®é¢˜: {test_case['input']['question']}\")\n",
        "    print(f\"  ç­”æ¡ˆ: {test_case['output']['output']}\")\n",
        "    \n",
        "    result = llm_relevance_evaluator(test_case['input'], test_case['output'])\n",
        "    \n",
        "    print(f\"  è¯„ä¼°ç»“æœ: {result['comment']}\")\n",
        "    print(f\"  å½’ä¸€åŒ–åˆ†æ•°: {result['score']:.2f}\\n\")\n",
        "\n",
        "print(\"âœ“ LLM-as-Judgeä¼˜ç‚¹ï¼š\")\n",
        "print(\"  - å¯ä»¥è¯„ä¼°è¯­ä¹‰è´¨é‡\")\n",
        "print(\"  - çµæ´»ï¼Œå¯ä»¥è¯„ä¼°å„ç§æŒ‡æ ‡\")\n",
        "print(\"  - æ¥è¿‘äººç±»åˆ¤æ–­\")\n",
        "print(\"âœ“ å±€é™æ€§ï¼š\")\n",
        "print(\"  - éœ€è¦é¢å¤–çš„LLMè°ƒç”¨ï¼ˆæˆæœ¬ï¼‰\")\n",
        "print(\"  - ç»“æœå¯èƒ½ä¸ç¨³å®š\")\n",
        "print(\"  - éœ€è¦ç²¾å¿ƒè®¾è®¡è¯„ä¼°æç¤ºè¯\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. RAGè¯„ä¼°æŒ‡æ ‡\n",
        "\n",
        "RAGåº”ç”¨éœ€è¦è¯„ä¼°æ£€ç´¢å’Œç”Ÿæˆä¸¤ä¸ªç¯èŠ‚ã€‚\n",
        "\n",
        "### RAGè¯„ä¼°ç»´åº¦\n",
        "\n",
        "| ç»´åº¦ | è¯´æ˜ | éœ€è¦å‚è€ƒç­”æ¡ˆ |\n",
        "|------|------|-------------|\n",
        "| **Document Relevance** | æ£€ç´¢çš„æ–‡æ¡£æ˜¯å¦ç›¸å…³ | å¦ |\n",
        "| **Answer Faithfulness** | ç­”æ¡ˆæ˜¯å¦åŸºäºæ£€ç´¢å†…å®¹ | å¦ |\n",
        "| **Answer Helpfulness** | ç­”æ¡ˆæ˜¯å¦æœ‰å¸®åŠ© | å¦ |\n",
        "| **Answer Correctness** | ç­”æ¡ˆæ˜¯å¦æ­£ç¡® | æ˜¯ |\n",
        "\n",
        "### è¯„ä¼°æµç¨‹\n",
        "\n",
        "```\n",
        "é—®é¢˜ â†’ RAGç³»ç»Ÿ â†’ æ£€ç´¢æ–‡æ¡£ + ç­”æ¡ˆ\n",
        "         â†“           â†“         â†“\n",
        "    è¯„ä¼°æ£€ç´¢è´¨é‡  è¯„ä¼°å¿ å®åº¦  è¯„ä¼°å‡†ç¡®æ€§\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ¼”ç¤º4ï¼šRAGè¯„ä¼°ç¤ºä¾‹ã€‘\n",
            "\n",
            "=== RAGè¯„ä¼°ç¤ºä¾‹ ===\n",
            "\n",
            "é—®é¢˜: ä»€ä¹ˆæ˜¯LangChainï¼Ÿ\n",
            "\n",
            "æ£€ç´¢æ–‡æ¡£:\n",
            "  1. LangChainæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºLLMåº”ç”¨çš„å¼€æºæ¡†æ¶ã€‚\n",
            "  2. LangChainæä¾›äº†Agentã€Chainç­‰æ ¸å¿ƒæŠ½è±¡ã€‚\n",
            "\n",
            "ç­”æ¡ˆ: LangChainæ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åºã€‚\n",
            "\n",
            "è¯„ä¼°ç»“æœ:\n",
            "  æ–‡æ¡£ç›¸å…³æ€§: 1.00 - 2/2 ä¸ªæ–‡æ¡£ç›¸å…³\n",
            "  ç­”æ¡ˆå¿ å®åº¦: 0.00 - ç­”æ¡ˆä¸­0/1ä¸ªè¯æ¥è‡ªæ£€ç´¢æ–‡æ¡£\n",
            "\n",
            "ğŸ’¡ RAGè¯„ä¼°è¦ç‚¹ï¼š\n",
            "  1. æ£€ç´¢è´¨é‡ç›´æ¥å½±å“æœ€ç»ˆç­”æ¡ˆ\n",
            "  2. ç­”æ¡ˆå¿…é¡»åŸºäºæ£€ç´¢å†…å®¹ï¼ˆå¿ å®åº¦ï¼‰\n",
            "  3. éœ€è¦è¯„ä¼°å¤šä¸ªç»´åº¦\n",
            "  4. ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨LLM-as-Judge\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ¼”ç¤º4ï¼šRAGè¯„ä¼°ç¤ºä¾‹ã€‘\\n\")\n",
        "\n",
        "# æ¨¡æ‹ŸRAGè¾“å‡º\n",
        "rag_output = {\n",
        "    \"question\": \"ä»€ä¹ˆæ˜¯LangChainï¼Ÿ\",\n",
        "    \"retrieved_docs\": [\n",
        "        \"LangChainæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºLLMåº”ç”¨çš„å¼€æºæ¡†æ¶ã€‚\",\n",
        "        \"LangChainæä¾›äº†Agentã€Chainç­‰æ ¸å¿ƒæŠ½è±¡ã€‚\"\n",
        "    ],\n",
        "    \"answer\": \"LangChainæ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åºã€‚\"\n",
        "}\n",
        "\n",
        "# è¯„ä¼°å™¨1ï¼šæ–‡æ¡£ç›¸å…³æ€§\n",
        "def doc_relevance_evaluator(rag_output: dict) -> dict:\n",
        "    \"\"\"è¯„ä¼°æ£€ç´¢æ–‡æ¡£æ˜¯å¦ç›¸å…³\"\"\"\n",
        "    question = rag_output[\"question\"]\n",
        "    docs = rag_output[\"retrieved_docs\"]\n",
        "    \n",
        "    # ç®€å•æ£€æŸ¥ï¼šæ–‡æ¡£æ˜¯å¦åŒ…å«é—®é¢˜ä¸­çš„å…³é”®è¯\n",
        "    keywords = [\"langchain\"]\n",
        "    relevant_docs = [doc for doc in docs if any(kw in doc.lower() for kw in keywords)]\n",
        "    \n",
        "    score = len(relevant_docs) / len(docs) if docs else 0.0\n",
        "    comment = f\"{len(relevant_docs)}/{len(docs)} ä¸ªæ–‡æ¡£ç›¸å…³\"\n",
        "    \n",
        "    return {\"key\": \"doc_relevance\", \"score\": score, \"comment\": comment}\n",
        "\n",
        "# è¯„ä¼°å™¨2ï¼šç­”æ¡ˆå¿ å®åº¦\n",
        "def answer_faithfulness_evaluator(rag_output: dict) -> dict:\n",
        "    \"\"\"è¯„ä¼°ç­”æ¡ˆæ˜¯å¦åŸºäºæ£€ç´¢å†…å®¹\"\"\"\n",
        "    answer = rag_output[\"answer\"].lower()\n",
        "    docs = rag_output[\"retrieved_docs\"]\n",
        "    \n",
        "    # æ£€æŸ¥ç­”æ¡ˆä¸­çš„å…³é”®ä¿¡æ¯æ˜¯å¦æ¥è‡ªæ–‡æ¡£\n",
        "    # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥ç­”æ¡ˆä¸­çš„è¯æ˜¯å¦åœ¨æ–‡æ¡£ä¸­\n",
        "    answer_words = set(answer.split())\n",
        "    doc_words = set(\" \".join(docs).lower().split())\n",
        "    \n",
        "    overlap = len(answer_words & doc_words)\n",
        "    score = overlap / len(answer_words) if answer_words else 0.0\n",
        "    \n",
        "    comment = f\"ç­”æ¡ˆä¸­{overlap}/{len(answer_words)}ä¸ªè¯æ¥è‡ªæ£€ç´¢æ–‡æ¡£\"\n",
        "    \n",
        "    return {\"key\": \"faithfulness\", \"score\": score, \"comment\": comment}\n",
        "\n",
        "# è¿è¡Œè¯„ä¼°\n",
        "print(\"=== RAGè¯„ä¼°ç¤ºä¾‹ ===\\n\")\n",
        "print(f\"é—®é¢˜: {rag_output['question']}\")\n",
        "print(f\"\\næ£€ç´¢æ–‡æ¡£:\")\n",
        "for i, doc in enumerate(rag_output['retrieved_docs'], 1):\n",
        "    print(f\"  {i}. {doc}\")\n",
        "print(f\"\\nç­”æ¡ˆ: {rag_output['answer']}\\n\")\n",
        "\n",
        "# è¯„ä¼°\n",
        "doc_rel = doc_relevance_evaluator(rag_output)\n",
        "faithfulness = answer_faithfulness_evaluator(rag_output)\n",
        "\n",
        "print(\"è¯„ä¼°ç»“æœ:\")\n",
        "print(f\"  æ–‡æ¡£ç›¸å…³æ€§: {doc_rel['score']:.2f} - {doc_rel['comment']}\")\n",
        "print(f\"  ç­”æ¡ˆå¿ å®åº¦: {faithfulness['score']:.2f} - {faithfulness['comment']}\\n\")\n",
        "\n",
        "print(\"ğŸ’¡ RAGè¯„ä¼°è¦ç‚¹ï¼š\")\n",
        "print(\"  1. æ£€ç´¢è´¨é‡ç›´æ¥å½±å“æœ€ç»ˆç­”æ¡ˆ\")\n",
        "print(\"  2. ç­”æ¡ˆå¿…é¡»åŸºäºæ£€ç´¢å†…å®¹ï¼ˆå¿ å®åº¦ï¼‰\")\n",
        "print(\"  3. éœ€è¦è¯„ä¼°å¤šä¸ªç»´åº¦\")\n",
        "print(\"  4. ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨LLM-as-Judge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Agentè¯„ä¼°ï¼ˆè½¨è¿¹è¯„ä¼°ï¼‰\n",
        "\n",
        "Agentè¯„ä¼°éœ€è¦è¯„ä¼°æ•´ä¸ªæ‰§è¡Œè½¨è¿¹ï¼ŒåŒ…æ‹¬å·¥å…·è°ƒç”¨é¡ºåºå’Œå†³ç­–ã€‚\n",
        "\n",
        "### è½¨è¿¹è¯„ä¼°æ–¹æ³•\n",
        "\n",
        "| æ–¹æ³• | è¯´æ˜ | ä¼˜ç‚¹ | ç¼ºç‚¹ |\n",
        "|------|------|------|------|\n",
        "| **Trajectory Match** | ä¸å‚è€ƒè½¨è¿¹ç²¾ç¡®åŒ¹é… | ç¡®å®šæ€§ã€å¿«é€Ÿ | ä¸çµæ´» |\n",
        "| **LLM-as-Judge** | LLMè¯„ä¼°è½¨è¿¹åˆç†æ€§ | çµæ´»ã€å…¨é¢ | æˆæœ¬é«˜ |\n",
        "\n",
        "### è¯„ä¼°ç»´åº¦\n",
        "\n",
        "- å·¥å…·é€‰æ‹©æ˜¯å¦æ­£ç¡®\n",
        "- å·¥å…·è°ƒç”¨é¡ºåºæ˜¯å¦åˆç†\n",
        "- å‚æ•°æ˜¯å¦æ­£ç¡®\n",
        "- æœ€ç»ˆç­”æ¡ˆæ˜¯å¦æ­£ç¡®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ¼”ç¤º5ï¼šAgentè½¨è¿¹è¯„ä¼°ã€‘\n",
            "\n",
            "=== Agentè½¨è¿¹è¯„ä¼° ===\n",
            "\n",
            "é—®é¢˜: åŒ—äº¬ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ\n",
            "\n",
            "æ‰§è¡Œè½¨è¿¹:\n",
            "  1. è°ƒç”¨å·¥å…·: get_weather({'city': 'åŒ—äº¬'})\n",
            "  2. å·¥å…·ç»“æœ: åŒ—äº¬ä»Šå¤©æ™´å¤©ï¼Œ25Â°C\n",
            "  3. æœ€ç»ˆç­”æ¡ˆ: åŒ—äº¬ä»Šå¤©æ˜¯æ™´å¤©ï¼Œæ°”æ¸©25Â°Cã€‚\n",
            "\n",
            "è¯„ä¼°ç»“æœ:\n",
            "  åˆ†æ•°: 1.0\n",
            "  è¯„è®º: å·¥å…·åŒ¹é…: True, å‚æ•°åŒ¹é…: True\n",
            "\n",
            "ğŸ’¡ Agentè¯„ä¼°è¦ç‚¹ï¼š\n",
            "  1. ä¸ä»…è¯„ä¼°æœ€ç»ˆç­”æ¡ˆï¼Œè¿˜è¦è¯„ä¼°è¿‡ç¨‹\n",
            "  2. è½¨è¿¹åŒ¹é…é€‚åˆç¡®å®šæ€§åœºæ™¯\n",
            "  3. LLM-as-Judgeé€‚åˆçµæ´»è¯„ä¼°\n",
            "  4. å¯ä»¥ä½¿ç”¨agentevalsåŒ…è¿›è¡Œä¸“ä¸šè¯„ä¼°\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ¼”ç¤º5ï¼šAgentè½¨è¿¹è¯„ä¼°ã€‘\\n\")\n",
        "\n",
        "# æ¨¡æ‹ŸAgentæ‰§è¡Œè½¨è¿¹\n",
        "agent_trajectory = {\n",
        "    \"question\": \"åŒ—äº¬ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ\",\n",
        "    \"steps\": [\n",
        "        {\"type\": \"tool_call\", \"tool\": \"get_weather\", \"args\": {\"city\": \"åŒ—äº¬\"}},\n",
        "        {\"type\": \"tool_result\", \"result\": \"åŒ—äº¬ä»Šå¤©æ™´å¤©ï¼Œ25Â°C\"},\n",
        "        {\"type\": \"final_answer\", \"answer\": \"åŒ—äº¬ä»Šå¤©æ˜¯æ™´å¤©ï¼Œæ°”æ¸©25Â°Cã€‚\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "# å‚è€ƒè½¨è¿¹ï¼ˆæœŸæœ›çš„æ‰§è¡Œè·¯å¾„ï¼‰\n",
        "reference_trajectory = {\n",
        "    \"expected_tools\": [\"get_weather\"],\n",
        "    \"expected_args\": {\"city\": \"åŒ—äº¬\"}\n",
        "}\n",
        "\n",
        "# è½¨è¿¹åŒ¹é…è¯„ä¼°å™¨\n",
        "def trajectory_match_evaluator(trajectory: dict, reference: dict) -> dict:\n",
        "    \"\"\"æ£€æŸ¥è½¨è¿¹æ˜¯å¦ä¸å‚è€ƒåŒ¹é…\"\"\"\n",
        "    # æå–å®é™…è°ƒç”¨çš„å·¥å…·\n",
        "    actual_tools = [\n",
        "        step[\"tool\"] for step in trajectory[\"steps\"] \n",
        "        if step[\"type\"] == \"tool_call\"\n",
        "    ]\n",
        "    \n",
        "    # æ£€æŸ¥å·¥å…·æ˜¯å¦åŒ¹é…\n",
        "    expected_tools = reference[\"expected_tools\"]\n",
        "    tools_match = set(actual_tools) == set(expected_tools)\n",
        "    \n",
        "    # æ£€æŸ¥å‚æ•°\n",
        "    tool_calls = [step for step in trajectory[\"steps\"] if step[\"type\"] == \"tool_call\"]\n",
        "    args_match = all(\n",
        "        step[\"args\"] == reference[\"expected_args\"] \n",
        "        for step in tool_calls\n",
        "    )\n",
        "    \n",
        "    score = 1.0 if (tools_match and args_match) else 0.0\n",
        "    comment = f\"å·¥å…·åŒ¹é…: {tools_match}, å‚æ•°åŒ¹é…: {args_match}\"\n",
        "    \n",
        "    return {\"key\": \"trajectory_match\", \"score\": score, \"comment\": comment}\n",
        "\n",
        "# è¿è¡Œè¯„ä¼°\n",
        "print(\"=== Agentè½¨è¿¹è¯„ä¼° ===\\n\")\n",
        "print(f\"é—®é¢˜: {agent_trajectory['question']}\\n\")\n",
        "print(\"æ‰§è¡Œè½¨è¿¹:\")\n",
        "for i, step in enumerate(agent_trajectory['steps'], 1):\n",
        "    if step['type'] == 'tool_call':\n",
        "        print(f\"  {i}. è°ƒç”¨å·¥å…·: {step['tool']}({step['args']})\")\n",
        "    elif step['type'] == 'tool_result':\n",
        "        print(f\"  {i}. å·¥å…·ç»“æœ: {step['result']}\")\n",
        "    elif step['type'] == 'final_answer':\n",
        "        print(f\"  {i}. æœ€ç»ˆç­”æ¡ˆ: {step['answer']}\")\n",
        "\n",
        "result = trajectory_match_evaluator(agent_trajectory, reference_trajectory)\n",
        "\n",
        "print(f\"\\nè¯„ä¼°ç»“æœ:\")\n",
        "print(f\"  åˆ†æ•°: {result['score']}\")\n",
        "print(f\"  è¯„è®º: {result['comment']}\\n\")\n",
        "\n",
        "print(\"ğŸ’¡ Agentè¯„ä¼°è¦ç‚¹ï¼š\")\n",
        "print(\"  1. ä¸ä»…è¯„ä¼°æœ€ç»ˆç­”æ¡ˆï¼Œè¿˜è¦è¯„ä¼°è¿‡ç¨‹\")\n",
        "print(\"  2. è½¨è¿¹åŒ¹é…é€‚åˆç¡®å®šæ€§åœºæ™¯\")\n",
        "print(\"  3. LLM-as-Judgeé€‚åˆçµæ´»è¯„ä¼°\")\n",
        "print(\"  4. å¯ä»¥ä½¿ç”¨agentevalsåŒ…è¿›è¡Œä¸“ä¸šè¯„ä¼°\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. è¯„ä¼°æœ€ä½³å®è·µ\n",
        "\n",
        "### è¯„ä¼°ç­–ç•¥é€‰æ‹©\n",
        "\n",
        "| åº”ç”¨ç±»å‹ | æ¨èè¯„ä¼°å™¨ | åŸå›  |\n",
        "|---------|-----------|------|\n",
        "| **ç®€å•QA** | åŸºäºè§„åˆ™ + LLM-as-Judge | å¿«é€ŸéªŒè¯åŸºæœ¬å±æ€§ + è¯­ä¹‰è´¨é‡ |\n",
        "| **RAGåº”ç”¨** | æ–‡æ¡£ç›¸å…³æ€§ + ç­”æ¡ˆå¿ å®åº¦ + å‡†ç¡®æ€§ | å¤šç»´åº¦è¯„ä¼° |\n",
        "| **Agentåº”ç”¨** | è½¨è¿¹è¯„ä¼° + æœ€ç»ˆç­”æ¡ˆè¯„ä¼° | è¯„ä¼°è¿‡ç¨‹å’Œç»“æœ |\n",
        "| **å¯¹è¯ç³»ç»Ÿ** | ç›¸å…³æ€§ + æœ‰ç”¨æ€§ + é•¿åº¦ | ç”¨æˆ·ä½“éªŒå¯¼å‘ |\n",
        "\n",
        "### è¯„ä¼°å·¥ä½œæµ\n",
        "\n",
        "```python\n",
        "# 1. åˆ›å»ºæ•°æ®é›†\n",
        "dataset = create_test_dataset()\n",
        "\n",
        "# 2. å®šä¹‰è¯„ä¼°å™¨\n",
        "evaluators = [\n",
        "    length_evaluator,\n",
        "    keyword_evaluator,\n",
        "    llm_relevance_evaluator\n",
        "]\n",
        "\n",
        "# 3. è¿è¡Œè¯„ä¼°\n",
        "results = []\n",
        "for example in dataset:\n",
        "    # è¿è¡Œåº”ç”¨\n",
        "    output = app.invoke(example[\"input\"])\n",
        "    \n",
        "    # è¿è¡Œæ‰€æœ‰è¯„ä¼°å™¨\n",
        "    scores = {}\n",
        "    for evaluator in evaluators:\n",
        "        result = evaluator(example[\"input\"], output, example.get(\"reference\"))\n",
        "        scores[result[\"key\"]] = result[\"score\"]\n",
        "    \n",
        "    results.append({\n",
        "        \"input\": example[\"input\"],\n",
        "        \"output\": output,\n",
        "        \"scores\": scores\n",
        "    })\n",
        "\n",
        "# 4. åˆ†æç»“æœ\n",
        "avg_scores = {\n",
        "    key: sum(r[\"scores\"][key] for r in results) / len(results)\n",
        "    for key in results[0][\"scores\"].keys()\n",
        "}\n",
        "```\n",
        "\n",
        "### å…³é”®åŸåˆ™\n",
        "\n",
        "âœ… **å¤šç»´åº¦è¯„ä¼°** - å•ä¸€æŒ‡æ ‡ä¸è¶³ä»¥è¡¡é‡è´¨é‡  \n",
        "âœ… **è‡ªåŠ¨åŒ–ä¼˜å…ˆ** - å°½å¯èƒ½ä½¿ç”¨è‡ªåŠ¨è¯„ä¼°  \n",
        "âœ… **æŒç»­è¯„ä¼°** - åœ¨å¼€å‘å’Œç”Ÿäº§ä¸­æŒç»­ç›‘æ§  \n",
        "âœ… **å¯¹æ¯”è¯„ä¼°** - ç”¨äºæ¯”è¾ƒä¸åŒç‰ˆæœ¬  \n",
        "âœ… **äººå·¥æŠ½æŸ¥** - å®šæœŸäººå·¥éªŒè¯è‡ªåŠ¨è¯„ä¼°ç»“æœ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ¼”ç¤º6ï¼šå®Œæ•´è¯„ä¼°æµç¨‹ã€‘\n",
            "\n",
            "=== è¿è¡Œè¯„ä¼° ===\n",
            "\n",
            "è¯„ä¼°æ ·æœ¬ 1/2: Pythonæ˜¯ä»€ä¹ˆï¼Ÿ...\n",
            "  length: 0.50\n",
            "  keyword: 1.00\n",
            "  relevance: 1.00\n",
            "\n",
            "è¯„ä¼°æ ·æœ¬ 2/2: å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ...\n",
            "  length: 0.50\n",
            "  keyword: 1.00\n",
            "  relevance: 1.00\n",
            "\n",
            "=== è¯„ä¼°æ±‡æ€» ===\n",
            "\n",
            "length: å¹³å‡åˆ† 0.50\n",
            "keyword: å¹³å‡åˆ† 1.00\n",
            "relevance: å¹³å‡åˆ† 1.00\n",
            "\n",
            "æ€»ä½“å¹³å‡åˆ†: 0.83\n",
            "\n",
            "ğŸ’¡ å®Œæ•´è¯„ä¼°æµç¨‹è¦ç‚¹ï¼š\n",
            "  1. ä½¿ç”¨å¤šä¸ªè¯„ä¼°å™¨ä»ä¸åŒè§’åº¦è¯„ä¼°\n",
            "  2. åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè¿è¡Œï¼Œè€Œä¸æ˜¯å•ä¸ªæ ·æœ¬\n",
            "  3. æ±‡æ€»ç»Ÿè®¡ç»“æœï¼Œä¾¿äºå¯¹æ¯”\n",
            "  4. å®šæœŸè¿è¡Œï¼Œç›‘æ§æ€§èƒ½å˜åŒ–\n",
            "  5. ç»“åˆè‡ªåŠ¨è¯„ä¼°å’Œäººå·¥æŠ½æŸ¥\n"
          ]
        }
      ],
      "source": [
        "print(\"ã€æ¼”ç¤º6ï¼šå®Œæ•´è¯„ä¼°æµç¨‹ã€‘\\n\")\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªç®€å•çš„QAåº”ç”¨\n",
        "def simple_qa_app(question: str) -> str:\n",
        "    \"\"\"ç®€å•çš„QAåº”ç”¨\"\"\"\n",
        "    response = model.invoke(question)\n",
        "    return response.content\n",
        "\n",
        "# 1. å‡†å¤‡æµ‹è¯•æ•°æ®é›†\n",
        "test_dataset = [\n",
        "    {\"question\": \"Pythonæ˜¯ä»€ä¹ˆï¼Ÿ\", \"category\": \"basic\"},\n",
        "    {\"question\": \"å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ\", \"category\": \"advice\"}\n",
        "]\n",
        "\n",
        "# 2. å®šä¹‰å¤šä¸ªè¯„ä¼°å™¨\n",
        "evaluators = {\n",
        "    \"length\": length_evaluator,\n",
        "    \"keyword\": keyword_evaluator,\n",
        "    \"relevance\": llm_relevance_evaluator\n",
        "}\n",
        "\n",
        "# 3. è¿è¡Œè¯„ä¼°\n",
        "print(\"=== è¿è¡Œè¯„ä¼° ===\\n\")\n",
        "results = []\n",
        "\n",
        "for i, example in enumerate(test_dataset, 1):\n",
        "    print(f\"è¯„ä¼°æ ·æœ¬ {i}/{len(test_dataset)}: {example['question'][:30]}...\")\n",
        "    \n",
        "    # è¿è¡Œåº”ç”¨\n",
        "    output = simple_qa_app(example[\"question\"])\n",
        "    \n",
        "    # è¿è¡Œæ‰€æœ‰è¯„ä¼°å™¨\n",
        "    scores = {}\n",
        "    for eval_name, evaluator in evaluators.items():\n",
        "        result = evaluator(\n",
        "            {\"question\": example[\"question\"]},\n",
        "            {\"output\": output}\n",
        "        )\n",
        "        scores[eval_name] = result[\"score\"]\n",
        "        print(f\"  {eval_name}: {result['score']:.2f}\")\n",
        "    \n",
        "    results.append({\n",
        "        \"question\": example[\"question\"],\n",
        "        \"output\": output[:50] + \"...\",\n",
        "        \"scores\": scores\n",
        "    })\n",
        "    print()\n",
        "\n",
        "# 4. æ±‡æ€»ç»“æœ\n",
        "print(\"=== è¯„ä¼°æ±‡æ€» ===\\n\")\n",
        "\n",
        "# è®¡ç®—å¹³å‡åˆ†\n",
        "avg_scores = {}\n",
        "for eval_name in evaluators.keys():\n",
        "    avg = sum(r[\"scores\"][eval_name] for r in results) / len(results)\n",
        "    avg_scores[eval_name] = avg\n",
        "    print(f\"{eval_name}: å¹³å‡åˆ† {avg:.2f}\")\n",
        "\n",
        "print(f\"\\næ€»ä½“å¹³å‡åˆ†: {sum(avg_scores.values()) / len(avg_scores):.2f}\\n\")\n",
        "\n",
        "print(\"ğŸ’¡ å®Œæ•´è¯„ä¼°æµç¨‹è¦ç‚¹ï¼š\")\n",
        "print(\"  1. ä½¿ç”¨å¤šä¸ªè¯„ä¼°å™¨ä»ä¸åŒè§’åº¦è¯„ä¼°\")\n",
        "print(\"  2. åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè¿è¡Œï¼Œè€Œä¸æ˜¯å•ä¸ªæ ·æœ¬\")\n",
        "print(\"  3. æ±‡æ€»ç»Ÿè®¡ç»“æœï¼Œä¾¿äºå¯¹æ¯”\")\n",
        "print(\"  4. å®šæœŸè¿è¡Œï¼Œç›‘æ§æ€§èƒ½å˜åŒ–\")\n",
        "print(\"  5. ç»“åˆè‡ªåŠ¨è¯„ä¼°å’Œäººå·¥æŠ½æŸ¥\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. æ€»ç»“ä¸å…³é”®æ”¶è·\n",
        "\n",
        "### æ ¸å¿ƒè¦ç‚¹\n",
        "\n",
        "#### 1. è¯„ä¼°çš„é‡è¦æ€§\n",
        "\n",
        "- LLMè¾“å‡ºæ˜¯éç¡®å®šæ€§çš„ï¼Œéœ€è¦ç³»ç»ŸåŒ–è¯„ä¼°\n",
        "- è¯„ä¼°ç¡®ä¿è´¨é‡ã€æŒ‡å¯¼ä¼˜åŒ–ã€å»ºç«‹ä¿¡å¿ƒ\n",
        "- è¯„ä¼°æ˜¯è¿­ä»£æ”¹è¿›çš„åŸºç¡€\n",
        "\n",
        "#### 2. è¯„ä¼°å™¨ç±»å‹\n",
        "\n",
        "| ç±»å‹ | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |\n",
        "|------|---------|------|------|\n",
        "| **åŸºäºè§„åˆ™** | åŸºæœ¬å±æ€§æ£€æŸ¥ | å¿«é€Ÿã€ç¡®å®š | æ— æ³•è¯„ä¼°è¯­ä¹‰ |\n",
        "| **LLM-as-Judge** | è¯­ä¹‰è´¨é‡è¯„ä¼° | çµæ´»ã€å…¨é¢ | æˆæœ¬é«˜ã€ä¸ç¨³å®š |\n",
        "| **åŸºäºå‚è€ƒ** | å‡†ç¡®æ€§è¯„ä¼° | å®¢è§‚ | éœ€è¦æ ‡æ³¨æ•°æ® |\n",
        "\n",
        "#### 3. ä¸åŒåº”ç”¨çš„è¯„ä¼°ç­–ç•¥\n",
        "\n",
        "```python\n",
        "# QAåº”ç”¨\n",
        "evaluators = [length, keyword, relevance, accuracy]\n",
        "\n",
        "# RAGåº”ç”¨\n",
        "evaluators = [doc_relevance, faithfulness, helpfulness, correctness]\n",
        "\n",
        "# Agentåº”ç”¨\n",
        "evaluators = [trajectory_match, tool_correctness, answer_quality]\n",
        "```\n",
        "\n",
        "#### 4. è¯„ä¼° vs æµ‹è¯•\n",
        "\n",
        "- **è¯„ä¼°**ï¼šè¡¡é‡æ€§èƒ½ï¼Œç›¸å¯¹æ ‡å‡†ï¼Œç”¨äºå¯¹æ¯”\n",
        "- **æµ‹è¯•**ï¼šæ–­è¨€æ­£ç¡®æ€§ï¼Œç»å¯¹æ ‡å‡†ï¼Œç”¨äºéƒ¨ç½²é—¨æ§›\n",
        "- è¯„ä¼°æŒ‡æ ‡å¯ä»¥è½¬æ¢ä¸ºæµ‹è¯•ï¼ˆå›å½’æµ‹è¯•ï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "### æœ€ä½³å®è·µ\n",
        "\n",
        "#### âœ… æ¨èåšæ³•\n",
        "\n",
        "1. **å¤šç»´åº¦è¯„ä¼°**\n",
        "   - ä¸ä¾èµ–å•ä¸€æŒ‡æ ‡\n",
        "   - ä»ä¸åŒè§’åº¦è¯„ä¼°è´¨é‡\n",
        "\n",
        "2. **è‡ªåŠ¨åŒ–è¯„ä¼°**\n",
        "   - ä¼˜å…ˆä½¿ç”¨è‡ªåŠ¨è¯„ä¼°å™¨\n",
        "   - å‡å°‘äººå·¥æˆæœ¬\n",
        "\n",
        "3. **æŒç»­è¯„ä¼°**\n",
        "   - å¼€å‘é˜¶æ®µï¼šæ¯æ¬¡ä¿®æ”¹åè¯„ä¼°\n",
        "   - ç”Ÿäº§é˜¶æ®µï¼šå®šæœŸç›‘æ§\n",
        "\n",
        "4. **åˆ†å±‚è¯„ä¼°**\n",
        "   - å¿«é€Ÿè¯„ä¼°ï¼šåŸºäºè§„åˆ™\n",
        "   - æ·±åº¦è¯„ä¼°ï¼šLLM-as-Judge\n",
        "   - äººå·¥æŠ½æŸ¥ï¼šéªŒè¯è‡ªåŠ¨è¯„ä¼°\n",
        "\n",
        "5. **æ•°æ®é›†ç®¡ç†**\n",
        "   - ç»´æŠ¤é«˜è´¨é‡æµ‹è¯•é›†\n",
        "   - å®šæœŸæ›´æ–°å’Œæ‰©å……\n",
        "   - åŒ…å«è¾¹ç•Œæƒ…å†µ\n",
        "\n",
        "#### âŒ é¿å…çš„é™·é˜±\n",
        "\n",
        "1. **åªè¯„ä¼°æœ€ç»ˆè¾“å‡º**\n",
        "   - âŒ å¿½ç•¥ä¸­é—´è¿‡ç¨‹\n",
        "   - âœ… è¯„ä¼°æ•´ä¸ªæµç¨‹ï¼ˆç‰¹åˆ«æ˜¯Agentï¼‰\n",
        "\n",
        "2. **è¿‡åº¦ä¾èµ–å•ä¸€æŒ‡æ ‡**\n",
        "   - âŒ åªçœ‹å‡†ç¡®ç‡\n",
        "   - âœ… å¤šç»´åº¦ç»¼åˆè¯„ä¼°\n",
        "\n",
        "3. **è¯„ä¼°æ•°æ®é›†å¤ªå°**\n",
        "   - âŒ åªæœ‰å‡ ä¸ªæ ·æœ¬\n",
        "   - âœ… è‡³å°‘å‡ åä¸ªæ ·æœ¬\n",
        "\n",
        "4. **ä¸æ›´æ–°è¯„ä¼°æ ‡å‡†**\n",
        "   - âŒ ä¸€æˆä¸å˜çš„è¯„ä¼°å™¨\n",
        "   - âœ… éšåº”ç”¨æ¼”è¿›æ›´æ–°\n",
        "\n",
        "5. **å¿½ç•¥æˆæœ¬**\n",
        "   - âŒ æ‰€æœ‰æ ·æœ¬éƒ½ç”¨LLM-as-Judge\n",
        "   - âœ… å¹³è¡¡æˆæœ¬å’Œè´¨é‡\n",
        "\n",
        "---\n",
        "\n",
        "### è¯„ä¼°å·¥å…·ç”Ÿæ€\n",
        "\n",
        "| å·¥å…· | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |\n",
        "|------|------|---------|\n",
        "| **LangSmith** | å®˜æ–¹è¯„ä¼°å¹³å° | åœ¨çº¿è¯„ä¼°ã€å›¢é˜Ÿåä½œ |\n",
        "| **pytest** | æµ‹è¯•æ¡†æ¶ | æœ¬åœ°æµ‹è¯•ã€CI/CD |\n",
        "| **agentevals** | Agentä¸“ç”¨è¯„ä¼° | Agentè½¨è¿¹è¯„ä¼° |\n",
        "| **è‡ªå®šä¹‰è¯„ä¼°å™¨** | çµæ´»å®šåˆ¶ | ç‰¹å®šéœ€æ±‚ |\n",
        "\n",
        "---\n",
        "\n",
        "## ä¸‹ä¸€æ­¥å­¦ä¹ \n",
        "\n",
        "å®Œæˆè¯„ä¼°åŸºç¡€åï¼Œå»ºè®®å­¦ä¹ ï¼š\n",
        "\n",
        "1. **ç¬¬22ç« ï¼šLangSmith Integration** - ä½¿ç”¨LangSmithè¿›è¡Œåœ¨çº¿è¯„ä¼°\n",
        "2. **ç»¼åˆé¡¹ç›®** - å°†è¯„ä¼°é›†æˆåˆ°å®é™…é¡¹ç›®ä¸­\n",
        "3. **é«˜çº§è¯„ä¼°** - A/Bæµ‹è¯•ã€å¤šæ¨¡å‹å¯¹æ¯”\n",
        "\n",
        "---\n",
        "\n",
        "## å…³é”®æ”¶è·\n",
        "\n",
        "âœ… **è¯„ä¼°æ˜¯LLMåº”ç”¨å¼€å‘çš„æ ¸å¿ƒç¯èŠ‚** - ç¡®ä¿è´¨é‡å’ŒæŒç»­æ”¹è¿›\n",
        "\n",
        "âœ… **å¤šç§è¯„ä¼°å™¨ç»„åˆä½¿ç”¨** - åŸºäºè§„åˆ™ + LLM-as-Judge + äººå·¥\n",
        "\n",
        "âœ… **ä¸åŒåº”ç”¨éœ€è¦ä¸åŒè¯„ä¼°ç­–ç•¥** - QAã€RAGã€Agentå„æœ‰ä¾§é‡\n",
        "\n",
        "âœ… **è¯„ä¼°è¦è¦†ç›–è¿‡ç¨‹å’Œç»“æœ** - ç‰¹åˆ«æ˜¯Agentåº”ç”¨\n",
        "\n",
        "âœ… **è‡ªåŠ¨åŒ–è¯„ä¼°æé«˜æ•ˆç‡** - ä½†éœ€è¦äººå·¥éªŒè¯\n",
        "\n",
        "âœ… **æŒç»­è¯„ä¼°å’Œè¿­ä»£** - åœ¨å¼€å‘å’Œç”Ÿäº§ä¸­éƒ½è¦ç›‘æ§\n",
        "\n",
        "âœ… **è¯„ä¼°æŒ‡æ ‡å¯ä»¥è½¬æ¢ä¸ºæµ‹è¯•** - å»ºç«‹è´¨é‡é—¨æ§›\n",
        "\n",
        "âœ… **LangSmithæä¾›å¼ºå¤§çš„è¯„ä¼°å·¥å…·** - ä¸‹ä¸€ç« å°†è¯¦ç»†å­¦ä¹ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
