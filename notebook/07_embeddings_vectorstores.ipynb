{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 第07章：Embeddings & Vector Stores（嵌入与向量存储）\n",
        "\n",
        "## 学习目标\n",
        "\n",
        "本章将学习：\n",
        "1. 理解Embeddings（嵌入）的概念和作用\n",
        "2. 使用Embedding模型将文本转换为向量\n",
        "3. 理解语义相似度和相似度度量\n",
        "4. 掌握Vector Store的使用\n",
        "5. 实现语义搜索功能\n",
        "\n",
        "## 为什么需要Embeddings和Vector Stores？\n",
        "\n",
        "在RAG系统中：\n",
        "- Embeddings将文本转换为数字向量，捕获语义信息\n",
        "- Vector Stores存储这些向量，支持快速的语义搜索\n",
        "- 通过语义相似度而非关键词匹配来检索相关文档\n",
        "- 这是RAG技术的核心基础"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "环境配置完成！\n",
            "Chat模型: gpt-4.1-mini\n",
            "Embedding模型: text-embedding-3-small\n"
          ]
        }
      ],
      "source": [
        "# 环境配置\n",
        "import os\n",
        "import sys\n",
        "\n",
        "_project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "sys.path.append(_project_root)\n",
        "\n",
        "from config import config\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.tools import tool\n",
        "from langchain.messages import HumanMessage, AIMessage, ToolMessage\n",
        "\n",
        "# 初始化模型\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    temperature=0,\n",
        "    api_key=config.CLOUD_API_KEY,\n",
        "    base_url=config.CLOUD_BASE_URL,\n",
        ")\n",
        "\n",
        "# 配置Embedding模型（使用OpenAI兼容的API）\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    api_key=config.CLOUD_API_KEY,\n",
        "    base_url=config.CLOUD_BASE_URL\n",
        ")\n",
        "\n",
        "print(\"环境配置完成！\")\n",
        "print(f\"Chat模型: {model.model_name}\")\n",
        "print(f\"Embedding模型: {embeddings.model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Embeddings（嵌入）\n",
        "\n",
        "### 什么是Embeddings？\n",
        "\n",
        "Embeddings是将文本转换为固定长度的数字向量的过程。这些向量捕获了文本的语义含义。\n",
        "\n",
        "### 核心特点\n",
        "\n",
        "1. **语义捕获**：相似含义的文本会产生相近的向量\n",
        "2. **固定维度**：无论文本长短，都转换为相同维度的向量\n",
        "3. **可计算**：可以用数学方法计算向量之间的相似度\n",
        "\n",
        "### 为什么重要？\n",
        "\n",
        "```\n",
        "传统关键词搜索：\n",
        "查询：\"机器学习\"\n",
        "只能匹配包含\"机器学习\"的文档\n",
        "\n",
        "语义搜索（基于Embeddings）：\n",
        "查询：\"机器学习\"\n",
        "可以匹配：\n",
        "- \"机器学习\"（完全匹配）\n",
        "- \"深度学习\"（相关概念）\n",
        "- \"神经网络\"（相关概念）\n",
        "- \"AI算法\"（相关领域）\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【示例1：生成文本Embedding】\n",
            "\n",
            "原始文本: 人工智能正在改变世界\n",
            "向量维度: 1536\n",
            "向量前10个元素: [0.036390144377946854, 0.0006589797558262944, 0.04068123549222946, 0.05586833879351616, 0.033466313034296036, -0.03420253098011017, -0.012526202946901321, 0.07564102113246918, -0.007078198716044426, -0.01901542767882347]\n",
            "\n",
            "说明：文本被转换为1536维的向量（具体维度取决于模型）\n"
          ]
        }
      ],
      "source": [
        "### 2.1 生成单个文本的Embedding\n",
        "\n",
        "print(\"【示例1：生成文本Embedding】\")\n",
        "print()\n",
        "\n",
        "# 生成单个文本的embedding\n",
        "text = \"人工智能正在改变世界\"\n",
        "embedding = embeddings.embed_query(text)\n",
        "\n",
        "print(f\"原始文本: {text}\")\n",
        "print(f\"向量维度: {len(embedding)}\")\n",
        "print(f\"向量前10个元素: {embedding[:10]}\")\n",
        "print()\n",
        "print(\"说明：文本被转换为1536维的向量（具体维度取决于模型）\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【示例2：批量生成Embeddings】\n",
            "\n",
            "处理了 4 个文本\n",
            "每个向量的维度: 1536\n",
            "\n",
            "文本 1: 机器学习是人工智能的一个分支\n",
            "  向量前5个元素: [0.021642746403813362, 0.003563135163858533, 0.0028191087767481804, -0.0396449975669384, 0.04252098873257637]\n",
            "\n",
            "文本 2: 深度学习使用多层神经网络\n",
            "  向量前5个元素: [-0.016283394768834114, -0.05267179757356644, 0.004675764590501785, -0.022784290835261345, 0.026668213307857513]\n",
            "\n",
            "文本 3: 今天天气很好，适合出门\n",
            "  向量前5个元素: [0.03830382227897644, 0.002759892027825117, -0.01888417638838291, -0.03285989537835121, 0.05365390703082085]\n",
            "\n",
            "文本 4: Python是一种编程语言\n",
            "  向量前5个元素: [0.009665939956903458, -0.029112696647644043, 0.0005882233381271362, -0.015951262786984444, 0.044801387935876846]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### 2.2 批量生成Embeddings\n",
        "\n",
        "print(\"【示例2：批量生成Embeddings】\")\n",
        "print()\n",
        "\n",
        "texts = [\n",
        "    \"机器学习是人工智能的一个分支\",\n",
        "    \"深度学习使用多层神经网络\",\n",
        "    \"今天天气很好，适合出门\",\n",
        "    \"Python是一种编程语言\"\n",
        "]\n",
        "\n",
        "# 批量生成embeddings（更高效）\n",
        "batch_embeddings = embeddings.embed_documents(texts)\n",
        "\n",
        "print(f\"处理了 {len(texts)} 个文本\")\n",
        "print(f\"每个向量的维度: {len(batch_embeddings[0])}\")\n",
        "print()\n",
        "for i, text in enumerate(texts):\n",
        "    print(f\"文本 {i+1}: {text}\")\n",
        "    print(f\"  向量前5个元素: {batch_embeddings[i][:5]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 相似度度量（Similarity Metrics）\n",
        "\n",
        "### 常用的相似度度量方法\n",
        "\n",
        "1. **余弦相似度（Cosine Similarity）**\n",
        "   - 测量两个向量之间的角度\n",
        "   - 值范围：-1到1（1表示完全相同，-1表示完全相反）\n",
        "   - 最常用的方法\n",
        "\n",
        "2. **欧氏距离（Euclidean Distance）**\n",
        "   - 测量两个向量之间的直线距离\n",
        "   - 值越小，相似度越高\n",
        "\n",
        "3. **点积（Dot Product）**\n",
        "   - 测量一个向量在另一个向量上的投影\n",
        "   - 值越大，相似度越高"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【示例3：计算文本相似度】\n",
            "\n",
            "查询文本: 机器学习算法\n",
            "\n",
            "相似度结果：\n",
            "1. 深度学习是机器学习的子领域\n",
            "   余弦相似度: 0.5208\n",
            "\n",
            "2. 今天天气很好\n",
            "   余弦相似度: 0.1055\n",
            "\n",
            "3. 神经网络是深度学习的基础\n",
            "   余弦相似度: 0.3786\n",
            "\n",
            "4. 我喜欢吃苹果\n",
            "   余弦相似度: 0.1145\n",
            "\n",
            "按相似度排序后：\n",
            "1. [0.5208] 深度学习是机器学习的子领域\n",
            "2. [0.3786] 神经网络是深度学习的基础\n",
            "3. [0.1145] 我喜欢吃苹果\n",
            "4. [0.1055] 今天天气很好\n"
          ]
        }
      ],
      "source": [
        "### 3.1 计算文本相似度\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"【示例3：计算文本相似度】\")\n",
        "print()\n",
        "\n",
        "# 定义余弦相似度函数\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"计算两个向量的余弦相似度\"\"\"\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm1 = np.linalg.norm(vec1)\n",
        "    norm2 = np.linalg.norm(vec2)\n",
        "    return dot_product / (norm1 * norm2)\n",
        "\n",
        "# 准备测试文本\n",
        "query = \"机器学习算法\"\n",
        "texts = [\n",
        "    \"深度学习是机器学习的子领域\",    # 高度相关\n",
        "    \"今天天气很好\",                   # 不相关\n",
        "    \"神经网络是深度学习的基础\",      # 相关\n",
        "    \"我喜欢吃苹果\"                    # 不相关\n",
        "]\n",
        "\n",
        "# 生成embeddings\n",
        "query_embedding = embeddings.embed_query(query)\n",
        "text_embeddings = embeddings.embed_documents(texts)\n",
        "\n",
        "# 计算相似度\n",
        "print(f\"查询文本: {query}\")\n",
        "print()\n",
        "print(\"相似度结果：\")\n",
        "similarities = []\n",
        "for i, text in enumerate(texts):\n",
        "    similarity = cosine_similarity(query_embedding, text_embeddings[i])\n",
        "    similarities.append((text, similarity))\n",
        "    print(f\"{i+1}. {text}\")\n",
        "    print(f\"   余弦相似度: {similarity:.4f}\")\n",
        "    print()\n",
        "\n",
        "# 按相似度排序\n",
        "similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "print(\"按相似度排序后：\")\n",
        "for i, (text, sim) in enumerate(similarities, 1):\n",
        "    print(f\"{i}. [{sim:.4f}] {text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Vector Stores\n",
        "\n",
        "### 什么是Vector Store？\n",
        "\n",
        "Vector Store是专门用于存储和检索向量的数据库。\n",
        "\n",
        "### 工作流程\n",
        "\n",
        "索引阶段：文档 → Embedding模型 → 向量 → Vector Store\n",
        "\n",
        "查询阶段：查询文本 → Embedding模型 → 查询向量 → 相似度搜索 → Top-K结果\n",
        "\n",
        "### 常用的Vector Store\n",
        "\n",
        "- InMemoryVectorStore：内存向量存储（开发测试）\n",
        "- Chroma：开源向量数据库\n",
        "- FAISS：Facebook的高性能向量检索库\n",
        "- Pinecone：托管向量数据库服务\n",
        "- Qdrant：高性能向量搜索引擎"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【示例4：使用InMemoryVectorStore】\n",
            "\n",
            "成功添加 5 个文档\n",
            "文档IDs: ['9b96c217-e1d1-4fb1-b7c0-5078215059cf', '8f761c5a-873c-4aad-8b62-e687edbb9b86', '679ae15c-6a0e-44f8-b315-fed47fbc44ab']...\n",
            "\n",
            "文档已被自动转换为向量并存储！\n"
          ]
        }
      ],
      "source": [
        "### 4.1 创建Vector Store并添加文档\n",
        "\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "print(\"【示例4：使用InMemoryVectorStore】\")\n",
        "print()\n",
        "\n",
        "# 创建Vector Store\n",
        "vector_store = InMemoryVectorStore(embeddings)\n",
        "\n",
        "# 准备文档\n",
        "documents = [\n",
        "    Document(page_content=\"LangChain是一个用于构建LLM应用的框架\", metadata={\"source\": \"doc1\", \"topic\": \"框架\"}),\n",
        "    Document(page_content=\"RAG是检索增强生成技术\", metadata={\"source\": \"doc2\", \"topic\": \"技术\"}),\n",
        "    Document(page_content=\"向量数据库用于存储和检索向量\", metadata={\"source\": \"doc3\", \"topic\": \"数据库\"}),\n",
        "    Document(page_content=\"Embedding将文本转换为向量\", metadata={\"source\": \"doc4\", \"topic\": \"技术\"}),\n",
        "    Document(page_content=\"今天是个好天气\", metadata={\"source\": \"doc5\", \"topic\": \"天气\"}),\n",
        "]\n",
        "\n",
        "# 添加文档到vector store\n",
        "ids = vector_store.add_documents(documents)\n",
        "\n",
        "print(f\"成功添加 {len(documents)} 个文档\")\n",
        "print(f\"文档IDs: {ids[:3]}...\")\n",
        "print()\n",
        "print(\"文档已被自动转换为向量并存储！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【示例5：相似度搜索】\n",
            "\n",
            "查询: 什么是RAG技术？\n",
            "\n",
            "搜索结果：\n",
            "1. RAG是检索增强生成技术\n",
            "   元数据: {'source': 'doc2', 'topic': '技术'}\n",
            "\n",
            "2. 向量数据库用于存储和检索向量\n",
            "   元数据: {'source': 'doc3', 'topic': '数据库'}\n",
            "\n",
            "3. LangChain是一个用于构建LLM应用的框架\n",
            "   元数据: {'source': 'doc1', 'topic': '框架'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### 4.2 相似度搜索\n",
        "\n",
        "print(\"【示例5：相似度搜索】\")\n",
        "print()\n",
        "\n",
        "# 搜索查询\n",
        "query = \"什么是RAG技术？\"\n",
        "\n",
        "# 执行相似度搜索（返回最相关的3个文档）\n",
        "results = vector_store.similarity_search(query, k=3)\n",
        "\n",
        "print(f\"查询: {query}\")\n",
        "print()\n",
        "print(\"搜索结果：\")\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"{i}. {doc.page_content}\")\n",
        "    print(f\"   元数据: {doc.metadata}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【示例6：带相似度分数的搜索】\n",
            "\n",
            "查询: 向量嵌入\n",
            "\n",
            "搜索结果（带分数）：\n",
            "1. [分数: 0.5969] 向量数据库用于存储和检索向量\n",
            "   元数据: {'source': 'doc3', 'topic': '数据库'}\n",
            "\n",
            "2. [分数: 0.5316] Embedding将文本转换为向量\n",
            "   元数据: {'source': 'doc4', 'topic': '技术'}\n",
            "\n",
            "3. [分数: 0.3213] RAG是检索增强生成技术\n",
            "   元数据: {'source': 'doc2', 'topic': '技术'}\n",
            "\n",
            "注意：分数越低表示相似度越高（这是距离度量）\n"
          ]
        }
      ],
      "source": [
        "### 4.3 带相似度分数的搜索\n",
        "\n",
        "print(\"【示例6：带相似度分数的搜索】\")\n",
        "print()\n",
        "\n",
        "query = \"向量嵌入\"\n",
        "\n",
        "# 返回文档和相似度分数\n",
        "results_with_scores = vector_store.similarity_search_with_score(query, k=3)\n",
        "\n",
        "print(f\"查询: {query}\")\n",
        "print()\n",
        "print(\"搜索结果（带分数）：\")\n",
        "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
        "    print(f\"{i}. [分数: {score:.4f}] {doc.page_content}\")\n",
        "    print(f\"   元数据: {doc.metadata}\")\n",
        "    print()\n",
        "\n",
        "print(\"注意：分数越低表示相似度越高（这是距离度量）\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【示例7：基于元数据的过滤搜索】\n",
            "\n",
            "查询: 技术\n",
            "过滤条件: topic='技术'\n",
            "\n",
            "搜索结果：\n",
            "1. RAG是检索增强生成技术\n",
            "   元数据: {'source': 'doc2', 'topic': '技术'}\n",
            "\n",
            "2. Embedding将文本转换为向量\n",
            "   元数据: {'source': 'doc4', 'topic': '技术'}\n",
            "\n",
            "只返回了符合过滤条件的文档！\n"
          ]
        }
      ],
      "source": [
        "### 4.4 元数据过滤\n",
        "\n",
        "print(\"【示例7：基于元数据的过滤搜索】\")\n",
        "print()\n",
        "\n",
        "query = \"技术\"\n",
        "\n",
        "# 定义过滤函数：只保留topic为\"技术\"的文档\n",
        "def filter_func(doc: Document) -> bool:\n",
        "    # 防止元数据中没有topic字段导致KeyError\n",
        "    return doc.metadata.get(\"topic\") == \"技术\"\n",
        "\n",
        "# 只搜索topic为\"技术\"的文档\n",
        "results = vector_store.similarity_search(\n",
        "    query, \n",
        "    k=3,\n",
        "    filter=filter_func  # 关键：传入函数而非字典\n",
        ")\n",
        "\n",
        "print(f\"查询: {query}\")\n",
        "print(f\"过滤条件: topic='技术'\")\n",
        "print()\n",
        "print(\"搜索结果：\")\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"{i}. {doc.page_content}\")\n",
        "    print(f\"   元数据: {doc.metadata}\")\n",
        "    print()\n",
        "\n",
        "print(\"只返回了符合过滤条件的文档！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 完整流程：从文档处理到语义搜索\n",
        "\n",
        "现在让我们结合第06章学到的文档处理知识，实现一个完整的语义搜索系统。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【完整流程演示】\n",
            "\n",
            "步骤1：加载文档\n",
            "  加载了 1 个文档\n",
            "\n",
            "步骤2：分割文档\n",
            "  分割成 3 个块\n",
            "\n",
            "步骤3：创建向量存储并索引文档\n",
            "  已索引 3 个文档块\n",
            "\n",
            "步骤4：语义搜索\n",
            "\n",
            "查询: LangChain的核心功能是什么？\n",
            "  结果1: 2. 提示词管理\n",
            "LangChain提供了强大的提示词模板系统，支持动态变量、条件逻辑和少样本学习。\n",
            "\n",
            "3. 链式调用\n",
            "通过LCEL（LangChain Exp...\n",
            "  结果2: LangChain简介\n",
            "\n",
            "LangChain是一个强大的框架，专门用于构建基于大型语言模型（LLM）的应用程序。它提供了一套完整的工具链，帮助开发者快速构建智能...\n",
            "\n",
            "查询: 支持哪些模型提供商？\n",
            "  结果1: LangChain简介\n",
            "\n",
            "LangChain是一个强大的框架，专门用于构建基于大型语言模型（LLM）的应用程序。它提供了一套完整的工具链，帮助开发者快速构建智能...\n",
            "  结果2: 5. Agent框架\n",
            "LangChain提供了Agent框架，使模型能够自主决策和使用工具。\n",
            "\n",
            "应用场景\n",
            "\n",
            "- 问答系统\n",
            "- 文档分析\n",
            "- 代码生成\n",
            "- 对话机...\n",
            "\n",
            "完成！语义搜索系统已就绪。\n"
          ]
        }
      ],
      "source": [
        "print(\"【完整流程演示】\")\n",
        "print()\n",
        "\n",
        "# 步骤1：加载和分割文档\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "print(\"步骤1：加载文档\")\n",
        "loader = TextLoader(\"../data/langchain_intro.txt\", encoding=\"utf-8\")\n",
        "docs = loader.load()\n",
        "print(f\"  加载了 {len(docs)} 个文档\")\n",
        "\n",
        "# 步骤2：分割文档\n",
        "print(\"\\n步骤2：分割文档\")\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "splits = text_splitter.split_documents(docs)\n",
        "print(f\"  分割成 {len(splits)} 个块\")\n",
        "\n",
        "# 步骤3：创建Vector Store并索引\n",
        "print(\"\\n步骤3：创建向量存储并索引文档\")\n",
        "vector_store = InMemoryVectorStore(embeddings)\n",
        "vector_store.add_documents(splits)\n",
        "print(f\"  已索引 {len(splits)} 个文档块\")\n",
        "\n",
        "# 步骤4：执行语义搜索\n",
        "print(\"\\n步骤4：语义搜索\")\n",
        "queries = [\n",
        "    \"LangChain的核心功能是什么？\",\n",
        "    \"支持哪些模型提供商？\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    print(f\"\\n查询: {query}\")\n",
        "    results = vector_store.similarity_search(query, k=2)\n",
        "    for i, doc in enumerate(results, 1):\n",
        "        print(f\"  结果{i}: {doc.page_content[:80]}...\")\n",
        "        \n",
        "print(\"\\n完成！语义搜索系统已就绪。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 实战项目：智能文档问答系统\n",
        "\n",
        "构建一个完整的文档问答系统，能够：\n",
        "1. 索引多个文档\n",
        "2. 理解自然语言查询\n",
        "3. 返回相关文档片段\n",
        "4. 使用LLM生成答案"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【智能文档问答系统】\n",
            "\n",
            "已索引 4 个文档，总计 4 个\n",
            "\n",
            "============================================================\n",
            "\n",
            "问题: LangChain是什么？\n",
            "答案: LangChain是一个开源框架，用于开发由语言模型驱动的应用程序。\n",
            "\n",
            "参考文档:\n",
            "  1. LangChain是一个开源框架，用于开发由语言模型驱动的应用程序。\n",
            "  2. LangChain提供了Document Loaders、Text Splitters、Vector Stores等工具。\n",
            "============================================================\n",
            "\n",
            "问题: LangChain支持哪些模型？\n",
            "答案: LangChain支持OpenAI、Anthropic、Google等多个模型提供商的模型。\n",
            "\n",
            "参考文档:\n",
            "  1. LangChain支持OpenAI、Anthropic、Google等多个模型提供商。\n",
            "  2. LangChain是一个开源框架，用于开发由语言模型驱动的应用程序。\n",
            "============================================================\n",
            "\n",
            "问题: 什么是RAG？\n",
            "答案: RAG（检索增强生成）是LangChain的核心应用场景，它结合了检索和生成。\n",
            "\n",
            "参考文档:\n",
            "  1. RAG（检索增强生成）是LangChain的核心应用场景，它结合了检索和生成。\n",
            "  2. LangChain是一个开源框架，用于开发由语言模型驱动的应用程序。\n",
            "============================================================\n",
            "\n",
            "智能问答系统演示完成！\n"
          ]
        }
      ],
      "source": [
        "print(\"【智能文档问答系统】\")\n",
        "print()\n",
        "\n",
        "class DocumentQA:\n",
        "    \"\"\"智能文档问答系统\"\"\"\n",
        "    \n",
        "    def __init__(self, embeddings, llm):\n",
        "        self.embeddings = embeddings\n",
        "        self.llm = llm\n",
        "        self.vector_store = InMemoryVectorStore(embeddings)\n",
        "        self.doc_count = 0\n",
        "    \n",
        "    def index_documents(self, documents):\n",
        "        \"\"\"索引文档\"\"\"\n",
        "        self.vector_store.add_documents(documents)\n",
        "        self.doc_count += len(documents)\n",
        "        return f\"已索引 {len(documents)} 个文档，总计 {self.doc_count} 个\"\n",
        "    \n",
        "    def search(self, query, k=3):\n",
        "        \"\"\"搜索相关文档\"\"\"\n",
        "        return self.vector_store.similarity_search(query, k=k)\n",
        "    \n",
        "    def ask(self, question, k=3):\n",
        "        \"\"\"问答：检索相关文档并生成答案\"\"\"\n",
        "        # 1. 检索相关文档\n",
        "        relevant_docs = self.search(question, k=k)\n",
        "        \n",
        "        # 2. 构建上下文\n",
        "        context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "        \n",
        "        # 3. 构建提示词\n",
        "        prompt = f\"\"\"基于以下文档内容回答问题。如果文档中没有相关信息，请说\"我不知道\"。\n",
        "\n",
        "文档内容：\n",
        "{context}\n",
        "\n",
        "问题：{question}\n",
        "\n",
        "回答：\"\"\"\n",
        "        \n",
        "        # 4. 生成答案\n",
        "        response = self.llm.invoke(prompt)\n",
        "        \n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"answer\": response.content,\n",
        "            \"sources\": relevant_docs\n",
        "        }\n",
        "\n",
        "# 创建问答系统\n",
        "qa_system = DocumentQA(embeddings, model)\n",
        "\n",
        "# 准备测试文档\n",
        "test_docs = [\n",
        "    Document(page_content=\"LangChain是一个开源框架，用于开发由语言模型驱动的应用程序。\", \n",
        "             metadata={\"source\": \"intro\"}),\n",
        "    Document(page_content=\"LangChain支持OpenAI、Anthropic、Google等多个模型提供商。\", \n",
        "             metadata={\"source\": \"models\"}),\n",
        "    Document(page_content=\"RAG（检索增强生成）是LangChain的核心应用场景，它结合了检索和生成。\", \n",
        "             metadata={\"source\": \"rag\"}),\n",
        "    Document(page_content=\"LangChain提供了Document Loaders、Text Splitters、Vector Stores等工具。\", \n",
        "             metadata={\"source\": \"tools\"}),\n",
        "]\n",
        "\n",
        "# 索引文档\n",
        "print(qa_system.index_documents(test_docs))\n",
        "print()\n",
        "\n",
        "# 测试问答\n",
        "questions = [\n",
        "    \"LangChain是什么？\",\n",
        "    \"LangChain支持哪些模型？\",\n",
        "    \"什么是RAG？\"\n",
        "]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "for question in questions:\n",
        "    result = qa_system.ask(question, k=2)\n",
        "    print(f\"\\n问题: {result['question']}\")\n",
        "    print(f\"答案: {result['answer']}\")\n",
        "    print(f\"\\n参考文档:\")\n",
        "    for i, doc in enumerate(result['sources'], 1):\n",
        "        print(f\"  {i}. {doc.page_content}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n智能问答系统演示完成！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 总结与最佳实践\n",
        "\n",
        "### 核心概念回顾\n",
        "\n",
        "1. Embeddings：将文本转换为向量，捕获语义信息\n",
        "2. Vector Stores：存储和检索向量\n",
        "3. 相似度度量：余弦相似度、欧氏距离、点积\n",
        "4. 语义搜索：基于含义而非关键词的搜索\n",
        "\n",
        "### 关键要点\n",
        "\n",
        "- 使用embed_query()处理查询，embed_documents()批量处理\n",
        "- Vector Store提供add_documents()和similarity_search()方法\n",
        "- 元数据过滤可以提高检索精度\n",
        "- k值通常设置为3-5\n",
        "\n",
        "### 最佳实践\n",
        "\n",
        "1. 选择合适的Embedding模型和维度\n",
        "2. 合理设置文档分割大小\n",
        "3. 充分利用元数据\n",
        "4. 根据应用选择合适的Vector Store\n",
        "\n",
        "### 常见陷阱\n",
        "\n",
        "- 索引和查询使用不同的embedding模型\n",
        "- 文档太长没有分割\n",
        "- k值设置不当\n",
        "- 忽略元数据的作用"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
