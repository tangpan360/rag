{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ç¬¬03ç« ï¼šLCELåŸºç¡€ï¼ˆLangChain Expression Languageï¼‰\n",
        "\n",
        "## æœ¬ç« å­¦ä¹ ç›®æ ‡\n",
        "\n",
        "1. ç†è§£LCELçš„æ¦‚å¿µå’Œé‡è¦æ€§\n",
        "2. æŒæ¡Runnableæ¥å£å’Œåè®®\n",
        "3. å­¦ä¼šä½¿ç”¨Pipeæ“ä½œç¬¦ï¼ˆ|ï¼‰ç»„åˆç»„ä»¶\n",
        "4. æŒæ¡@chainè£…é¥°å™¨åˆ›å»ºè‡ªå®šä¹‰Runnable\n",
        "5. ç†è§£RunnableLambdaçš„ä½œç”¨\n",
        "6. å­¦ä¹ æ•°æ®ä¼ é€’å’Œæµå¼å¤„ç†æ¨¡å¼\n",
        "7. æ„å»ºå¤æ‚çš„å¤„ç†é“¾\n",
        "\n",
        "## æ ¸å¿ƒæ¦‚å¿µ\n",
        "\n",
        "- **LCEL**ï¼šLangChain Expression Languageï¼ŒLangChainçš„æ ¸å¿ƒè¯­æ³•\n",
        "- **Runnable**ï¼šLangChainä¸­æ‰€æœ‰ç»„ä»¶çš„æ ‡å‡†æ¥å£\n",
        "- **Pipeæ“ä½œç¬¦ï¼ˆ|ï¼‰**ï¼šç”¨äºè¿æ¥å’Œç»„åˆä¸åŒç»„ä»¶\n",
        "- **@chainè£…é¥°å™¨**ï¼šåˆ›å»ºè‡ªå®šä¹‰Runnableçš„æ ‡å‡†æ–¹å¼\n",
        "- **RunnableLambda**ï¼šå°†æ™®é€šå‡½æ•°è½¬æ¢ä¸ºRunnable\n",
        "\n",
        "## é‡è¦è¯´æ˜\n",
        "\n",
        "LCELæ˜¯LangChain v1çš„æ ¸å¿ƒï¼Œè®©ç»„ä»¶ç»„åˆå˜å¾—ç®€æ´è€Œå¼ºå¤§ã€‚æœ¬ç« å°†ç³»ç»Ÿå­¦ä¹ è¿™ä¸ªå¼ºå¤§çš„è¯­æ³•ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ç¯å¢ƒé…ç½®å®Œæˆ\n",
            "LCELå­¦ä¹ å¼€å§‹ï¼\n"
          ]
        }
      ],
      "source": [
        "# ç¯å¢ƒé…ç½®\n",
        "import os\n",
        "import sys\n",
        "\n",
        "_project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "sys.path.append(_project_root)\n",
        "\n",
        "from config import config\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# åˆå§‹åŒ–æ¨¡å‹\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.7,\n",
        "    api_key=config.OPENAI_API_KEY,\n",
        "    base_url=config.OPENAI_BASE_URL,\n",
        ")\n",
        "\n",
        "print(\"ç¯å¢ƒé…ç½®å®Œæˆ\")\n",
        "print(\"LCELå­¦ä¹ å¼€å§‹ï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ä»€ä¹ˆæ˜¯LCELï¼Ÿ\n",
        "\n",
        "**LCEL (LangChain Expression Language)**æ˜¯LangChainçš„æ ¸å¿ƒè¯­æ³•ï¼Œå®ƒè®©ä½ èƒ½å¤Ÿï¼š\n",
        "\n",
        "### æ ¸å¿ƒç‰¹ç‚¹\n",
        "\n",
        "| ç‰¹ç‚¹ | è¯´æ˜ | ä¼˜åŠ¿ |\n",
        "|------|------|------|\n",
        "| **ç»Ÿä¸€æ¥å£** | æ‰€æœ‰ç»„ä»¶éƒ½å®ç°Runnableæ¥å£ | ä¸€è‡´çš„ä½¿ç”¨æ–¹å¼ |\n",
        "| **å¯ç»„åˆæ€§** | ä½¿ç”¨Pipeæ“ä½œç¬¦ï¼ˆ`\\|`ï¼‰è¿æ¥ç»„ä»¶ | ç®€æ´çš„ä»£ç  |\n",
        "| **æµå¼æ”¯æŒ** | è‡ªåŠ¨æ”¯æŒæµå¼å¤„ç† | æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ |\n",
        "| **å¹¶è¡Œæ‰§è¡Œ** | æ”¯æŒbatchæ‰¹é‡å¤„ç† | æ›´é«˜çš„æ€§èƒ½ |\n",
        "| **æ ‡å‡†åŒ–** | invokeã€streamã€batchç­‰æ ‡å‡†æ–¹æ³• | æ˜“äºå­¦ä¹ å’Œä½¿ç”¨ |\n",
        "\n",
        "### ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ\n",
        "\n",
        "åœ¨ç¬¬02ç« ä¸­ï¼Œæˆ‘ä»¬è¿™æ ·è°ƒç”¨æ¨¡å‹ï¼š\n",
        "```python\n",
        "messages = prompt.format_messages(topic=\"AI\")\n",
        "response = model.invoke(messages)\n",
        "```\n",
        "\n",
        "ä½¿ç”¨LCELï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·ï¼š\n",
        "```python\n",
        "chain = prompt | model\n",
        "response = chain.invoke({\"topic\": \"AI\"})\n",
        "```\n",
        "\n",
        "**æ›´ç®€æ´ã€æ›´å¼ºå¤§ã€æ›´æ˜“ç»´æŠ¤ï¼**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€éªŒè¯Runnableæ¥å£ã€‘\n",
            "ChatOpenAIæ˜¯Runnable: True\n",
            "ChatPromptTemplateæ˜¯Runnable: True\n",
            "\n",
            "ã€æŸ¥çœ‹æ ‡å‡†æ–¹æ³•ã€‘\n",
            "  invoke(): Model=True, Prompt=True\n",
            "  stream(): Model=True, Prompt=True\n",
            "  batch(): Model=True, Prompt=True\n",
            "\n",
            "ã€æµ‹è¯•Promptçš„Runnableæ–¹æ³•ã€‘\n",
            "Prompt.invoke()è¿”å›: <class 'langchain_core.prompt_values.ChatPromptValue'>\n"
          ]
        }
      ],
      "source": [
        "# éªŒè¯ä¸åŒç»„ä»¶éƒ½æ˜¯Runnable\n",
        "from langchain_core.runnables import Runnable\n",
        "\n",
        "# åˆ›å»ºç»„ä»¶\n",
        "prompt = ChatPromptTemplate.from_template(\"ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯\")\n",
        "\n",
        "print(\"ã€éªŒè¯Runnableæ¥å£ã€‘\")\n",
        "print(f\"ChatOpenAIæ˜¯Runnable: {isinstance(model, Runnable)}\")\n",
        "print(f\"ChatPromptTemplateæ˜¯Runnable: {isinstance(prompt, Runnable)}\")\n",
        "\n",
        "print(\"\\nã€æŸ¥çœ‹æ ‡å‡†æ–¹æ³•ã€‘\")\n",
        "runnable_methods = ['invoke', 'stream', 'batch']\n",
        "for method in runnable_methods:\n",
        "    has_model = hasattr(model, method)\n",
        "    has_prompt = hasattr(prompt, method)\n",
        "    print(f\"  {method}(): Model={has_model}, Prompt={has_prompt}\")\n",
        "\n",
        "print(\"\\nã€æµ‹è¯•Promptçš„Runnableæ–¹æ³•ã€‘\")\n",
        "# Promptä¹Ÿå¯ä»¥ç›´æ¥invoke\n",
        "formatted_messages = prompt.invoke({\"topic\": \"ç¨‹åºå‘˜\"})\n",
        "print(f\"Prompt.invoke()è¿”å›: {type(formatted_messages)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€ç¬¬ä¸€ä¸ªLCEL Chainã€‘\n",
            "Chainç±»å‹: <class 'langchain_core.runnables.base.RunnableSequence'>\n",
            "Chainæ˜¯Runnable: True\n",
            "\n",
            "è¾“å…¥: language='æ³•è¯­', message='ä½ å¥½ï¼Œä¸–ç•Œ'\n",
            "è¾“å‡º: ä½ å¥½ï¼Œä¸–ç•Œç”¨æ³•è¯­å¯ä»¥è¯´æˆâ€œBonjour, le mondeâ€ã€‚\n",
            "\n",
            "============================================================\n",
            "\n",
            "ã€Chainçš„æµå¼è¾“å‡ºã€‘\n",
            "AIå›å¤ï¼ˆæµå¼ï¼‰ï¼šç”¨æ—¥è¯­è¯´â€œè°¢è°¢â€æ˜¯ã€Œã‚ã‚ŠãŒã¨ã†ã€(arigatou)ã€‚\n"
          ]
        }
      ],
      "source": [
        "# ç¬¬ä¸€ä¸ªLCEL Chain\n",
        "prompt = ChatPromptTemplate.from_template(\"è¯·ç”¨{language}è¯­è¨€è¯´'{message}'\")\n",
        "\n",
        "# ä½¿ç”¨Pipeæ“ä½œç¬¦åˆ›å»ºChain\n",
        "chain = prompt | model\n",
        "\n",
        "print(\"ã€ç¬¬ä¸€ä¸ªLCEL Chainã€‘\")\n",
        "print(\"Chainç±»å‹:\", type(chain))\n",
        "print(\"Chainæ˜¯Runnable:\", isinstance(chain, Runnable))\n",
        "\n",
        "# è°ƒç”¨Chain\n",
        "result = chain.invoke({\n",
        "    \"language\": \"æ³•è¯­\", \n",
        "    \"message\": \"ä½ å¥½ï¼Œä¸–ç•Œ\"\n",
        "})\n",
        "\n",
        "print(f\"\\nè¾“å…¥: language='æ³•è¯­', message='ä½ å¥½ï¼Œä¸–ç•Œ'\")\n",
        "print(f\"è¾“å‡º: {result.content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Chainä¹Ÿæ”¯æŒæ‰€æœ‰Runnableæ–¹æ³•\n",
        "print(\"\\nã€Chainçš„æµå¼è¾“å‡ºã€‘\")\n",
        "print(\"AIå›å¤ï¼ˆæµå¼ï¼‰ï¼š\", end=\"\", flush=True)\n",
        "for chunk in chain.stream({\"language\": \"æ—¥è¯­\", \"message\": \"è°¢è°¢\"}):\n",
        "    print(chunk.content, end=\"\", flush=True)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€@chainè£…é¥°å™¨ç¤ºä¾‹ã€‘\n",
            "format_responseæ˜¯Runnable: True\n",
            "\n",
            "æ ¼å¼åŒ–ç»“æœ:\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘              AI å›å¤                 â•‘\n",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
            "â•‘                 ä½ å¥½ï¼                  â•‘\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "============================================================\n",
            "\n",
            "ã€æ‰©å±•çš„Chainã€‘\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘              AI å›å¤                 â•‘\n",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
            "â•‘           å­¦ä¹ LangChainå¾ˆæœ‰è¶£ã€‚            â•‘\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import chain as chain_decorator\n",
        "\n",
        "# ä½¿ç”¨@chainè£…é¥°å™¨åˆ›å»ºè‡ªå®šä¹‰å¤„ç†å‡½æ•°\n",
        "@chain_decorator\n",
        "def format_response(ai_message):\n",
        "    \"\"\"æ ¼å¼åŒ–AIå›å¤ï¼Œæ·»åŠ è£…é¥°\"\"\"\n",
        "    content = ai_message.content\n",
        "    formatted = f\"\"\"\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘              AI å›å¤                 â•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
        "â•‘ {content:^36} â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\"\"\"\n",
        "    return formatted.strip()\n",
        "\n",
        "print(\"ã€@chainè£…é¥°å™¨ç¤ºä¾‹ã€‘\")\n",
        "print(f\"format_responseæ˜¯Runnable: {isinstance(format_response, Runnable)}\")\n",
        "\n",
        "# æµ‹è¯•è‡ªå®šä¹‰å‡½æ•°\n",
        "from langchain_core.messages import AIMessage\n",
        "test_message = AIMessage(content=\"ä½ å¥½ï¼\")\n",
        "result = format_response.invoke(test_message)\n",
        "print(f\"\\næ ¼å¼åŒ–ç»“æœ:\\n{result}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# å°†è‡ªå®šä¹‰å‡½æ•°åŠ å…¥Chain\n",
        "extended_chain = prompt | model | format_response\n",
        "\n",
        "print(\"\\nã€æ‰©å±•çš„Chainã€‘\")\n",
        "formatted_result = extended_chain.invoke({\n",
        "    \"language\": \"ä¸­æ–‡\", \n",
        "    \"message\": \"å­¦ä¹ LangChainå¾ˆæœ‰è¶£\"\n",
        "})\n",
        "print(formatted_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€Chainçš„æ‰¹é‡å¤„ç†ã€‘\n",
            "\n",
            "è¯·æ±‚ 1:\n",
            "  è¾“å…¥: {'language': 'è‹±è¯­', 'message': 'æ—©ä¸Šå¥½'}\n",
            "  è¾“å‡º: 'æ—©ä¸Šå¥½' in English is 'Good morning.'\n",
            "\n",
            "è¯·æ±‚ 2:\n",
            "  è¾“å…¥: {'language': 'è¥¿ç­ç‰™è¯­', 'message': 'æ™šå®‰'}\n",
            "  è¾“å‡º: 'æ™šå®‰'ç”¨è¥¿ç­ç‰™è¯­è¯´æ˜¯\"Buenas noches\"ã€‚\n",
            "\n",
            "è¯·æ±‚ 3:\n",
            "  è¾“å…¥: {'language': 'å¾·è¯­', 'message': 'å¾ˆé«˜å…´è®¤è¯†ä½ '}\n",
            "  è¾“å‡º: å¾ˆé«˜å…´è®¤è¯†ä½ ç”¨å¾·è¯­å¯ä»¥è¯´ï¼šâ€œFreut mich, dich kennenzulernen.â€\n"
          ]
        }
      ],
      "source": [
        "# Chainçš„æ‰¹é‡å¤„ç†\n",
        "chain = prompt | model\n",
        "\n",
        "print(\"ã€Chainçš„æ‰¹é‡å¤„ç†ã€‘\")\n",
        "\n",
        "inputs = [\n",
        "    {\"language\": \"è‹±è¯­\", \"message\": \"æ—©ä¸Šå¥½\"},\n",
        "    {\"language\": \"è¥¿ç­ç‰™è¯­\", \"message\": \"æ™šå®‰\"},\n",
        "    {\"language\": \"å¾·è¯­\", \"message\": \"å¾ˆé«˜å…´è®¤è¯†ä½ \"},\n",
        "]\n",
        "\n",
        "# æ‰¹é‡è°ƒç”¨\n",
        "responses = chain.batch(inputs)\n",
        "\n",
        "for i, (input_data, response) in enumerate(zip(inputs, responses), 1):\n",
        "    print(f\"\\nè¯·æ±‚ {i}:\")\n",
        "    print(f\"  è¾“å…¥: {input_data}\")\n",
        "    print(f\"  è¾“å‡º: {response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Pipeæ“ä½œç¬¦ï¼ˆ|ï¼‰- LCELçš„æ ¸å¿ƒ\n",
        "\n",
        "**Pipeæ“ä½œç¬¦ï¼ˆ`|`ï¼‰**æ˜¯LCELæœ€é‡è¦çš„è¯­æ³•ï¼Œç”¨äºè¿æ¥Runnableç»„ä»¶ã€‚\n",
        "\n",
        "### åŸºæœ¬è¯­æ³•\n",
        "\n",
        "```python\n",
        "# åŸºæœ¬æ¨¡å¼\n",
        "chain = component1 | component2 | component3\n",
        "\n",
        "# å…·ä½“ä¾‹å­\n",
        "chain = prompt | model\n",
        "```\n",
        "\n",
        "### å·¥ä½œåŸç†\n",
        "\n",
        "1. **æ•°æ®æµå‘**ï¼šæ•°æ®ä»å·¦åˆ°å³æµåŠ¨\n",
        "2. **è‡ªåŠ¨é€‚é…**ï¼šå‰ä¸€ä¸ªç»„ä»¶çš„è¾“å‡ºè‡ªåŠ¨æˆä¸ºä¸‹ä¸€ä¸ªç»„ä»¶çš„è¾“å…¥\n",
        "3. **ç±»å‹å®‰å…¨**ï¼šLangChainä¼šéªŒè¯ç»„ä»¶ä¹‹é—´çš„å…¼å®¹æ€§\n",
        "\n",
        "### ä¼˜åŠ¿\n",
        "\n",
        "- **ç®€æ´æ€§**ï¼šä¸€è¡Œä»£ç å®Œæˆå¤æ‚çš„ç»„åˆ\n",
        "- **å¯è¯»æ€§**ï¼šæ¸…æ™°è¡¨è¾¾æ•°æ®å¤„ç†æµç¨‹\n",
        "- **å¯ç»´æŠ¤æ€§**ï¼šå®¹æ˜“æ·»åŠ ã€åˆ é™¤æˆ–æ›¿æ¢ç»„ä»¶\n",
        "\n",
        "## 4. RunnableLambda - å‡½æ•°å¼ç¼–ç¨‹\n",
        "\n",
        "**RunnableLambda**å°†æ™®é€šå‡½æ•°è‡ªåŠ¨è½¬æ¢ä¸ºRunnableã€‚å®é™…ä¸Šï¼Œ@chainè£…é¥°å™¨å†…éƒ¨å°±æ˜¯ä½¿ç”¨RunnableLambdaã€‚\n",
        "\n",
        "### ä¸¤ç§åˆ›å»ºæ–¹å¼\n",
        "\n",
        "1. **ä½¿ç”¨@chainè£…é¥°å™¨**ï¼ˆæ¨èï¼‰\n",
        "2. **ç›´æ¥ä½¿ç”¨RunnableLambda**\n",
        "\n",
        "### ä½¿ç”¨åœºæ™¯\n",
        "\n",
        "- **æ•°æ®è½¬æ¢**ï¼šæ ¼å¼åŒ–ã€æ¸…ç†ã€è½¬æ¢æ•°æ®\n",
        "- **æ¡ä»¶é€»è¾‘**ï¼šæ ¹æ®è¾“å…¥å†…å®¹é€‰æ‹©ä¸åŒå¤„ç†\n",
        "- **å¤–éƒ¨APIè°ƒç”¨**ï¼šé›†æˆç¬¬ä¸‰æ–¹æœåŠ¡\n",
        "- **è‡ªå®šä¹‰å¤„ç†**ï¼šä»»ä½•ä½ éœ€è¦çš„è‡ªå®šä¹‰é€»è¾‘"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€RunnableLambdaç¤ºä¾‹ã€‘\n",
            "keyword_extractoræ˜¯Runnable: True\n",
            "\n",
            "å…³é”®è¯æå–ç»“æœ:\n",
            "  åŸæ–‡: æˆ‘æ­£åœ¨å­¦ä¹ Pythonå’ŒLangChainå¼€å‘AIåº”ç”¨ã€‚\n",
            "  å…³é”®è¯: ['python', 'langchain', 'ai', 'å­¦ä¹ ', 'å¼€å‘']\n",
            "  å…³é”®è¯æ•°é‡: 5\n",
            "\n",
            "============================================================\n",
            "\n",
            "ã€@chainè£…é¥°å™¨å¯¹æ¯”ã€‘\n",
            "æƒ…æ„Ÿåˆ†æç»“æœ:\n",
            "  æƒ…æ„Ÿ: ç§¯æ\n",
            "  åˆ†æ•°: 2\n",
            "  ç§¯æè¯æ•°: 2\n",
            "  æ¶ˆæè¯æ•°: 0\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# æ–¹å¼1ï¼šä½¿ç”¨RunnableLambdaï¼ˆæ˜¾å¼ï¼‰\n",
        "def extract_keywords(ai_message):\n",
        "    \"\"\"æå–å…³é”®è¯\"\"\"\n",
        "    content = ai_message.content.lower()\n",
        "    \n",
        "    # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…é¡¹ç›®ä¸­å¯èƒ½ä½¿ç”¨NLPåº“ï¼‰\n",
        "    keywords = []\n",
        "    key_phrases = [\"python\", \"langchain\", \"ai\", \"æ¨¡å‹\", \"å­¦ä¹ \", \"ç¼–ç¨‹\", \"å¼€å‘\"]\n",
        "    \n",
        "    for phrase in key_phrases:\n",
        "        if phrase in content:\n",
        "            keywords.append(phrase)\n",
        "    \n",
        "    return {\n",
        "        \"åŸæ–‡\": ai_message.content,\n",
        "        \"å…³é”®è¯\": keywords,\n",
        "        \"å…³é”®è¯æ•°é‡\": len(keywords)\n",
        "    }\n",
        "\n",
        "# æ˜¾å¼åˆ›å»ºRunnableLambda\n",
        "keyword_extractor = RunnableLambda(extract_keywords)\n",
        "\n",
        "print(\"ã€RunnableLambdaç¤ºä¾‹ã€‘\")\n",
        "print(f\"keyword_extractoræ˜¯Runnable: {isinstance(keyword_extractor, Runnable)}\")\n",
        "\n",
        "# åˆ›å»ºå…³é”®è¯æå–Chain\n",
        "keyword_chain = prompt | model | keyword_extractor\n",
        "\n",
        "result = keyword_chain.invoke({\n",
        "    \"language\": \"ä¸­æ–‡\",\n",
        "    \"message\": \"æˆ‘æ­£åœ¨å­¦ä¹ Pythonå’ŒLangChainå¼€å‘AIåº”ç”¨\"\n",
        "})\n",
        "\n",
        "print(\"\\nå…³é”®è¯æå–ç»“æœ:\")\n",
        "for key, value in result.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# æ–¹å¼2ï¼šä½¿ç”¨@chainè£…é¥°å™¨ï¼ˆæ¨èï¼‰\n",
        "@chain_decorator\n",
        "def sentiment_analyzer(ai_message):\n",
        "    \"\"\"æƒ…æ„Ÿåˆ†æå™¨\"\"\"\n",
        "    content = ai_message.content.lower()\n",
        "    \n",
        "    positive_words = [\"å¥½\", \"æ£’\", \"å–œæ¬¢\", \"å¼€å¿ƒ\", \"æ»¡æ„\", \"excellent\", \"great\", \"good\"]\n",
        "    negative_words = [\"å\", \"å·®\", \"ä¸å–œæ¬¢\", \"éš¾è¿‡\", \"ç³Ÿç³•\", \"bad\", \"terrible\", \"awful\"]\n",
        "    \n",
        "    positive_count = sum(1 for word in positive_words if word in content)\n",
        "    negative_count = sum(1 for word in negative_words if word in content)\n",
        "    \n",
        "    if positive_count > negative_count:\n",
        "        sentiment = \"ç§¯æ\"\n",
        "        score = positive_count - negative_count\n",
        "    elif negative_count > positive_count:\n",
        "        sentiment = \"æ¶ˆæ\"  \n",
        "        score = negative_count - positive_count\n",
        "    else:\n",
        "        sentiment = \"ä¸­æ€§\"\n",
        "        score = 0\n",
        "    \n",
        "    return {\n",
        "        \"æƒ…æ„Ÿ\": sentiment,\n",
        "        \"åˆ†æ•°\": score,\n",
        "        \"ç§¯æè¯æ•°\": positive_count,\n",
        "        \"æ¶ˆæè¯æ•°\": negative_count\n",
        "    }\n",
        "\n",
        "# åˆ›å»ºæƒ…æ„Ÿåˆ†æChain\n",
        "sentiment_chain = prompt | model | sentiment_analyzer\n",
        "\n",
        "print(\"\\nã€@chainè£…é¥°å™¨å¯¹æ¯”ã€‘\")\n",
        "sentiment_result = sentiment_chain.invoke({\n",
        "    \"language\": \"ä¸­æ–‡\", \n",
        "    \"message\": \"è¿™ä¸ªè¯¾ç¨‹çœŸçš„å¾ˆå¥½ï¼Œæˆ‘å¾ˆå–œæ¬¢ï¼\"\n",
        "})\n",
        "\n",
        "print(\"æƒ…æ„Ÿåˆ†æç»“æœ:\")\n",
        "for key, value in sentiment_result.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. å¤æ‚Chainç»„åˆ\n",
        "\n",
        "LCELçš„çœŸæ­£å¨åŠ›åœ¨äºç»„åˆå¤æ‚çš„å¤„ç†æµç¨‹ã€‚\n",
        "\n",
        "### ç»„åˆæ¨¡å¼\n",
        "\n",
        "```python\n",
        "# ç®€å•çº¿æ€§Chain\n",
        "chain = prompt | model | processor\n",
        "\n",
        "# å¤æ‚å¤„ç†Chain  \n",
        "complex_chain = (\n",
        "    input_processor \n",
        "    | prompt \n",
        "    | model \n",
        "    | output_formatter \n",
        "    | validator\n",
        ")\n",
        "```\n",
        "\n",
        "### è®¾è®¡åŸåˆ™\n",
        "\n",
        "1. **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªç»„ä»¶ä¸“æ³¨åšä¸€ä»¶äº‹\n",
        "2. **å¯ç»„åˆ**ï¼šç»„ä»¶ä¹‹é—´æ¾è€¦åˆ\n",
        "3. **å¯æµ‹è¯•**ï¼šæ¯ä¸ªç»„ä»¶éƒ½å¯ä»¥ç‹¬ç«‹æµ‹è¯•\n",
        "4. **å¯å¤ç”¨**ï¼šç»„ä»¶å¯ä»¥åœ¨ä¸åŒChainä¸­å¤ç”¨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€å¤æ‚Chainç¤ºä¾‹ã€‘\n",
            "åˆ†æå®Œæˆï¼\n",
            "æ—¶é—´æˆ³: 2024-01-15 10:30:00\n",
            "åˆ†æç»“æœ:\n",
            "å¥½çš„ï¼Œä»¥ä¸‹æ˜¯å¯¹è¯¥æ–‡æœ¬çš„å…¨é¢åˆ†æï¼š\n",
            "\n",
            "### 1. ä¸»é¢˜æ¦‚æ‹¬\n",
            "æ–‡æœ¬çš„ä¸»é¢˜å›´ç»•LangChainæ¡†æ¶å±•å¼€ï¼Œå¼ºè°ƒäº†å…¶åœ¨æ„å»ºè¯­è¨€æ¨¡å‹åº”ç”¨æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ã€‚æåˆ°çš„LCELï¼ˆLangChain Expression Languageï¼‰æä¾›äº†ä¸€ç§ç®€æ´çš„è¯­æ³•ï¼Œä½¿å¾—å¼€å‘è€…èƒ½å¤Ÿç»„åˆå¤æ‚çš„å¤„ç†æµç¨‹ï¼Œä»è€Œæé«˜å¼€å‘æ•ˆç‡ã€‚\n",
            "\n",
            "### 2. æƒ…æ„Ÿå€¾å‘\n",
            "æ–‡æœ¬æ•´ä½“å‘ˆç°å‡ºç§¯æçš„æƒ…æ„Ÿå€¾å‘ã€‚ä½¿ç”¨äº†â€œå¼ºå¤§â€ã€â€œè½»æ¾â€ã€â€œç®€æ´â€ã€â€œå¤ªæ£’äº†â€ç­‰æ­£é¢è¯æ±‡ï¼Œè¡¨è¾¾äº†å¯¹LangChainåŠå…¶åŠŸèƒ½çš„é«˜åº¦èµèµå’Œè®¤å¯ã€‚\n",
            "\n",
            "### 3. è¯­è¨€é£æ ¼\n",
            "æ–‡æœ¬ä½¿ç”¨äº†ç®€æ´æ˜äº†çš„è¯­è¨€é£æ ¼ï¼Œç›´æˆªäº†å½“åœ°ä¼ è¾¾äº†ä¿¡æ¯ã€‚å¥å­ç»“æ„ç®€å•ï¼Œæ˜“äºç†è§£ï¼Œé€‚åˆæŠ€æœ¯ç±»å†…å®¹çš„è¡¨è¾¾ã€‚æ­¤å¤–ï¼Œä½¿ç”¨äº†æ„Ÿå¹å¥ï¼ˆâ€œè¿™çœŸæ˜¯å¤ªæ£’äº†ï¼â€ï¼‰ï¼Œå¢åŠ äº†æƒ…æ„Ÿçš„è¡¨è¾¾ï¼Œä½¿å¾—å†…å®¹æ›´åŠ ç”ŸåŠ¨ã€‚\n",
            "\n",
            "### 4. å…³é”®ä¿¡æ¯\n",
            "- **LangChain**ï¼šä¸€ä¸ªæ¡†æ¶ï¼Œä¸“æ³¨äºæ„å»ºåŸºäºè¯­è¨€æ¨¡å‹çš„åº”ç”¨ã€‚\n",
            "- **LCEL**ï¼šLangChain Expression Languageï¼Œæä¾›ç®€æ´çš„è¯­æ³•ç”¨äºç»„åˆå¤æ‚å¤„ç†æµç¨‹ã€‚\n",
            "- **å¼€å‘è€…å—ç›Š**ï¼šå¼ºè°ƒäº†æ¡†æ¶çš„æ˜“ç”¨æ€§å’Œé«˜æ•ˆæ€§ï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿæ›´è½»æ¾åœ°è¿›è¡Œå¼€å‘ã€‚\n",
            "\n",
            "ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥æ–‡æœ¬ç®€æ´åœ°ä»‹ç»äº†LangChainæ¡†æ¶åŠå…¶è¯­è¨€å¤„ç†èƒ½åŠ›ï¼Œå±•ç°äº†ç§¯æçš„æƒ…æ„Ÿå€¾å‘ï¼Œå¹¶é‡‡ç”¨äº†æ˜“æ‡‚çš„è¯­è¨€é£æ ¼ã€‚\n",
            "çŠ¶æ€: åˆ†æå®Œæˆ\n",
            "å­—ç¬¦æ•°: 544\n"
          ]
        }
      ],
      "source": [
        "# æ„å»ºå¤æ‚çš„æ–‡æœ¬å¤„ç†Chain\n",
        "\n",
        "@chain_decorator\n",
        "def input_validator(input_data):\n",
        "    \"\"\"è¾“å…¥éªŒè¯å™¨\"\"\"\n",
        "    if not input_data.get(\"text\"):\n",
        "        raise ValueError(\"è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º\")\n",
        "    \n",
        "    text = input_data[\"text\"].strip()\n",
        "    if len(text) < 2:\n",
        "        raise ValueError(\"è¾“å…¥æ–‡æœ¬å¤ªçŸ­\")\n",
        "    \n",
        "    return {\"text\": text, \"original_length\": len(input_data[\"text\"])}\n",
        "\n",
        "@chain_decorator\n",
        "def text_preprocessor(data):\n",
        "    \"\"\"æ–‡æœ¬é¢„å¤„ç†å™¨\"\"\"\n",
        "    text = data[\"text\"]\n",
        "    \n",
        "    # æ¸…ç†å’Œæ ‡å‡†åŒ–\n",
        "    cleaned_text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
        "    while \"  \" in cleaned_text:\n",
        "        cleaned_text = cleaned_text.replace(\"  \", \" \")\n",
        "    \n",
        "    return {\n",
        "        **data,\n",
        "        \"cleaned_text\": cleaned_text,\n",
        "        \"word_count\": len(cleaned_text.split())\n",
        "    }\n",
        "\n",
        "@chain_decorator\n",
        "def create_analysis_prompt(data):\n",
        "    \"\"\"åˆ›å»ºåˆ†ææç¤ºè¯\"\"\"\n",
        "    text = data[\"cleaned_text\"]\n",
        "    \n",
        "    prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œå…¨é¢åˆ†æï¼š\n",
        "\n",
        "æ–‡æœ¬ï¼š{text}\n",
        "\n",
        "è¯·æä¾›ï¼š\n",
        "1. ä¸»é¢˜æ¦‚æ‹¬\n",
        "2. æƒ…æ„Ÿå€¾å‘\n",
        "3. è¯­è¨€é£æ ¼\n",
        "4. å…³é”®ä¿¡æ¯\n",
        "\n",
        "åˆ†æï¼š\"\"\")\n",
        "    \n",
        "    return prompt_template.format_messages(text=text)\n",
        "\n",
        "@chain_decorator\n",
        "def result_formatter(ai_response):\n",
        "    \"\"\"ç»“æœæ ¼å¼åŒ–å™¨\"\"\"\n",
        "    analysis = ai_response.content\n",
        "    \n",
        "    return {\n",
        "        \"æ—¶é—´æˆ³\": \"2024-01-15 10:30:00\",\n",
        "        \"åˆ†æç»“æœ\": analysis,\n",
        "        \"çŠ¶æ€\": \"åˆ†æå®Œæˆ\",\n",
        "        \"å­—ç¬¦æ•°\": len(analysis)\n",
        "    }\n",
        "\n",
        "# ç»„åˆæˆå¤æ‚Chain\n",
        "text_analysis_chain = (\n",
        "    input_validator \n",
        "    | text_preprocessor \n",
        "    | create_analysis_prompt \n",
        "    | model \n",
        "    | result_formatter\n",
        ")\n",
        "\n",
        "print(\"ã€å¤æ‚Chainç¤ºä¾‹ã€‘\")\n",
        "\n",
        "# æµ‹è¯•å¤æ‚Chain\n",
        "test_input = {\n",
        "    \"text\": \"\"\"\n",
        "    LangChainæ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶ï¼Œå®ƒè®©å¼€å‘è€…èƒ½å¤Ÿè½»æ¾æ„å»ºåŸºäºè¯­è¨€æ¨¡å‹çš„åº”ç”¨ã€‚\n",
        "    é€šè¿‡LCELï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ç®€æ´çš„è¯­æ³•ç»„åˆå¤æ‚çš„å¤„ç†æµç¨‹ã€‚\n",
        "    è¿™çœŸæ˜¯å¤ªæ£’äº†ï¼\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    final_result = text_analysis_chain.invoke(test_input)\n",
        "    \n",
        "    print(\"åˆ†æå®Œæˆï¼\")\n",
        "    for key, value in final_result.items():\n",
        "        if key == \"åˆ†æç»“æœ\":\n",
        "            print(f\"{key}:\\n{value}\")\n",
        "        else:\n",
        "            print(f\"{key}: {value}\")\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f\"å¤„ç†å‡ºé”™: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. æ•°æ®ä¼ é€’æ¨¡å¼\n",
        "\n",
        "åœ¨å¤æ‚çš„Chainä¸­ï¼Œç†è§£æ•°æ®å¦‚ä½•åœ¨ç»„ä»¶ä¹‹é—´ä¼ é€’æ˜¯å…³é”®ã€‚\n",
        "\n",
        "### ä¼ é€’è§„åˆ™\n",
        "\n",
        "1. **è‡ªåŠ¨æ˜ å°„**ï¼šå‰ä¸€ä¸ªç»„ä»¶çš„è¾“å‡ºè‡ªåŠ¨æˆä¸ºä¸‹ä¸€ä¸ªç»„ä»¶çš„è¾“å…¥\n",
        "2. **ç±»å‹é€‚é…**ï¼šLangChainè‡ªåŠ¨å¤„ç†ç±»å‹è½¬æ¢\n",
        "3. **æ•°æ®ä¿æŒ**ï¼šé™¤éæ˜¾å¼ä¿®æ”¹ï¼Œå¦åˆ™æ•°æ®ä¼šä¼ é€’ä¸‹å»\n",
        "\n",
        "### å¸¸è§æ¨¡å¼\n",
        "\n",
        "| æ¨¡å¼ | è¯´æ˜ | ç¤ºä¾‹ |\n",
        "|------|------|------|\n",
        "| **ç›´é€šä¼ é€’** | æ•°æ®ä¸å˜ï¼Œç›´æ¥ä¼ ç»™ä¸‹ä¸€ä¸ªç»„ä»¶ | `dict -> dict` |\n",
        "| **æ ¼å¼è½¬æ¢** | æ”¹å˜æ•°æ®æ ¼å¼ä½†ä¿æŒå†…å®¹ | `str -> Messages` |\n",
        "| **æ•°æ®å¢å¼º** | æ·»åŠ é¢å¤–ä¿¡æ¯ | `{a: 1} -> {a: 1, b: 2}` |\n",
        "| **æ•°æ®æå–** | ä»å¤æ‚å¯¹è±¡ä¸­æå–ç‰¹å®šå­—æ®µ | `AIMessage -> str` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ•°æ®ä¼ é€’æ¨¡å¼æ¼”ç¤ºã€‘\n",
            "Step 1 è¾“å…¥: Hello LCEL! (ç±»å‹: <class 'str'>)\n",
            "Step 1 è¾“å‡º: {'original_input': 'Hello LCEL!', 'timestamp': '2024-01-15', 'step': 1}\n",
            "\n",
            "Step 2 è¾“å…¥: {'original_input': 'Hello LCEL!', 'timestamp': '2024-01-15', 'step': 1} (ç±»å‹: <class 'dict'>)\n",
            "Step 2 è¾“å‡º: {'original_input': 'Hello LCEL!', 'timestamp': '2024-01-15', 'step': 2, 'processed': True, 'message_count': 11}\n",
            "\n",
            "Step 3 è¾“å…¥: {'original_input': 'Hello LCEL!', 'timestamp': '2024-01-15', 'step': 2, 'processed': True, 'message_count': 11} (ç±»å‹: <class 'dict'>)\n",
            "Step 3 è¾“å‡º: å¤„ç†å®Œæˆï¼åŸå§‹è¾“å…¥ï¼šHello LCEL!ï¼Œæ¶ˆæ¯é•¿åº¦ï¼š11 (ç±»å‹: <class 'str'>)\n",
            "\n",
            "æœ€ç»ˆç»“æœ: å¤„ç†å®Œæˆï¼åŸå§‹è¾“å…¥ï¼šHello LCEL!ï¼Œæ¶ˆæ¯é•¿åº¦ï¼š11\n",
            "æœ€ç»ˆç±»å‹: <class 'str'>\n"
          ]
        }
      ],
      "source": [
        "# æ•°æ®ä¼ é€’æ¨¡å¼ç¤ºä¾‹\n",
        "\n",
        "@chain_decorator\n",
        "def step1_add_metadata(input_data):\n",
        "    \"\"\"æ­¥éª¤1ï¼šæ·»åŠ å…ƒæ•°æ®\"\"\"\n",
        "    print(f\"Step 1 è¾“å…¥: {input_data} (ç±»å‹: {type(input_data)})\")\n",
        "    \n",
        "    result = {\n",
        "        \"original_input\": input_data,\n",
        "        \"timestamp\": \"2024-01-15\",\n",
        "        \"step\": 1\n",
        "    }\n",
        "    print(f\"Step 1 è¾“å‡º: {result}\")\n",
        "    return result\n",
        "\n",
        "@chain_decorator  \n",
        "def step2_process_data(data):\n",
        "    \"\"\"æ­¥éª¤2ï¼šå¤„ç†æ•°æ®\"\"\"\n",
        "    print(f\"\\nStep 2 è¾“å…¥: {data} (ç±»å‹: {type(data)})\")\n",
        "    \n",
        "    result = {\n",
        "        **data,  # ä¿æŒåŸæœ‰æ•°æ®\n",
        "        \"processed\": True,\n",
        "        \"step\": 2,\n",
        "        \"message_count\": len(str(data[\"original_input\"]))\n",
        "    }\n",
        "    print(f\"Step 2 è¾“å‡º: {result}\")\n",
        "    return result\n",
        "\n",
        "@chain_decorator\n",
        "def step3_extract_info(data):\n",
        "    \"\"\"æ­¥éª¤3ï¼šæå–ä¿¡æ¯\"\"\"\n",
        "    print(f\"\\nStep 3 è¾“å…¥: {data} (ç±»å‹: {type(data)})\")\n",
        "    \n",
        "    # åªæå–éƒ¨åˆ†ä¿¡æ¯\n",
        "    result = f\"å¤„ç†å®Œæˆï¼åŸå§‹è¾“å…¥ï¼š{data['original_input']}ï¼Œæ¶ˆæ¯é•¿åº¦ï¼š{data['message_count']}\"\n",
        "    print(f\"Step 3 è¾“å‡º: {result} (ç±»å‹: {type(result)})\")\n",
        "    return result\n",
        "\n",
        "# åˆ›å»ºæ•°æ®ä¼ é€’Chain\n",
        "data_flow_chain = step1_add_metadata | step2_process_data | step3_extract_info\n",
        "\n",
        "print(\"ã€æ•°æ®ä¼ é€’æ¨¡å¼æ¼”ç¤ºã€‘\")\n",
        "final_result = data_flow_chain.invoke(\"Hello LCEL!\")\n",
        "\n",
        "print(f\"\\næœ€ç»ˆç»“æœ: {final_result}\")\n",
        "print(f\"æœ€ç»ˆç±»å‹: {type(final_result)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. é”™è¯¯å¤„ç†å’Œè°ƒè¯•\n",
        "\n",
        "åœ¨å¤æ‚Chainä¸­ï¼Œé”™è¯¯å¤„ç†å’Œè°ƒè¯•éå¸¸é‡è¦ã€‚\n",
        "\n",
        "### è°ƒè¯•ç­–ç•¥\n",
        "\n",
        "1. **åˆ†æ­¥æµ‹è¯•**ï¼šå•ç‹¬æµ‹è¯•æ¯ä¸ªç»„ä»¶\n",
        "2. **æ—¥å¿—è®°å½•**ï¼šåœ¨å…³é”®æ­¥éª¤æ·»åŠ æ‰“å°è¯­å¥\n",
        "3. **ç±»å‹æ£€æŸ¥**ï¼šéªŒè¯è¾“å…¥è¾“å‡ºç±»å‹\n",
        "4. **å¼‚å¸¸æ•è·**ï¼šä¼˜é›…å¤„ç†é”™è¯¯\n",
        "\n",
        "### æœ€ä½³å®è·µ\n",
        "\n",
        "- **æ˜ç¡®æ¥å£**ï¼šæ¸…æ¥šå®šä¹‰æ¯ä¸ªç»„ä»¶çš„è¾“å…¥è¾“å‡º\n",
        "- **è¾¹ç•Œæ£€æŸ¥**ï¼šéªŒè¯è¾“å…¥æ•°æ®çš„æœ‰æ•ˆæ€§\n",
        "- **æ¸è¿›å¼æ„å»º**ï¼šé€æ­¥æ·»åŠ ç»„ä»¶ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§æ„å»ºå¤æ‚Chain\n",
        "- **å•å…ƒæµ‹è¯•**ï¼šä¸ºæ¯ä¸ªç»„ä»¶ç¼–å†™æµ‹è¯•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€é”™è¯¯å¤„ç†ç¤ºä¾‹ã€‘\n",
            "\n",
            "æµ‹è¯•1 - æ­£å¸¸è¾“å…¥:\n",
            "å¤„ç†è¾“å…¥: {'text': 'Hello LCEL'}\n",
            "å¤„ç†æˆåŠŸ: {'text': 'Hello LCEL', 'length': 10, 'status': 'success'}\n",
            "ç»“æœ: âœ… å¤„ç†æˆåŠŸ: 'Hello LCEL' (é•¿åº¦: 10)\n",
            "\n",
            "æµ‹è¯•2 - ç¼ºå°‘å­—æ®µ:\n",
            "å¤„ç†è¾“å…¥: {'message': 'Hello'}\n",
            "å¤„ç†å¤±è´¥: \"ç¼ºå°‘å¿…éœ€çš„'text'å­—æ®µ\"\n",
            "ç»“æœ: âŒ å¤„ç†å‡ºé”™: \"ç¼ºå°‘å¿…éœ€çš„'text'å­—æ®µ\"\n",
            "\n",
            "æµ‹è¯•3 - ç©ºæ–‡æœ¬:\n",
            "å¤„ç†è¾“å…¥: {'text': '   '}\n",
            "å¤„ç†å¤±è´¥: 'text'å­—æ®µä¸èƒ½ä¸ºç©º\n",
            "ç»“æœ: âŒ å¤„ç†å‡ºé”™: 'text'å­—æ®µä¸èƒ½ä¸ºç©º\n",
            "\n",
            "æµ‹è¯•4 - é”™è¯¯ç±»å‹:\n",
            "å¤„ç†è¾“å…¥: Hello\n",
            "å¤„ç†å¤±è´¥: æœŸæœ›dictç±»å‹ï¼Œå¾—åˆ°<class 'str'>\n",
            "ç»“æœ: âŒ å¤„ç†å‡ºé”™: æœŸæœ›dictç±»å‹ï¼Œå¾—åˆ°<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "# é”™è¯¯å¤„ç†å’Œè°ƒè¯•ç¤ºä¾‹\n",
        "\n",
        "@chain_decorator\n",
        "def safe_input_processor(data):\n",
        "    \"\"\"å®‰å…¨çš„è¾“å…¥å¤„ç†å™¨\"\"\"\n",
        "    try:\n",
        "        print(f\"å¤„ç†è¾“å…¥: {data}\")\n",
        "        \n",
        "        # è¾“å…¥éªŒè¯\n",
        "        if not isinstance(data, dict):\n",
        "            raise TypeError(f\"æœŸæœ›dictç±»å‹ï¼Œå¾—åˆ°{type(data)}\")\n",
        "        \n",
        "        if \"text\" not in data:\n",
        "            raise KeyError(\"ç¼ºå°‘å¿…éœ€çš„'text'å­—æ®µ\")\n",
        "        \n",
        "        text = data[\"text\"]\n",
        "        if not isinstance(text, str):\n",
        "            raise TypeError(\"'text'å­—æ®µå¿…é¡»æ˜¯å­—ç¬¦ä¸²\")\n",
        "        \n",
        "        if len(text.strip()) == 0:\n",
        "            raise ValueError(\"'text'å­—æ®µä¸èƒ½ä¸ºç©º\")\n",
        "        \n",
        "        # å¤„ç†æˆåŠŸ\n",
        "        result = {\n",
        "            \"text\": text.strip(),\n",
        "            \"length\": len(text.strip()),\n",
        "            \"status\": \"success\"\n",
        "        }\n",
        "        \n",
        "        print(f\"å¤„ç†æˆåŠŸ: {result}\")\n",
        "        return result\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"å¤„ç†å¤±è´¥: {e}\")\n",
        "        # è¿”å›é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸\n",
        "        return {\n",
        "            \"text\": \"\",\n",
        "            \"length\": 0, \n",
        "            \"status\": \"error\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "@chain_decorator\n",
        "def error_aware_formatter(data):\n",
        "    \"\"\"é”™è¯¯æ„ŸçŸ¥çš„æ ¼å¼åŒ–å™¨\"\"\"\n",
        "    if data[\"status\"] == \"error\":\n",
        "        return f\"âŒ å¤„ç†å‡ºé”™: {data['error']}\"\n",
        "    \n",
        "    return f\"âœ… å¤„ç†æˆåŠŸ: '{data['text']}' (é•¿åº¦: {data['length']})\"\n",
        "\n",
        "# åˆ›å»ºå¸¦é”™è¯¯å¤„ç†çš„Chain\n",
        "safe_chain = safe_input_processor | error_aware_formatter\n",
        "\n",
        "print(\"ã€é”™è¯¯å¤„ç†ç¤ºä¾‹ã€‘\")\n",
        "\n",
        "# æµ‹è¯•æ­£å¸¸è¾“å…¥\n",
        "print(\"\\næµ‹è¯•1 - æ­£å¸¸è¾“å…¥:\")\n",
        "result1 = safe_chain.invoke({\"text\": \"Hello LCEL\"})\n",
        "print(f\"ç»“æœ: {result1}\")\n",
        "\n",
        "# æµ‹è¯•é”™è¯¯è¾“å…¥\n",
        "print(\"\\næµ‹è¯•2 - ç¼ºå°‘å­—æ®µ:\")\n",
        "result2 = safe_chain.invoke({\"message\": \"Hello\"})  # é”™è¯¯ï¼šç¼ºå°‘textå­—æ®µ\n",
        "print(f\"ç»“æœ: {result2}\")\n",
        "\n",
        "print(\"\\næµ‹è¯•3 - ç©ºæ–‡æœ¬:\")\n",
        "result3 = safe_chain.invoke({\"text\": \"   \"})  # é”™è¯¯ï¼šç©ºæ–‡æœ¬\n",
        "print(f\"ç»“æœ: {result3}\")\n",
        "\n",
        "print(\"\\næµ‹è¯•4 - é”™è¯¯ç±»å‹:\")\n",
        "result4 = safe_chain.invoke(\"Hello\")  # é”™è¯¯ï¼šä¸æ˜¯dict\n",
        "print(f\"ç»“æœ: {result4}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. å®æˆ˜ç»ƒä¹ ï¼šæ„å»ºæ™ºèƒ½æ‘˜è¦ç”Ÿæˆå™¨\n",
        "\n",
        "ç»“åˆæœ¬ç« æ‰€å­¦ï¼Œæ„å»ºä¸€ä¸ªå®Œæ•´çš„æ–‡æ¡£æ‘˜è¦ç”ŸæˆChainã€‚\n",
        "\n",
        "**éœ€æ±‚åˆ†æï¼š**\n",
        "- è¾“å…¥ï¼šé•¿æ–‡æ¡£æ–‡æœ¬\n",
        "- å¤„ç†ï¼šæ¸…ç†ã€åˆ†æã€ç”Ÿæˆæ‘˜è¦\n",
        "- è¾“å‡ºï¼šæ ¼å¼åŒ–çš„æ‘˜è¦æŠ¥å‘Š\n",
        "\n",
        "**æŠ€æœ¯è¦ç‚¹ï¼š**\n",
        "- ä½¿ç”¨@chainåˆ›å»ºè‡ªå®šä¹‰ç»„ä»¶\n",
        "- ç”¨Pipeæ“ä½œç¬¦ç»„åˆå¤„ç†æµç¨‹\n",
        "- å®ç°é”™è¯¯å¤„ç†å’Œæ•°æ®éªŒè¯\n",
        "- æ”¯æŒæµå¼è¾“å‡º"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ã€æ™ºèƒ½æ‘˜è¦ç”Ÿæˆå™¨ã€‘\n",
            "ğŸ“„ æ™ºèƒ½æ‘˜è¦æŠ¥å‘Š\n",
            "========================================\n",
            "\n",
            "ğŸ“ æ‘˜è¦å†…å®¹ï¼š\n",
            "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½æ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚ç°ä»£AIæŠ€æœ¯ï¼Œå¦‚æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ï¼Œå·²åœ¨åŒ»ç–—ã€é‡‘èå’Œäº¤é€šç­‰å¤šä¸ªè¡Œä¸šå¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œå°½ç®¡å…¶å‘å±•å¸¦æ¥äº†æ˜¾è‘—çš„å¥½å¤„ï¼Œä½†ä¹Ÿå¼•å‘äº†å°±ä¸šã€éšç§å’Œç®—æ³•åè§ç­‰æŒ‘æˆ˜ï¼Œå› æ­¤éœ€è¦åœ¨æŠ€æœ¯è¿›æ­¥ä¸ç¤¾ä¼šè´£ä»»ä¹‹é—´å¯»æ±‚å¹³è¡¡ã€‚\n",
            "\n",
            "â° ç”Ÿæˆæ—¶é—´ï¼š2024-01-15 10:30:00\n",
            "âœ… çŠ¶æ€ï¼šæ‘˜è¦ç”Ÿæˆå®Œæˆ\n",
            "\n",
            "ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å°†åœ¨å¤„ç†å®Œæˆåæ·»åŠ ...\n",
            "\n",
            "============================================================\n",
            "\n",
            "ã€æµå¼æ‘˜è¦ç”Ÿæˆã€‘\n",
            "æ­£åœ¨ç”Ÿæˆæ‘˜è¦...\n",
            "----------------------------------------\n",
            "ğŸ“„ æ™ºèƒ½æ‘˜è¦æŠ¥å‘Š\n",
            "========================================\n",
            "\n",
            "ğŸ“ æ‘˜è¦å†…å®¹ï¼š\n",
            "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨ä½¿æœºå™¨èƒ½å¤Ÿæ‰§è¡Œéœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡ã€‚ç°ä»£AIæŠ€æœ¯æ¶µç›–æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸï¼Œå·²å¹¿æ³›åº”ç”¨äºåŒ»ç–—ã€é‡‘èå’Œäº¤é€šç­‰è¡Œä¸šã€‚ç„¶è€Œï¼ŒAIçš„å‘å±•ä¹Ÿé¢ä¸´å°±ä¸šå½±å“ã€éšç§ä¿æŠ¤å’Œç®—æ³•åè§ç­‰æŒ‘æˆ˜ï¼Œå› æ­¤è´Ÿè´£ä»»çš„AIå‘å±•æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚\n",
            "\n",
            "â° ç”Ÿæˆæ—¶é—´ï¼š2024-01-15 10:30:00\n",
            "âœ… çŠ¶æ€ï¼šæ‘˜è¦ç”Ÿæˆå®Œæˆ\n",
            "\n",
            "ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å°†åœ¨å¤„ç†å®Œæˆåæ·»åŠ ...\n"
          ]
        }
      ],
      "source": [
        "# å®æˆ˜ï¼šæ™ºèƒ½æ‘˜è¦ç”Ÿæˆå™¨\n",
        "\n",
        "@chain_decorator\n",
        "def document_preprocessor(input_data):\n",
        "    \"\"\"æ–‡æ¡£é¢„å¤„ç†å™¨\"\"\"\n",
        "    text = input_data.get(\"document\", \"\").strip()\n",
        "    \n",
        "    if not text:\n",
        "        raise ValueError(\"æ–‡æ¡£å†…å®¹ä¸èƒ½ä¸ºç©º\")\n",
        "    \n",
        "    if len(text) < 50:\n",
        "        raise ValueError(\"æ–‡æ¡£å†…å®¹å¤ªçŸ­ï¼Œè‡³å°‘éœ€è¦50ä¸ªå­—ç¬¦\")\n",
        "    \n",
        "    # æ¸…ç†æ–‡æœ¬\n",
        "    cleaned = text.replace(\"\\n\\n\", \"\\n\").replace(\"\\t\", \" \")\n",
        "    words = cleaned.split()\n",
        "    \n",
        "    return {\n",
        "        \"original_text\": text,\n",
        "        \"cleaned_text\": cleaned,\n",
        "        \"word_count\": len(words),\n",
        "        \"char_count\": len(cleaned),\n",
        "        \"estimated_reading_time\": len(words) // 200  # å‡è®¾æ¯åˆ†é’Ÿè¯»200å­—\n",
        "    }\n",
        "\n",
        "@chain_decorator\n",
        "def create_summary_prompt(doc_data):\n",
        "    \"\"\"åˆ›å»ºæ‘˜è¦æç¤ºè¯\"\"\"\n",
        "    text = doc_data[\"cleaned_text\"]\n",
        "    word_count = doc_data[\"word_count\"]\n",
        "    \n",
        "    # æ ¹æ®æ–‡æ¡£é•¿åº¦è°ƒæ•´æ‘˜è¦è¦æ±‚\n",
        "    if word_count < 200:\n",
        "        summary_length = \"2-3å¥è¯\"\n",
        "    elif word_count < 500:\n",
        "        summary_length = \"ä¸€ä¸ªæ®µè½ï¼ˆ4-5å¥è¯ï¼‰\"\n",
        "    else:\n",
        "        summary_length = \"2-3ä¸ªæ®µè½\"\n",
        "    \n",
        "    prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "è¯·ä¸ºä»¥ä¸‹æ–‡æ¡£ç”Ÿæˆæ‘˜è¦ï¼š\n",
        "\n",
        "æ–‡æ¡£å†…å®¹ï¼š\n",
        "{text}\n",
        "\n",
        "è¦æ±‚ï¼š\n",
        "1. æ‘˜è¦é•¿åº¦ï¼š{summary_length}\n",
        "2. æŠ“ä½æ ¸å¿ƒè¦ç‚¹å’Œä¸»è¦è§‚ç‚¹\n",
        "3. ä¿æŒå®¢è§‚å’Œå‡†ç¡®\n",
        "4. ä½¿ç”¨æ¸…æ™°ç®€æ´çš„è¯­è¨€\n",
        "\n",
        "è¯·ç”Ÿæˆæ‘˜è¦ï¼š\"\"\")\n",
        "    \n",
        "    return prompt_template.format_messages(\n",
        "        text=text,\n",
        "        summary_length=summary_length\n",
        "    )\n",
        "\n",
        "@chain_decorator\n",
        "def format_summary_report(ai_response):\n",
        "    \"\"\"æ ¼å¼åŒ–æ‘˜è¦æŠ¥å‘Š\"\"\"\n",
        "    summary = ai_response.content\n",
        "    \n",
        "    report = f\"\"\"\n",
        "ğŸ“„ æ™ºèƒ½æ‘˜è¦æŠ¥å‘Š\n",
        "{'=' * 40}\n",
        "\n",
        "ğŸ“ æ‘˜è¦å†…å®¹ï¼š\n",
        "{summary}\n",
        "\n",
        "â° ç”Ÿæˆæ—¶é—´ï¼š2024-01-15 10:30:00\n",
        "âœ… çŠ¶æ€ï¼šæ‘˜è¦ç”Ÿæˆå®Œæˆ\n",
        "\n",
        "ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å°†åœ¨å¤„ç†å®Œæˆåæ·»åŠ ...\n",
        "\"\"\"\n",
        "    return report.strip()\n",
        "\n",
        "# åˆ›å»ºæ‘˜è¦ç”ŸæˆChain\n",
        "summary_chain = (\n",
        "    document_preprocessor \n",
        "    | create_summary_prompt \n",
        "    | model \n",
        "    | format_summary_report\n",
        ")\n",
        "\n",
        "print(\"ã€æ™ºèƒ½æ‘˜è¦ç”Ÿæˆå™¨ã€‘\")\n",
        "\n",
        "# æµ‹è¯•æ–‡æ¡£\n",
        "test_document = \"\"\"\n",
        "äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼ŒAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½æ‰èƒ½å®Œæˆçš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚AIçš„å‘å±•å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ï¼Œå½“æ—¶ç ”ç©¶äººå‘˜å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ€ç»´çš„å¯èƒ½æ€§ã€‚\n",
        "\n",
        "ç°ä»£AIæŠ€æœ¯åŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰å¤šä¸ªé¢†åŸŸã€‚æœºå™¨å­¦ä¹ å…è®¸ç³»ç»Ÿä»æ•°æ®ä¸­å­¦ä¹ å¹¶æ”¹è¿›æ€§èƒ½ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥å¤„ç†å¤æ‚çš„æ•°æ®æ¨¡å¼ã€‚\n",
        "\n",
        "AIæŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºå„ä¸ªè¡Œä¸šï¼ŒåŒ…æ‹¬åŒ»ç–—å¥åº·ã€é‡‘èæœåŠ¡ã€äº¤é€šè¿è¾“ã€å¨±ä¹åª’ä½“ç­‰ã€‚åœ¨åŒ»ç–—é¢†åŸŸï¼ŒAIå¯ä»¥å¸®åŠ©è¯Šæ–­ç–¾ç—…ã€å‘ç°æ–°è¯ï¼›åœ¨é‡‘èé¢†åŸŸï¼ŒAIç”¨äºé£é™©è¯„ä¼°å’Œæ¬ºè¯ˆæ£€æµ‹ï¼›åœ¨äº¤é€šé¢†åŸŸï¼Œè‡ªåŠ¨é©¾é©¶æ±½è½¦æ­£åœ¨æˆä¸ºç°å®ã€‚\n",
        "\n",
        "å°½ç®¡AIå¸¦æ¥äº†è®¸å¤šå¥½å¤„ï¼Œä½†ä¹Ÿå­˜åœ¨ä¸€äº›æŒ‘æˆ˜å’Œæ‹…å¿§ï¼ŒåŒ…æ‹¬å°±ä¸šå½±å“ã€éšç§ä¿æŠ¤ã€ç®—æ³•åè§ç­‰é—®é¢˜ã€‚å› æ­¤ï¼Œè´Ÿè´£ä»»çš„AIå‘å±•å˜å¾—è¶Šæ¥è¶Šé‡è¦ï¼Œéœ€è¦åœ¨æŠ€æœ¯è¿›æ­¥å’Œç¤¾ä¼šè´£ä»»ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ã€‚\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    summary_result = summary_chain.invoke({\"document\": test_document})\n",
        "    print(summary_result)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# æµ‹è¯•æµå¼è¾“å‡º\n",
        "print(\"\\nã€æµå¼æ‘˜è¦ç”Ÿæˆã€‘\")\n",
        "print(\"æ­£åœ¨ç”Ÿæˆæ‘˜è¦...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for chunk in summary_chain.stream({\"document\": test_document}):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æœ¬ç« æ€»ç»“\n",
        "\n",
        "### æ ¸å¿ƒçŸ¥è¯†ç‚¹\n",
        "\n",
        "**LCELåŸºç¡€æ¦‚å¿µ**\n",
        "- LCELæ˜¯LangChainçš„æ ¸å¿ƒè¯­æ³•\n",
        "- æ‰€æœ‰ç»„ä»¶éƒ½å®ç°Runnableæ¥å£\n",
        "- ç»Ÿä¸€çš„invokeã€streamã€batchæ–¹æ³•\n",
        "\n",
        "**Pipeæ“ä½œç¬¦ï¼ˆ|ï¼‰**\n",
        "- ç”¨äºè¿æ¥å’Œç»„åˆRunnableç»„ä»¶\n",
        "- æ•°æ®ä»å·¦åˆ°å³æµåŠ¨\n",
        "- è‡ªåŠ¨å¤„ç†ç±»å‹é€‚é…\n",
        "\n",
        "**@chainè£…é¥°å™¨**\n",
        "- å°†æ™®é€šå‡½æ•°è½¬æ¢ä¸ºRunnable\n",
        "- æ”¯æŒæ‰€æœ‰æ ‡å‡†Runnableæ–¹æ³•\n",
        "- å¯ä»¥ä¸å…¶ä»–ç»„ä»¶ç»„åˆ\n",
        "\n",
        "**RunnableLambda**\n",
        "- å‡½æ•°å¼ç¼–ç¨‹æ”¯æŒ\n",
        "- @chainçš„åº•å±‚å®ç°\n",
        "- æä¾›çµæ´»çš„è‡ªå®šä¹‰å¤„ç†\n",
        "\n",
        "**å¤æ‚Chainæ„å»º**\n",
        "- å•ä¸€èŒè´£åŸåˆ™\n",
        "- å¯ç»„åˆå’Œå¯å¤ç”¨è®¾è®¡\n",
        "- é”™è¯¯å¤„ç†å’Œè°ƒè¯•ç­–ç•¥\n",
        "\n",
        "### ä¸å‰ä¸¤ç« çš„å…³ç³»\n",
        "\n",
        "```\n",
        "ç¬¬01ç« ï¼šChat ModelsåŸºç¡€\n",
        "  â†“ å­¦ä¼šæ¨¡å‹è°ƒç”¨\n",
        "ç¬¬02ç« ï¼šPrompts & Messages  \n",
        "  â†“ å­¦ä¼šæç¤ºè¯è®¾è®¡\n",
        "ç¬¬03ç« ï¼šLCELåŸºç¡€\n",
        "  â†“ å­¦ä¼šç»„ä»¶ç»„åˆï¼ˆå½“å‰ï¼‰\n",
        "ç¬¬04ç« ï¼šStructured Output\n",
        "```\n",
        "\n",
        "### é‡è¦æé†’\n",
        "\n",
        "**LCELçš„å¨åŠ›**\n",
        "- ç®€æ´çš„è¯­æ³•è¡¨è¾¾å¤æ‚é€»è¾‘\n",
        "- è‡ªåŠ¨æ”¯æŒæµå¼å’Œæ‰¹é‡å¤„ç†\n",
        "- å¼ºå¤§çš„å¯ç»„åˆæ€§\n",
        "\n",
        "**æœ€ä½³å®è·µ**\n",
        "- ä¿æŒç»„ä»¶ç®€å•å’Œä¸“ä¸€\n",
        "- åˆç†çš„é”™è¯¯å¤„ç†\n",
        "- æ¸…æ™°çš„æ•°æ®æµè®¾è®¡\n",
        "- å……åˆ†æµ‹è¯•æ¯ä¸ªç»„ä»¶\n",
        "\n",
        "### ç»ƒä¹ å»ºè®®\n",
        "\n",
        "1. å°è¯•ç”¨@chainåˆ›å»ºä¸åŒç±»å‹çš„å¤„ç†å‡½æ•°\n",
        "2. æ„å»ºåŒ…å«3-5ä¸ªç»„ä»¶çš„å¤æ‚Chain\n",
        "3. å®éªŒæµå¼è¾“å‡ºåœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨\n",
        "4. ç»ƒä¹ é”™è¯¯å¤„ç†å’Œè°ƒè¯•æŠ€å·§"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
