{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 第08章：RAG基础（Retrieval Augmented Generation）\n",
        "\n",
        "## 学习目标\n",
        "\n",
        "本章将学习：\n",
        "1. 理解RAG的核心概念和工作原理\n",
        "2. 掌握2-Step RAG的实现\n",
        "3. 使用Retriever接口\n",
        "4. 构建完整的RAG Chain\n",
        "5. 理解RAG vs 传统问答的区别\n",
        "\n",
        "## 什么是RAG？\n",
        "\n",
        "RAG（Retrieval Augmented Generation，检索增强生成）是一种结合检索和生成的技术：\n",
        "\n",
        "1. **检索（Retrieval）**：从知识库中检索相关文档\n",
        "2. **增强（Augmented）**：将检索到的文档作为上下文\n",
        "3. **生成（Generation）**：LLM基于上下文生成答案\n",
        "\n",
        "### RAG的优势\n",
        "\n",
        "- 减少幻觉：答案基于真实文档\n",
        "- 知识更新：无需重新训练模型\n",
        "- 可追溯：可以查看引用来源\n",
        "- 成本效益：比微调模型更经济\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "环境配置完成！\n",
            "Chat模型: gpt-4.1-mini\n",
            "Embedding模型: text-embedding-3-small\n"
          ]
        }
      ],
      "source": [
        "# 环境配置\n",
        "import os\n",
        "import sys\n",
        "\n",
        "_project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "sys.path.append(_project_root)\n",
        "\n",
        "from config import config\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# 初始化模型\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    temperature=0,\n",
        "    api_key=config.CLOUD_API_KEY,\n",
        "    base_url=config.CLOUD_BASE_URL,\n",
        ")\n",
        "\n",
        "# 配置Embedding模型\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    api_key=config.CLOUD_API_KEY,\n",
        "    base_url=config.CLOUD_BASE_URL\n",
        ")\n",
        "\n",
        "print(\"环境配置完成！\")\n",
        "print(f\"Chat模型: {model.model_name}\")\n",
        "print(f\"Embedding模型: {embeddings.model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. RAG工作流程\n",
        "\n",
        "### RAG的两种主要模式\n",
        "\n",
        "#### 2-Step RAG（两步RAG）\n",
        "- 总是先检索，再生成\n",
        "- 流程固定：查询 → 检索 → 生成\n",
        "- 每次查询只需1次LLM调用\n",
        "- 快速高效，适合简单场景\n",
        "\n",
        "#### Agentic RAG（智能体RAG）\n",
        "- Agent决定何时检索\n",
        "- 可以多次检索\n",
        "- 更灵活但需要更多token\n",
        "- 适合复杂推理场景\n",
        "\n",
        "本章重点学习2-Step RAG。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【准备知识库】\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "知识库已创建，包含 5 个文档\n",
            "文档主题: {'技术', 'Agent', 'LCEL', 'RAG', 'LangChain'}\n"
          ]
        }
      ],
      "source": [
        "### 2.1 准备知识库\n",
        "\n",
        "print(\"【准备知识库】\")\n",
        "print()\n",
        "\n",
        "# 创建知识库文档\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"LangChain是一个用于构建LLM应用的开源框架，支持多种模型提供商。\",\n",
        "        metadata={\"source\": \"doc1\", \"topic\": \"LangChain\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"RAG（检索增强生成）通过检索外部知识来增强LLM的回答能力。\",\n",
        "        metadata={\"source\": \"doc2\", \"topic\": \"RAG\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Vector Store用于存储文档的向量表示，支持语义搜索。\",\n",
        "        metadata={\"source\": \"doc3\", \"topic\": \"技术\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"LCEL（LangChain Expression Language）是LangChain的核心语法，使用管道操作符连接组件。\",\n",
        "        metadata={\"source\": \"doc4\", \"topic\": \"LCEL\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Agent可以自主决策使用哪些工具来完成任务，是LangChain的高级特性。\",\n",
        "        metadata={\"source\": \"doc5\", \"topic\": \"Agent\"}\n",
        "    ),\n",
        "]\n",
        "\n",
        "# 创建Vector Store并索引\n",
        "vector_store = InMemoryVectorStore(embeddings)\n",
        "vector_store.add_documents(documents)\n",
        "\n",
        "print(f\"知识库已创建，包含 {len(documents)} 个文档\")\n",
        "print(\"文档主题:\", set(doc.metadata[\"topic\"] for doc in documents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Retriever接口\n",
        "\n",
        "### 什么是Retriever？\n",
        "\n",
        "Retriever是一个Runnable接口，用于检索文档。它比Vector Store更通用：\n",
        "- Vector Store只能基于向量相似度检索\n",
        "- Retriever可以实现各种检索策略\n",
        "- Retriever是Runnable，可以用`|`组合\n",
        "\n",
        "### 核心方法\n",
        "\n",
        "- `invoke(query)`: 同步检索\n",
        "- `ainvoke(query)`: 异步检索\n",
        "- `batch(queries)`: 批量检索"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【创建Retriever】\n",
            "\n",
            "Retriever已创建\n",
            "搜索类型: similarity\n",
            "返回结果数: 2\n",
            "\n",
            "查询: 什么是RAG？\n",
            "检索到 2 个文档:\n",
            "\n",
            "1. RAG（检索增强生成）通过检索外部知识来增强LLM的回答能力。\n",
            "   来源: doc2\n",
            "\n",
            "2. LangChain是一个用于构建LLM应用的开源框架，支持多种模型提供商。\n",
            "   来源: doc1\n"
          ]
        }
      ],
      "source": [
        "### 3.1 创建Retriever\n",
        "\n",
        "print(\"【创建Retriever】\")\n",
        "print()\n",
        "\n",
        "# 从Vector Store创建Retriever\n",
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity\",  # 相似度搜索\n",
        "    search_kwargs={\"k\": 2}      # 返回top-2结果\n",
        ")\n",
        "\n",
        "print(\"Retriever已创建\")\n",
        "print(f\"搜索类型: similarity\")\n",
        "print(f\"返回结果数: 2\")\n",
        "print()\n",
        "\n",
        "# 测试检索\n",
        "query = \"什么是RAG？\"\n",
        "docs = retriever.invoke(query)\n",
        "\n",
        "print(f\"查询: {query}\")\n",
        "print(f\"检索到 {len(docs)} 个文档:\")\n",
        "for i, doc in enumerate(docs, 1):\n",
        "    print(f\"\\n{i}. {doc.page_content}\")\n",
        "    print(f\"   来源: {doc.metadata['source']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【批量检索】\n",
            "\n",
            "查询: LangChain是什么？\n",
            "  最相关: LangChain是一个用于构建LLM应用的开源框架，支持多种模型提供商。...\n",
            "\n",
            "查询: 什么是Agent？\n",
            "  最相关: Agent可以自主决策使用哪些工具来完成任务，是LangChain的高级特性。...\n",
            "\n",
            "查询: LCEL的作用是什么？\n",
            "  最相关: LCEL（LangChain Expression Language）是LangChain的核心语法...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### 3.2 批量检索\n",
        "\n",
        "print(\"【批量检索】\")\n",
        "print()\n",
        "\n",
        "# 批量检索多个查询\n",
        "queries = [\n",
        "    \"LangChain是什么？\",\n",
        "    \"什么是Agent？\",\n",
        "    \"LCEL的作用是什么？\"\n",
        "]\n",
        "\n",
        "# 使用batch方法\n",
        "results = retriever.batch(queries)\n",
        "\n",
        "for query, docs in zip(queries, results):\n",
        "    print(f\"查询: {query}\")\n",
        "    print(f\"  最相关: {docs[0].page_content[:50]}...\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 构建2-Step RAG Chain\n",
        "\n",
        "### RAG Chain的核心步骤\n",
        "\n",
        "1. **检索（Retrieve）**：根据查询检索相关文档\n",
        "2. **生成（Generate）**：将文档作为上下文，LLM生成答案\n",
        "\n",
        "### 使用LCEL构建RAG Chain\n",
        "\n",
        "LCEL让我们可以用管道操作符`|`优雅地组合组件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【构建简单RAG Chain】\n",
            "\n",
            "RAG Chain已构建\n",
            "组件: Retriever → Format → Prompt → Model → Parser\n",
            "\n",
            "问题: 什么是RAG？\n",
            "回答: RAG（检索增强生成）是通过检索外部知识来增强大型语言模型（LLM）回答能力的一种方法。\n"
          ]
        }
      ],
      "source": [
        "### 4.1 简单RAG Chain\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "print(\"【构建简单RAG Chain】\")\n",
        "print()\n",
        "\n",
        "# 定义格式化函数\n",
        "def format_docs(docs):\n",
        "    \"\"\"将文档列表格式化为字符串\"\"\"\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# 创建提示词模板\n",
        "template = \"\"\"基于以下上下文回答问题。如果上下文中没有相关信息，请说\"我不知道\"。\n",
        "\n",
        "上下文：\n",
        "{context}\n",
        "\n",
        "问题：{question}\n",
        "\n",
        "回答：\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# 构建RAG Chain\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"RAG Chain已构建\")\n",
        "print(\"组件: Retriever → Format → Prompt → Model → Parser\")\n",
        "print()\n",
        "\n",
        "# 测试\n",
        "question = \"什么是RAG？\"\n",
        "answer = rag_chain.invoke(question)\n",
        "\n",
        "print(f\"问题: {question}\")\n",
        "print(f\"回答: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【测试多个问题】\n",
            "\n",
            "Q: LangChain支持哪些功能？\n",
            "A: LangChain支持构建LLM应用，支持多种模型提供商，并且具备Agent功能，能够自主决策使用哪些工具来完成任务。\n",
            "------------------------------------------------------------\n",
            "\n",
            "Q: LCEL是什么？\n",
            "A: LCEL（LangChain Expression Language）是LangChain的核心语法，使用管道操作符连接组件。\n",
            "------------------------------------------------------------\n",
            "\n",
            "Q: Agent的作用是什么？\n",
            "A: Agent的作用是能够自主决策使用哪些工具来完成任务。\n",
            "------------------------------------------------------------\n",
            "\n",
            "Q: 如何训练大型语言模型？\n",
            "A: 我不知道。\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### 4.2 多问题测试\n",
        "\n",
        "print(\"【测试多个问题】\")\n",
        "print()\n",
        "\n",
        "test_questions = [\n",
        "    \"LangChain支持哪些功能？\",\n",
        "    \"LCEL是什么？\",\n",
        "    \"Agent的作用是什么？\",\n",
        "    \"如何训练大型语言模型？\"  # 知识库中没有的问题\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    answer = rag_chain.invoke(question)\n",
        "    print(f\"Q: {question}\")\n",
        "    print(f\"A: {answer}\")\n",
        "    print(\"-\" * 60)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 带来源引用的RAG\n",
        "\n",
        "在实际应用中，我们通常希望返回答案的同时，也返回引用的文档来源。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【带来源的RAG】\n",
            "\n",
            "问题: 什么是LCEL？\n",
            "\n",
            "答案: LCEL（LangChain Expression Language）是LangChain的核心语法，使用管道操作符连接组件。\n",
            "\n",
            "引用来源:\n",
            "1. [doc4] LCEL（LangChain Expression Language）是LangChain的核心语法，使用管道操作符连接...\n",
            "2. [doc1] LangChain是一个用于构建LLM应用的开源框架，支持多种模型提供商。...\n"
          ]
        }
      ],
      "source": [
        "### 5.1 返回答案和来源\n",
        "\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "print(\"【带来源的RAG】\")\n",
        "print()\n",
        "\n",
        "# 构建带来源的RAG Chain\n",
        "rag_chain_with_source = RunnableParallel(\n",
        "    {\n",
        "        \"context\": retriever,\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        ").assign(\n",
        "    answer=lambda x: (prompt | model | StrOutputParser()).invoke({\n",
        "        \"context\": format_docs(x[\"context\"]),\n",
        "        \"question\": x[\"question\"]\n",
        "    })\n",
        ")\n",
        "\n",
        "# 测试\n",
        "question = \"什么是LCEL？\"\n",
        "result = rag_chain_with_source.invoke(question)\n",
        "\n",
        "print(f\"问题: {question}\")\n",
        "print(f\"\\n答案: {result['answer']}\")\n",
        "print(f\"\\n引用来源:\")\n",
        "for i, doc in enumerate(result['context'], 1):\n",
        "    print(f\"{i}. [{doc.metadata['source']}] {doc.page_content[:60]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 实战项目：完整的RAG问答系统\n",
        "\n",
        "构建一个功能完整的RAG系统，包括：\n",
        "1. 文档加载和索引\n",
        "2. 智能检索\n",
        "3. 答案生成\n",
        "4. 来源追踪"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【完整RAG系统】\n",
            "\n",
            "已索引 3 个文档块\n",
            "RAG系统已就绪\n",
            "\n",
            "============================================================\n",
            "\n",
            "Q: LangChain的主要特性有哪些？\n",
            "A: LangChain的主要特性包括：  \n",
            "1. 模型集成，支持多种语言模型提供商；  \n",
            "2. 强大的提示词模板系统，支持动态变量、条件逻辑和少样本学习；  \n",
            "3. 链式调用，通过LCEL构建复杂处理流程；  \n",
            "4. 完整的RAG工具链支持，包括文档加载、文本分割和向量数据库集成；  \n",
            "5. Agent框架，使模型能够自主决策和使用工具。\n",
            "\n",
            "参考文档数: 3\n",
            "============================================================\n",
            "\n",
            "Q: LangChain支持哪些模型提供商？\n",
            "A: LangChain支持OpenAI、Anthropic、Google等多种语言模型提供商。\n",
            "\n",
            "参考文档数: 3\n",
            "============================================================\n",
            "\n",
            "Q: 什么是RAG工具链？\n",
            "A: RAG工具链是指LangChain内置的一整套支持检索增强生成（Retrieval-Augmented Generation）的工具，包括文档加载器、文本分割器和向量数据库集成等，用于实现基于外部知识的智能生成。\n",
            "\n",
            "参考文档数: 3\n",
            "============================================================\n",
            "\n",
            "RAG系统演示完成！\n"
          ]
        }
      ],
      "source": [
        "print(\"【完整RAG系统】\")\n",
        "print()\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "class RAGSystem:\n",
        "    \"\"\"完整的RAG问答系统\"\"\"\n",
        "    \n",
        "    def __init__(self, embeddings, model):\n",
        "        self.embeddings = embeddings\n",
        "        self.model = model\n",
        "        self.vector_store = InMemoryVectorStore(embeddings)\n",
        "        self.retriever = None\n",
        "        \n",
        "    def load_and_index(self, file_path, chunk_size=200, chunk_overlap=50):\n",
        "        \"\"\"加载文档并建立索引\"\"\"\n",
        "        # 加载文档\n",
        "        loader = TextLoader(file_path, encoding=\"utf-8\")\n",
        "        docs = loader.load()\n",
        "        \n",
        "        # 分割文档\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap\n",
        "        )\n",
        "        splits = splitter.split_documents(docs)\n",
        "        \n",
        "        # 索引\n",
        "        self.vector_store.add_documents(splits)\n",
        "        \n",
        "        # 创建retriever\n",
        "        self.retriever = self.vector_store.as_retriever(\n",
        "            search_kwargs={\"k\": 3}\n",
        "        )\n",
        "        \n",
        "        return len(splits)\n",
        "    \n",
        "    def create_rag_chain(self):\n",
        "        \"\"\"创建RAG链\"\"\"\n",
        "        template = \"\"\"基于以下上下文回答问题。请简洁明了地回答。\n",
        "\n",
        "上下文：\n",
        "{context}\n",
        "\n",
        "问题：{question}\n",
        "\n",
        "回答：\"\"\"\n",
        "        \n",
        "        prompt = ChatPromptTemplate.from_template(template)\n",
        "        \n",
        "        def format_docs(docs):\n",
        "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "        \n",
        "        answer_chain = prompt | self.model | StrOutputParser()\n",
        "        \n",
        "        # 构建链\n",
        "        self.rag_chain = RunnableParallel(\n",
        "            {\n",
        "                \"context\": self.retriever,\n",
        "                \"question\": RunnablePassthrough()\n",
        "            }\n",
        "        ).assign(\n",
        "            answer=lambda x: answer_chain.invoke({\n",
        "                \"context\": format_docs(x[\"context\"]),\n",
        "                \"question\": x[\"question\"]\n",
        "            })\n",
        "        )\n",
        "    \n",
        "    def ask(self, question):\n",
        "        \"\"\"提问并返回答案和来源\"\"\"\n",
        "        result = self.rag_chain.invoke(question)\n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"answer\": result[\"answer\"],\n",
        "            \"sources\": result[\"context\"]\n",
        "        }\n",
        "\n",
        "# 创建RAG系统\n",
        "rag_system = RAGSystem(embeddings, model)\n",
        "\n",
        "# 加载文档\n",
        "num_chunks = rag_system.load_and_index(\"../data/langchain_intro.txt\")\n",
        "print(f\"已索引 {num_chunks} 个文档块\")\n",
        "\n",
        "# 创建RAG链\n",
        "rag_system.create_rag_chain()\n",
        "print(\"RAG系统已就绪\")\n",
        "print()\n",
        "\n",
        "# 测试问答\n",
        "test_questions = [\n",
        "    \"LangChain的主要特性有哪些？\",\n",
        "    \"LangChain支持哪些模型提供商？\",\n",
        "    \"什么是RAG工具链？\"\n",
        "]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "for question in test_questions:\n",
        "    result = rag_system.ask(question)\n",
        "    print(f\"\\nQ: {result['question']}\")\n",
        "    print(f\"A: {result['answer']}\")\n",
        "    print(f\"\\n参考文档数: {len(result['sources'])}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nRAG系统演示完成！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. RAG vs 传统问答\n",
        "\n",
        "对比使用RAG和不使用RAG的区别"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【RAG vs 传统问答对比】\n",
            "\n",
            "1. 不使用RAG（直接问模型）:\n",
            "   截至目前，LangChain 支持多种 Agent 框架，主要包括以下几种：\n",
            "\n",
            "1. **Zero-Shot Agent**  \n",
            "   通过提示模板直接让模型根据输入决定调用哪些工具，无需示例演示。\n",
            "\n",
            "2. **Conversational Agent**  \n",
            "   适用于对话场景，能够结合上下文进...\n",
            "\n",
            "2. 使用RAG（基于知识库）:\n",
            "   LangChain提供的Agent框架，使模型能够自主决策和使用工具，支持问答系统、文档分析、代码生成、对话机器人、数据提取和智能搜索等应用场景。\n",
            "\n",
            "对比分析:\n",
            "- 不使用RAG: 可能产生幻觉，信息可能过时\n",
            "- 使用RAG: 基于实际文档，答案更准确可靠\n"
          ]
        }
      ],
      "source": [
        "print(\"【RAG vs 传统问答对比】\")\n",
        "print()\n",
        "\n",
        "question = \"LangChain支持哪些Agent框架？\"\n",
        "\n",
        "# 1. 不使用RAG（直接问模型）\n",
        "print(\"1. 不使用RAG（直接问模型）:\")\n",
        "direct_answer = model.invoke(question)\n",
        "print(f\"   {direct_answer.content[:150]}...\")\n",
        "print()\n",
        "\n",
        "# 2. 使用RAG\n",
        "print(\"2. 使用RAG（基于知识库）:\")\n",
        "rag_result = rag_system.ask(question)\n",
        "print(f\"   {rag_result['answer']}\")\n",
        "print()\n",
        "\n",
        "print(\"对比分析:\")\n",
        "print(\"- 不使用RAG: 可能产生幻觉，信息可能过时\")\n",
        "print(\"- 使用RAG: 基于实际文档，答案更准确可靠\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 总结与最佳实践\n",
        "\n",
        "### 核心概念回顾\n",
        "\n",
        "1. RAG = 检索 + 生成\n",
        "2. 2-Step RAG: 固定流程，快速高效\n",
        "3. Retriever: Runnable接口，支持各种检索策略\n",
        "4. RAG Chain: 使用LCEL优雅组合组件\n",
        "\n",
        "### RAG的关键组件\n",
        "\n",
        "- Document Loader: 加载文档\n",
        "- Text Splitter: 分割文档\n",
        "- Embeddings: 文本向量化\n",
        "- Vector Store: 存储向量\n",
        "- Retriever: 检索接口\n",
        "- Prompt Template: 构建提示词\n",
        "- LLM: 生成答案\n",
        "\n",
        "### 最佳实践\n",
        "\n",
        "1. 文档质量: 确保文档内容准确、完整\n",
        "2. 分割策略: 合理设置chunk_size和overlap\n",
        "3. 检索数量: k值通常设置为3-5\n",
        "4. 提示词设计: 明确指示模型基于上下文回答\n",
        "5. 来源追踪: 返回引用文档便于验证\n",
        "\n",
        "### 常见问题\n",
        "\n",
        "- 检索不到相关文档: 调整k值或改进查询\n",
        "- 答案不准确: 优化提示词或提高文档质量\n",
        "- 响应慢: 减少k值或优化向量存储\n",
        "- 成本高: 使用更小的embedding模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
