{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a8b2d5",
   "metadata": {},
   "source": [
    "# LangChain å­¦ä¹  - Prompts & Messages\n",
    "\n",
    "## æœ¬èŠ‚ç›®æ ‡\n",
    "- ç†è§£Prompt Templateçš„ä½œç”¨\n",
    "- æŒæ¡ChatPromptTemplateçš„ä½¿ç”¨\n",
    "- å­¦ä¼šå˜é‡æ³¨å…¥å’ŒåŠ¨æ€æç¤ºè¯\n",
    "- **ç†è§£Pipeæ“ä½œç¬¦ï¼ˆ|ï¼‰å’Œé“¾å¼ä½¿ç”¨**\n",
    "- æŒæ¡Few-shot LearningæŠ€æœ¯\n",
    "- å­¦ä¹ æç¤ºè¯å·¥ç¨‹æœ€ä½³å®è·µ\n",
    "\n",
    "## ä¸ºä»€ä¹ˆéœ€è¦Prompt Templatesï¼Ÿ\n",
    "åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦ï¼š\n",
    "1. **å¤ç”¨**ï¼šåŒä¸€ä¸ªæç¤ºè¯æ¡†æ¶ï¼Œä¸åŒçš„è¾“å…¥å†…å®¹\n",
    "2. **ç»´æŠ¤**ï¼šé›†ä¸­ç®¡ç†æç¤ºè¯ï¼Œæ–¹ä¾¿ä¿®æ”¹å’Œä¼˜åŒ–\n",
    "3. **ç»„åˆ**ï¼šå°†å¤šä¸ªæç¤ºè¯ç»„åˆæˆå¤æ‚çš„å¯¹è¯æµç¨‹\n",
    "\n",
    "Prompt Templateè®©æç¤ºè¯å˜æˆå¯ç¼–ç¨‹çš„ç»„ä»¶ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c4a604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¯å¢ƒå‡†å¤‡å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "_project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(_project_root)\n",
    "\n",
    "from config import config\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    api_key=config.OPENAI_API_KEY,\n",
    "    base_url=config.OPENAI_BASE_URL,\n",
    ")\n",
    "\n",
    "print(\"ç¯å¢ƒå‡†å¤‡å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce42ff4",
   "metadata": {},
   "source": [
    "## é—®é¢˜ï¼šç¡¬ç¼–ç çš„æç¤ºè¯\n",
    "åœ¨ç¬¬ä¸€è¯¾ä¸­ï¼Œæˆ‘ä»¬è¿™æ ·ä½¿ç”¨æç¤ºè¯ï¼š\n",
    "\n",
    "```python\n",
    "response = model.invoke(\"ç»™æˆ‘è®²ä¸€ä¸ªå…³äºAIçš„ç¬‘è¯\")\n",
    "```\n",
    "\n",
    "**é—®é¢˜**ï¼š\n",
    "- æ¯æ¬¡éƒ½è¦å†™å®Œæ•´çš„æç¤ºè¯\n",
    "- éš¾ä»¥å¤ç”¨å’Œç»´æŠ¤\n",
    "- æ— æ³•åŠ¨æ€æ’å…¥å˜é‡\n",
    "- å›¢é˜Ÿåä½œå›°éš¾\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆ**ï¼šPrompt Templates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41655df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡æ¿åˆ›å»ºæˆåŠŸï¼\n",
      "æ¨¡æ¿å†…å®¹ï¼šinput_variables=['topic'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯'), additional_kwargs={})]\n",
      "\n",
      "å˜é‡ï¼š['topic']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªç®€å•çš„æç¤ºè¯æ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_template(\"ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯\")\n",
    "\n",
    "print(\"æ¨¡æ¿åˆ›å»ºæˆåŠŸï¼\")\n",
    "print(f\"æ¨¡æ¿å†…å®¹ï¼š{prompt}\")\n",
    "print(f\"\\nå˜é‡ï¼š{prompt.input_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afec91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¼å¼åŒ–åçš„æç¤ºè¯ï¼š\n",
      "Human: ç»™æˆ‘è®²ä¸€ä¸ªå…³äºç¨‹åºå‘˜çš„ç¬‘è¯\n",
      "\n",
      "============================================================\n",
      "\n",
      "æ ¼å¼åŒ–åçš„æ¶ˆæ¯å¯¹è±¡ï¼š\n",
      " HumanMessage: ç»™æˆ‘è®²ä¸€ä¸ªå…³äºAIçš„ç¬‘è¯\n"
     ]
    }
   ],
   "source": [
    "# æ–¹å¼1ï¼šformat() - ç”Ÿæˆå­—ç¬¦ä¸²\n",
    "formatted_prompt = prompt.format(topic=\"ç¨‹åºå‘˜\")\n",
    "print(\"æ ¼å¼åŒ–åçš„æç¤ºè¯ï¼š\")\n",
    "print(formatted_prompt)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# æ–¹å¼2ï¼šformat_messages(topic=\"AI\")\n",
    "messages = prompt.format_messages(topic=\"AI\")\n",
    "print(\"æ ¼å¼åŒ–åçš„æ¶ˆæ¯å¯¹è±¡ï¼š\")\n",
    "for msg in messages:\n",
    "    print(f\" {type(msg).__name__}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817807b",
   "metadata": {},
   "source": [
    "## â­ Pipeæ“ä½œç¬¦ï¼ˆ|ï¼‰- é“¾å¼è°ƒç”¨\n",
    "è¿™æ˜¯LangChainæœ€æ ¸å¿ƒçš„è¯­æ³•ä¹‹ä¸€ï¼\n",
    "\n",
    "### æ¦‚å¿µ\n",
    "Pipeæ“ä½œç¬¦ï¼ˆ`|`ï¼‰ç”¨äºè¿æ¥ä¸åŒçš„ç»„ä»¶ï¼Œå½¢æˆå¤„ç†é“¾ï¼ˆChainï¼‰\n",
    "\n",
    "### è¯­æ³•\n",
    "```python\n",
    "chain = prompt | model\n",
    "result = chain.invoke({\"topic\": \"Python\"})\n",
    "```\n",
    "\n",
    "### ä¼˜åŠ¿\n",
    "- ä»£ç ç®€æ´æ˜“è¯»\n",
    "- å¯ç»„åˆæ€§å¼º\n",
    "- è¿™æ˜¯LCELï¼ˆLangChain Expression Languageï¼‰çš„åŸºç¡€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3490ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIå›å¤ï¼š\n",
      "å½“ç„¶å¯ä»¥ï¼è¿™æ˜¯ä¸€ä¸ªå…³äºPythonçš„ç¬‘è¯ï¼š\n",
      "\n",
      "ä¸ºä»€ä¹ˆPythonç¨‹åºå‘˜å–œæ¬¢ç”¨â€œwhile Trueâ€ï¼Ÿ\n",
      "\n",
      "å› ä¸ºä»–ä»¬æ€»æ˜¯æƒ³ä¿æŒâ€œå¾ªç¯â€å¿«ä¹ï¼ğŸ˜„\n",
      "\n",
      "å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªç¬‘è¯ï¼å¦‚æœæƒ³å¬æ›´å¤šï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªchainï¼šprompt | model\n",
    "chain = prompt | model\n",
    "\n",
    "# è°ƒç”¨chain\n",
    "response = chain.invoke({\"topic\": \"Python\"})\n",
    "\n",
    "print(\"AIå›å¤ï¼š\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf165e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ä½¿ç”¨Chainè¿›è¡Œæµå¼è¾“å‡ºæ”¹é€ \n",
      "============================================================\n",
      "AIå›å¤ï¼ˆæµå¼ï¼‰ï¼šå½“ç„¶å¯ä»¥ï¼è¿™é‡Œæœ‰ä¸€ä¸ªå…³äºçŒ«çš„ç¬‘è¯ï¼š\n",
      "\n",
      "ä¸ºä»€ä¹ˆçŒ«å–œæ¬¢åœ¨ç”µè„‘é”®ç›˜ä¸Šèµ°æ¥èµ°å»ï¼Ÿ\n",
      "\n",
      "å› ä¸ºå®ƒä»¬æƒ³è¦æ‰¾åˆ°â€œé¼ æ ‡â€ï¼ğŸ­ğŸ˜¸\n",
      "\n",
      "å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªç¬‘è¯ï¼\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chainä¹Ÿæ”¯æŒstream\n",
    "print(\"=\" * 60)\n",
    "print(\"ä½¿ç”¨Chainè¿›è¡Œæµå¼è¾“å‡ºæ”¹é€ \")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "print(\"AIå›å¤ï¼ˆæµå¼ï¼‰ï¼š\", end=\"\", flush=True)\n",
    "for chunk in chain.stream({\"topic\": \"çŒ«\"}):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40097711",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate - å¤šæ¶ˆæ¯æ¨¡æ¿\n",
    "\n",
    "`from_template()`åªèƒ½åˆ›å»ºå•æŒ‘æ¶ˆæ¯ï¼Œå®é™…åº”ç”¨ä¸­æˆ‘ä»¬éœ€è¦å¤šæ¡æ¶ˆæ¯ï¼ˆsystem + userï¼‰\n",
    "\n",
    "ä½¿ç”¨`from_messages()`åˆ›å»ºåŒ…å«å¤šæ¡æ¶ˆæ¯çš„æ¨¡æ¿ï¼š\n",
    "\n",
    "```python\n",
    "ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ç³»ç»Ÿæ¶ˆæ¯\"),\n",
    "    (\"user\", \"ç”¨æˆ·æ¶ˆæ¯\"),\n",
    "    (\"assistant\", \"AIæ¶ˆæ¯\"),  # å¯é€‰\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3725dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡æ¿å˜é‡ï¼š ['question', 'role']\n",
      "\n",
      "æ ¼å¼åŒ–åçš„æ¶ˆæ¯ï¼š\n",
      " SystemMessage: ä½ æ˜¯Pythonç¼–ç¨‹ä¸“å®¶ï¼Œè¯·ç”¨ä¸“ä¸šçš„æ–¹å¼å›ç­”é—®é¢˜ã€‚\n",
      " HumanMessage: ä»€ä¹ˆæ˜¯è£…é¥°å™¨ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# åˆ›å»ºåŒ…å«systemå’Œuseræ¶ˆæ¯çš„æ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯{role}ï¼Œè¯·ç”¨ä¸“ä¸šçš„æ–¹å¼å›ç­”é—®é¢˜ã€‚\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "print(\"æ¨¡æ¿å˜é‡ï¼š\", prompt.input_variables)\n",
    "print(\"\\næ ¼å¼åŒ–åçš„æ¶ˆæ¯ï¼š\")\n",
    "\n",
    "messages = prompt.format_messages(\n",
    "    role=\"Pythonç¼–ç¨‹ä¸“å®¶\",\n",
    "    question=\"ä»€ä¹ˆæ˜¯è£…é¥°å™¨ï¼Ÿ\"\n",
    ")\n",
    "\n",
    "for msg in messages:\n",
    "    print(f\" {msg.__class__.__name__}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca66243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€ç¤ºä¾‹1ï¼šæµ·ç›—èˆ¹é•¿ã€‘\n",
      "å“ˆå“ˆï¼Œä¼™è®¡ä»¬ï¼ä»Šå¤©å¤©æ°”å¯çœŸä¸é”™ï¼æµ·é£å¾å¾ï¼Œé˜³å…‰æ™®ç…§ï¼Œæ­£æ˜¯èˆªæµ·çš„å¥½æ—¶å…‰ï¼å’±ä»¬å¯ä»¥æ‰¬å¸†èµ·èˆªï¼Œå»å¾æœé‚£æ— å°½çš„æµ·æ´‹ï¼å‡†å¤‡å¥½ä½ ä»¬çš„å¸†å’Œæ°´æ‰‹åˆ€ï¼Œå‡ºå‘å§ï¼\n",
      "\n",
      "============================================================\n",
      "\n",
      "ã€ç¤ºä¾‹2ï¼šæ–‡è‰ºè¯—äººã€‘\n",
      "ä»Šå¤©çš„å¤©æ°”ï¼Œå¦‚åŒä¸€å¹…ç»†è…»çš„ç”»å·ï¼Œé˜³å…‰æ´’è½åœ¨å¤§åœ°ä¸Šï¼Œå®›å¦‚é‡‘è‰²çš„ä¸çº¿ç¼–ç»‡è€Œæˆçš„æ¢¦ï¼›å¾®é£è½»æ‹‚ï¼Œä¼¼é‚£æ¸©æŸ”çš„ä½è¯­ï¼Œå¸¦ç€æ˜¥å¤©çš„æ°”æ¯ï¼Œè½»è½»å»è¿‡æ¯ä¸€ç‰‡ç»¿å¶ã€‚å¤©ç©ºæ¹›è“ï¼Œäº‘æœµå¦‚åŒæ£‰èŠ±ç³–èˆ¬æ‚ ç„¶æ¼‚æµ®ï¼Œä»¿ä½›åœ¨è¯‰è¯´ç€æ— å°½çš„æ•…äº‹ã€‚æ— è®ºæ˜¯æ¼«æ­¥äºå¤§è¡—å°å··ï¼Œè¿˜æ˜¯é™åäºçª—å‰ï¼Œéƒ½æ˜¯ä¸è‡ªç„¶äº²å¯†æ¥è§¦çš„ç»ä½³æ—¶åˆ»ã€‚è¿™æ ·çš„æ—¥å­ï¼Œä»¿ä½›æ˜¯ä¸Šå¸ä¸ºæˆ‘ä»¬å‡†å¤‡çš„ä¸€åœºç››å®´ï¼Œè®©å¿ƒçµåœ¨æ¸©æš–çš„é˜³å…‰ä¸‹å°½æƒ…èˆåŠ¨ã€‚\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªè§’è‰²æ‰®æ¼”åŠ©æ‰‹æ¨¡æ¿\n",
    "role_play_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä½{role}ï¼Œè¯´è¯é£æ ¼æ˜¯{style}ã€‚\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "# åˆ›å»ºchain\n",
    "chain = role_play_prompt | model\n",
    "\n",
    "# æµ‹è¯•ä¸åŒè§’è‰²\n",
    "print(\"ã€ç¤ºä¾‹1ï¼šæµ·ç›—èˆ¹é•¿ã€‘\")\n",
    "response1 = chain.invoke({\n",
    "    \"role\": \"æµ·ç›—èˆ¹é•¿\",\n",
    "    \"style\": \"ç²—çŠ·è±ªè¿ˆï¼Œå¸¸ç”¨'å“ˆå“ˆ'å’Œ'ä¼™è®¡ä»¬'\",\n",
    "    \"question\": \"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"\n",
    "})\n",
    "print(response1.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"ã€ç¤ºä¾‹2ï¼šæ–‡è‰ºè¯—äººã€‘\")\n",
    "response2 = chain.invoke({\n",
    "    \"role\": \"æ–‡è‰ºè¯—äºº\",\n",
    "    \"style\": \"ä¼˜é›…æµªæ¼«ï¼Œå–„ç”¨æ¯”å–»\",\n",
    "    \"question\": \"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"\n",
    "})\n",
    "print(response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f165cf",
   "metadata": {},
   "source": [
    "## å¤šå˜é‡æ¨¡æ¿\n",
    "\n",
    "æ¨¡æ¿å¯ä»¥åŒ…å«å¤šä¸ªå˜é‡ï¼Œè®©æç¤ºè¯æ›´åŠ çµæ´»ï¼š\n",
    "\n",
    "```python\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯{role}ï¼Œæ“…é•¿{skill}ã€‚\"),\n",
    "    (\"user\", \"å…³äº{topic}: {question}\")\n",
    "])\n",
    "```\n",
    "\n",
    "**è°ƒç”¨æ—¶å¿…é¡»æä¾›æ‰€æœ‰å˜é‡**ï¼š\n",
    "```python\n",
    "chain.invoke({\n",
    "    \"role\": \"...\",\n",
    "    \"skill\": \"...\",\n",
    "    \"topic\": \"...\",\n",
    "    \"question\": \"...\",\n",
    "})\n",
    "```\n",
    "\n",
    "è°ƒç”¨æ—¶å¿…é¡»æä¾›æ‰€æœ‰å˜é‡ï¼š\n",
    "\n",
    "```python\n",
    "chain.invoke({\n",
    "    \"role\": \"...\",\n",
    "    \"skill\": \"...\",\n",
    "    \"topic\": \"...\",\n",
    "    \"question\": \"...\",\n",
    "})\n",
    "\n",
    "\n",
    "chain = complex_prompt | model\n",
    "\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"role\": \"æŠ€æœ¯åšä¸»\",\n",
    "    \"specialty\": \"Pythonå’ŒAI\",\n",
    "    \"style\": \"é€šä¿—æ˜“æ‡‚ï¼Œå¤šç”¨æ¯”å–»\",\n",
    "    \"length\": \"100å­—å·¦å³\",\n",
    "    \"question\": \"ä»€ä¹ˆæ˜¯LangChainï¼Ÿ\"\n",
    "})\n",
    "\n",
    "print(response.content)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "649c4da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChainå°±åƒæ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½å·¥å…·ç®±ï¼Œä¸“é—¨ä¸ºæ„å»ºä¸è¯­è¨€æ¨¡å‹äº’åŠ¨çš„åº”ç”¨è€Œè®¾è®¡ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œä½ åœ¨ä½¿ç”¨ä¸€ä¸ªå¼ºå¤§çš„æœºå™¨äººåŠ©æ‰‹ï¼ŒLangChainå¸®åŠ©ä½ æ›´å¥½åœ°ç»„ç»‡å’Œåˆ©ç”¨è¿™ä¸ªåŠ©æ‰‹çš„èƒ½åŠ›ã€‚å®ƒæä¾›äº†è¿æ¥ä¸åŒæ•°æ®æºã€å¤„ç†æ–‡æœ¬ã€ç”Ÿæˆå“åº”ç­‰åŠŸèƒ½ï¼Œè®©å¼€å‘è€…å¯ä»¥è½»æ¾åˆ›å»ºèŠå¤©æœºå™¨äººã€é—®ç­”ç³»ç»Ÿç­‰åº”ç”¨ã€‚é€šè¿‡è¿™ä¸ªå·¥å…·ç®±ï¼Œå¼€å‘è€…å¯ä»¥æœ‰æ•ˆåœ°â€œæ­å»ºâ€ä¸è¯­è¨€æ¨¡å‹çš„æ¡¥æ¢ï¼Œä½¿å¾—å¤æ‚çš„å¯¹è¯å˜å¾—ç®€å•æ˜“è¡Œã€‚\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºå¤æ‚çš„å¤šå˜é‡æ¨¡æ¿\n",
    "complex_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ä½ æ˜¯ä¸€ä½{role}ï¼Œä¸“é•¿äº{specialty}ã€‚\n",
    "ä½ çš„å›ç­”é£æ ¼ï¼š{style}\n",
    "å›ç­”é•¿åº¦ï¼š{length}\"\"\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = complex_prompt | model\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"role\": \"æŠ€æœ¯åšä¸»\",\n",
    "    \"specialty\": \"Pythonå’ŒAI\",\n",
    "    \"style\": \"é€šä¿—æ˜“æ‡‚ï¼Œå¤šç”¨æ¯”å–»\",\n",
    "    \"length\": \"100å­—å·¦å³\",\n",
    "    \"question\": \"ä»€ä¹ˆæ˜¯LangChainï¼Ÿ\"\n",
    "})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8adb8",
   "metadata": {},
   "source": [
    "## Few-shot Learningï¼ˆå°‘æ ·æœ¬å­¦ä¹ ï¼‰\n",
    "\n",
    "### æ¦‚å¿µ\n",
    "é€šè¿‡æä¾›**ç¤ºä¾‹**æ¥å¼•å¯¼æ¨¡å‹ç†è§£ä»»åŠ¡ï¼Œè€Œä¸æ˜¯è¯¦ç»†æè¿°è§„åˆ™ã€‚\n",
    "\n",
    "### ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ\n",
    "Systemï¼šä»»åŠ¡è¯´æ˜\n",
    "Humanï¼šç¤ºä¾‹è¾“å…¥1\n",
    "AIï¼šç¤ºä¾‹è¾“å‡º1\n",
    "Humanï¼šç¤ºä¾‹è¾“å…¥2\n",
    "AIï¼šç¤ºä¾‹è¾“å‡º2\n",
    "Humanï¼šå®é™…è¾“å…¥\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# åˆ›å»ºfew-shot promptç”¨äºæƒ…æ„Ÿåˆ†ç±»\n",
    "sentiment_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªæƒ…æ„Ÿåˆ†ç±»å™¨ï¼Œå°†æ–‡æœ¬åˆ†ç±»ä¸ºï¼šç§¯æã€æ¶ˆæã€ä¸­æ€§\"),\n",
    "\n",
    "    # Few-shot examples\n",
    "    (\"human\", \"è¿™ä¸ªäº§å“å¤ªæ£’äº†ï¼éå¸¸æ»¡æ„ï¼\"),\n",
    "    (\"ai\", \"ç§¯æ\"),\n",
    "\n",
    "    (\"human\", \"è´¨é‡å¾ˆå·®ï¼Œå®Œå…¨ä¸å€¼è¿™ä¸ªä»·æ ¼ã€‚\"),\n",
    "    (\"ai\", \"æ¶ˆæ\"),\n",
    "\n",
    "    (\"human\", \"åŒ…è£…è¿˜å¯ä»¥ï¼Œç‰©æµæ­£å¸¸ã€‚\"),\n",
    "    (\"ai\", \"ä¸­æ€§\"),\n",
    "    \n",
    "    # å®é™…ä»»åŠ¡\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "chain = sentiment_prompt | model\n",
    "\n",
    "# æµ‹è¯•\n",
    "```python\n",
    "test_texts = [\n",
    "    \"è¿™å®¶é¤å…çš„æœåŠ¡éå¸¸å¥½ï¼Œèœå“ä¹Ÿå¾ˆç¾å‘³ï¼\",\n",
    "    \"ç­‰äº†ä¸€ä¸ªå°æ—¶æ‰ä¸Šèœï¼Œå¤ªæ…¢äº†ã€‚\",\n",
    "    \"ä»·æ ¼é€‚ä¸­ï¼Œç¯å¢ƒä¸€èˆ¬ã€‚\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    result = chain.invoke({\"text\": text})\n",
    "    print(f\"è¾“å…¥ï¼š{text}\")\n",
    "    print(f\"åˆ†ç±»ï¼š{result.content}\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d4f4713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¾“å…¥ï¼šè¿™å®¶é¤å…çš„æœåŠ¡éå¸¸å¥½ï¼Œèœå“ä¹Ÿå¾ˆç¾å‘³ï¼\n",
      "åˆ†ç±»ï¼šç§¯æ\n",
      "\n",
      "è¾“å…¥ï¼šç­‰äº†ä¸€ä¸ªå°æ—¶æ‰ä¸Šèœï¼Œå¤ªæ…¢äº†ã€‚\n",
      "åˆ†ç±»ï¼šæ¶ˆæ\n",
      "\n",
      "è¾“å…¥ï¼šä»·æ ¼é€‚ä¸­ï¼Œç¯å¢ƒä¸€èˆ¬ã€‚\n",
      "åˆ†ç±»ï¼šä¸­æ€§\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# åˆ›å»ºfew-shot promptç”¨äºæƒ…æ„Ÿåˆ†ç±»\n",
    "sentiment_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªæƒ…æ„Ÿåˆ†ç±»å™¨ï¼Œå°†æ–‡æœ¬åˆ†ç±»ä¸ºï¼šç§¯æã€æ¶ˆæã€ä¸­æ€§\"),\n",
    "    \n",
    "    # Few-shot examples\n",
    "    (\"human\", \"è¿™ä¸ªäº§å“å¤ªæ£’äº†ï¼éå¸¸æ»¡æ„ï¼\"),\n",
    "    (\"ai\", \"ç§¯æ\"),\n",
    "    \n",
    "    (\"human\", \"è´¨é‡å¾ˆå·®ï¼Œå®Œå…¨ä¸å€¼è¿™ä¸ªä»·æ ¼ã€‚\"),\n",
    "    (\"ai\", \"æ¶ˆæ\"),\n",
    "    \n",
    "    (\"human\", \"åŒ…è£…è¿˜å¯ä»¥ï¼Œç‰©æµæ­£å¸¸ã€‚\"),\n",
    "    (\"ai\", \"ä¸­æ€§\"),\n",
    "    \n",
    "    # å®é™…ä»»åŠ¡\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "chain = sentiment_prompt | model\n",
    "\n",
    "# æµ‹è¯•\n",
    "test_texts = [\n",
    "    \"è¿™å®¶é¤å…çš„æœåŠ¡éå¸¸å¥½ï¼Œèœå“ä¹Ÿå¾ˆç¾å‘³ï¼\",\n",
    "    \"ç­‰äº†ä¸€ä¸ªå°æ—¶æ‰ä¸Šèœï¼Œå¤ªæ…¢äº†ã€‚\",\n",
    "    \"ä»·æ ¼é€‚ä¸­ï¼Œç¯å¢ƒä¸€èˆ¬ã€‚\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    result = chain.invoke({\"text\": text})\n",
    "    print(f\"è¾“å…¥ï¼š{text}\")\n",
    "    print(f\"åˆ†ç±»ï¼š{result.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84246e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"äººå\": \"ç‹äº”\", \"åœ°ç‚¹\": \"æ­å·\", \"æ—¶é—´\": \"ä»Šå¤©æ—©ä¸Š\"}\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºfew-shot promptç”¨äºç»“æ„åŒ–è¾“å‡ºï¼ˆä¿®å¤ï¼šè½¬ä¹‰JSONä¸­çš„{}ï¼‰\n",
    "extract_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä»æ–‡æœ¬ä¸­æå–äººåã€åœ°ç‚¹ã€æ—¶é—´ï¼Œä»¥JSONæ ¼å¼è¾“å‡º\"),\n",
    "    \n",
    "    # Few-shot examples - ç”¨{{}}è½¬ä¹‰JSONçš„{}\n",
    "    (\"human\", \"å¼ ä¸‰æ˜¨å¤©åœ¨åŒ—äº¬å‚åŠ äº†ä¼šè®®\"),\n",
    "    (\"ai\", '{{\"äººå\": \"å¼ ä¸‰\", \"åœ°ç‚¹\": \"åŒ—äº¬\", \"æ—¶é—´\": \"æ˜¨å¤©\"}}'),\n",
    "    \n",
    "    (\"human\", \"æå››ä¸‹å‘¨è¦å»ä¸Šæµ·å‡ºå·®\"),\n",
    "    (\"ai\", '{{\"äººå\": \"æå››\", \"åœ°ç‚¹\": \"ä¸Šæµ·\", \"æ—¶é—´\": \"ä¸‹å‘¨\"}}'),\n",
    "    \n",
    "    # å®é™…ä»»åŠ¡\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "chain = extract_prompt | model\n",
    "\n",
    "result = chain.invoke({\"text\": \"ç‹äº”ä»Šå¤©æ—©ä¸Šåœ¨æ­å·å¼€äº†ä¸ªé‡è¦ä¼šè®®\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2678dd0",
   "metadata": {},
   "source": [
    "## Partial Variablesï¼ˆéƒ¨åˆ†å˜é‡ï¼‰\n",
    "\n",
    "æœ‰æ—¶æˆ‘ä»¬å¸Œæœ›**é¢„å…ˆå¡«å……**æŸäº›å˜é‡ï¼Œåªåœ¨è°ƒç”¨æ—¶å¡«å……å…¶ä»–å˜é‡ã€‚\n",
    "\n",
    "### ä½¿ç”¨åœºæ™¯\n",
    "- å›ºå®šçš„ç³»ç»Ÿè§’è‰²\n",
    "- å½“å‰æ—¥æœŸ/æ—¶é—´\n",
    "- é…ç½®ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84afd153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={'role': 'Pythonä¸“å®¶', 'date': <function <lambda> at 0x7f21740793f0>} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['role'], input_types={}, partial_variables={}, template='ä½ æ˜¯{role}ï¼Œè¯·ç”¨ä¸“ä¸šçš„æ–¹å¼å›ç­”é—®é¢˜ã€‚'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# æ–¹æ³•1ï¼šåˆ›å»ºæ—¶æŒ‡å®š\n",
    "prompt = prompt.partial(role=\"Pythonä¸“å®¶\")\n",
    "\n",
    "# æ–¹æ³•2ï¼šåŠ¨æ€å‡½æ•°\n",
    "from datetime import datetime\n",
    "prompt = prompt.partial(date=lambda: datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9c89e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c7f9e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä»Šå¤©æ˜¯2025å¹´12æœˆ16æ—¥ï¼Œæ˜ŸæœŸäºŒã€‚\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# åˆ›å»ºæ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯{role}ï¼Œä»Šå¤©æ˜¯{date}\"),\n",
    "    (\"user\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# ä½¿ç”¨partialé¢„å¡«å……æŸäº›å˜é‡\n",
    "partial_prompt = prompt.partial(\n",
    "    role=\"AIåŠ©æ‰‹\",\n",
    "    date=lambda: datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n",
    ")\n",
    "\n",
    "# ç°åœ¨åªéœ€è¦æä¾›question\n",
    "chain = partial_prompt | model\n",
    "\n",
    "response = chain.invoke({\"question\": \"ä»Šå¤©æ˜ŸæœŸå‡ ï¼Ÿ\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7df11",
   "metadata": {},
   "source": [
    "## æç¤ºè¯å·¥ç¨‹æœ€ä½³å®è·µ\n",
    "### 1. **æ˜ç¡®è§’è‰²å’Œä»»åŠ¡**\n",
    "```python\n",
    "\"ä½ æ˜¯ä¸€ä½Pythonç¼–ç¨‹ä¸“å®¶ï¼Œæ“…é•¿è§£é‡Šå¤æ‚æ¦‚å¿µã€‚\"\n",
    "```\n",
    "\n",
    "### 2. **æä¾›ä¸Šä¸‹æ–‡**\n",
    "```python\n",
    "\"åœ¨ä¼ä¸šåº”ç”¨å¼€å‘çš„åœºæ™¯ä¸‹ï¼Œå›ç­”ä»¥ä¸‹é—®é¢˜...\"\n",
    "````\n",
    "\n",
    "### 3. **ä½¿ç”¨Few-shot Examples**\n",
    "- æä¾›2-5ä¸ªé«˜è´¨é‡ç¤ºä¾‹\n",
    "- ç¤ºä¾‹è¦è¦†ç›–ä¸åŒæƒ…å†µ\n",
    "\n",
    "### 4. ** æŒ‡å®šè¾“å‡ºæ ¼å¼**\n",
    "```python\n",
    "\"è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼ŒåŒ…å«titleå’Œcontentä¸¤ä¸ªå­—æ®µ\"\n",
    "```\n",
    "\n",
    "### 5. **åˆ†æ­¥éª¤æ€è€ƒï¼ˆChain of Thoughtï¼‰**\n",
    "```python\n",
    "\"è®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥æ€è€ƒï¼š\\n1. é¦–å…ˆ...\\n2. ç„¶å...\\n3. æœ€å...\"\n",
    "```\n",
    "\n",
    "### 6. **è®¾ç½®çº¦æŸæ¡ä»¶**\n",
    "```python\n",
    "\"å›ç­”ä¸è¶…è¿‡100å­—\"\n",
    "\"åªä½¿ç”¨Pythonæ ‡å‡†åº“\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7580f6",
   "metadata": {},
   "source": [
    "# ç»¼åˆåº”ç”¨æœ€ä½³å®è·µ\n",
    "```python\n",
    "best_practice_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä»£ç å®¡æŸ¥å‘˜ï¼Œä¸“æ³¨äºPythonä»£ç è´¨é‡ã€‚\n",
    "\n",
    "å®¡æŸ¥æ ‡å‡†ï¼š\n",
    "1. ä»£ç é£æ ¼ï¼ˆPEP 8ï¼‰\n",
    "2. æ€§èƒ½é—®é¢˜\n",
    "3. æ½œåœ¨bug\n",
    "4. å®‰å…¨éšæ‚£\n",
    "\n",
    "è¾“å‡ºæ ¼å¼ï¼š\n",
    "- é—®é¢˜ç­‰çº§ï¼šé«˜/ä¸­/ä½\n",
    "- é—®é¢˜æè¿°\n",
    "- ä¿®æ”¹å»ºè®®\n",
    "\n",
    "ç¤ºä¾‹ï¼š\n",
    "ä»£ç ï¼šx=[ i for i  in range(100) if i%2==0]\n",
    "é—®é¢˜ï¼š\n",
    "- ç­‰çº§ï¼šä½\n",
    "- æè¿°ï¼šä»£ç æ ¼å¼ä¸è§„èŒƒï¼Œç¼ºå°‘ç©ºæ ¼\n",
    "- å»ºè®®ï¼šx = [i for i in range(100) if i % 2 == 0]\n",
    "\"\"\"),\n",
    "    (\"user\", \"è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç ï¼š\\n{code}\")\n",
    "])\n",
    "\n",
    "chain = best_practice_prompt | model\n",
    "\n",
    "code_to_review = \"\"\"\n",
    "def calc(a,b):\n",
    "    return a/b\n",
    "\"\"\"\n",
    "\n",
    "response = chain.invoke({\"code\": code_to_review})\n",
    "print(response.content)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d698d7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã€æ­£å¼é£æ ¼ã€‘\n",
      "æˆ‘ç®€ç›´ä¸æ•¢ç›¸ä¿¡è¿™ä»¶äº‹å‘ç”Ÿäº†ï¼\n",
      "\n",
      "ã€å£è¯­åŒ–é£æ ¼ã€‘\n",
      "æˆ‘çœŸä¸æ•¢ç›¸ä¿¡ä¼šå‘ç”Ÿè¿™æ ·çš„äº‹ï¼\n",
      "\n",
      "ã€æ–‡å­¦æ€§é£æ ¼ã€‘\n",
      "æˆ‘ç®€ç›´ä¸æ•¢ç›¸ä¿¡è¿™å±…ç„¶å‘ç”Ÿäº†ï¼\n"
     ]
    }
   ],
   "source": [
    "# å®æˆ˜ï¼šåˆ›å»ºä¸€ä¸ªæ”¯æŒå¤šç§é£æ ¼çš„ç¿»è¯‘å™¨\n",
    "translator_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ä½ æ˜¯ä¸€ä½ä¸“ä¸šç¿»è¯‘ï¼Œå°†{source_lang}ç¿»è¯‘æˆ{target_lang}ã€‚\n",
    "\n",
    "    ç¿»è¯‘é£æ ¼ï¼š{style}\n",
    "\n",
    "    æ³¨æ„äº‹é¡¹ï¼š\n",
    "    - ä¿æŒåŸæ–‡çš„è¯­æ°”å’Œæƒ…æ„Ÿ\n",
    "    - å‚è€ƒæ–‡åŒ–å·®å¼‚\n",
    "    - ç¡®ä¿å‡†ç¡®æ€§\"\"\"),\n",
    "\n",
    "    # Few-shot examples\n",
    "    (\"human\", \"Hello, how are you?\"),\n",
    "    (\"ai\", \"ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ\"),\n",
    "\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "chain = translator_prompt | model\n",
    "\n",
    "# æµ‹è¯•ä¸åŒé£æ ¼\n",
    "styles = [\"æ­£å¼\", \"å£è¯­åŒ–\", \"æ–‡å­¦æ€§\"]\n",
    "\n",
    "text = \"I can't believe this happened!\"\n",
    "\n",
    "for style in styles:\n",
    "    print(f\"\\nã€{style}é£æ ¼ã€‘\")\n",
    "    response = chain.invoke({\n",
    "        \"source_lang\": \"è‹±è¯­\",\n",
    "        \"target_lang\": \"ä¸­æ–‡\",\n",
    "        \"style\": style,\n",
    "        \"text\": text\n",
    "    })\n",
    "\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99277e8",
   "metadata": {},
   "source": [
    "## æœ¬èŠ‚å°ç»“\n",
    "\n",
    "âœ… ä½ å·²ç»å­¦ä¼šï¼š\n",
    "1. **Prompt Templatesçš„ä½œç”¨å’Œåˆ›å»º**\n",
    "   - `from_template()` - ç®€å•æ¨¡æ¿\n",
    "   - `from_messages()` - å¤šæ¶ˆæ¯æ¨¡æ¿\n",
    "2. **â­ Pipeæ“ä½œç¬¦ï¼ˆ|ï¼‰** - é“¾å¼è°ƒç”¨çš„æ ¸å¿ƒ\n",
    "   - `prompt | model` å½¢æˆå¤„ç†é“¾\n",
    "   - æ”¯æŒinvoke()å’Œstream()\n",
    "3. **å˜é‡æ³¨å…¥å’ŒåŠ¨æ€æç¤ºè¯**\n",
    "   - å•å˜é‡å’Œå¤šå˜é‡\n",
    "   - Partial variablesé¢„å¡«å……\n",
    "4. **Few-shot Learning**\n",
    "   - é€šè¿‡ç¤ºä¾‹å¼•å¯¼æ¨¡å‹\n",
    "   - æé«˜è¾“å‡ºè´¨é‡å’Œä¸€è‡´æ€§\n",
    "5. **æç¤ºè¯å·¥ç¨‹æœ€ä½³å®è·µ**\n",
    "   - æ˜ç¡®è§’è‰²å’Œä»»åŠ¡\n",
    "   - æä¾›ä¸Šä¸‹æ–‡\n",
    "   - æŒ‡å®šæ ¼å¼\n",
    "   - è®¾ç½®çº¦æŸ\n",
    "\n",
    "ğŸ¯ æ ¸å¿ƒæ¦‚å¿µï¼š\n",
    "- **æ¨¡æ¿åŒ–** = å¯å¤ç”¨ + å¯ç»´æŠ¤\n",
    "- **Pipeæ“ä½œç¬¦** = LangChainçš„çµé­‚\n",
    "- **Few-shot** = å±•ç¤ºä¼˜äºæè¿°\n",
    "\n",
    "ğŸ’¡ æœ€ä½³å®è·µï¼š\n",
    "- å°†å¸¸ç”¨çš„æç¤ºè¯åšæˆæ¨¡æ¿\n",
    "- ä½¿ç”¨Few-shotæé«˜ç¨³å®šæ€§\n",
    "- Partialå¡«å……å›ºå®šå˜é‡\n",
    "- ç”¨Pipeç»„åˆå¤šä¸ªæ­¥éª¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7c7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
